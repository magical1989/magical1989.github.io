<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, minimum-scale=1, user-scalable=no, minimal-ui">
  <meta name="renderer" content="webkit">
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <meta name="format-detection" content="telephone=no,email=no,adress=no">
  <!-- Color theme for statusbar -->
  <meta name="theme-color" content="#000000" />
  <!-- 强制页面在当前窗口以独立页面显示,防止别人在框架里调用页面 -->
  <meta http-equiv="window-target" content="_top" />
  
  
  <title>Hexo</title>
  <meta name="description" content="Spark Streaming 实现思路与模块概述[酷玩 Spark] Spark Streaming 源码解析系列 ，返回目录请 猛戳这里 「腾讯·广点通」技术团队荣誉出品 12345本系列内容适用范围：* 2017.07.11 update, Spark 2.2 全系列 √ (已发布：2.2.0)* 2017.10.02 update, Spark 2.1 全系列 √ (已发布：2.1.0,">
<meta property="og:type" content="article">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/0.1 Spark Streaming 实现思路与模块概述/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Spark Streaming 实现思路与模块概述[酷玩 Spark] Spark Streaming 源码解析系列 ，返回目录请 猛戳这里 「腾讯·广点通」技术团队荣誉出品 12345本系列内容适用范围：* 2017.07.11 update, Spark 2.2 全系列 √ (已发布：2.2.0)* 2017.10.02 update, Spark 2.1 全系列 √ (已发布：2.1.0,">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/010.png">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/020.png">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/030.png">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/032.png">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/035.png">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/040.png">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/045.png">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/046.png">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/050.png">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/055.png">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/060.png">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/065.png">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/070.png">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/075a.png">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/075b.png">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/075c.png">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/075d.png">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/streaming-arch.png">
<meta property="og:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/streaming-flow.png">
<meta property="og:image" content="https://licensebuttons.net/l/by-nc/4.0/88x31.png">
<meta property="og:updated_time" content="2018-02-09T03:48:41.379Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hexo">
<meta name="twitter:description" content="Spark Streaming 实现思路与模块概述[酷玩 Spark] Spark Streaming 源码解析系列 ，返回目录请 猛戳这里 「腾讯·广点通」技术团队荣誉出品 12345本系列内容适用范围：* 2017.07.11 update, Spark 2.2 全系列 √ (已发布：2.2.0)* 2017.10.02 update, Spark 2.1 全系列 √ (已发布：2.1.0,">
<meta name="twitter:image" content="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20源码解析系列/0.1%20Spark%20Streaming%20实现思路与模块概述/0.imgs/010.png">
  <!-- Canonical links -->
  <link rel="canonical" href="http://yoursite.com/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/0.1 Spark Streaming 实现思路与模块概述/index.html">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png" type="image/x-icon">
  
  <!-- font-awesome CSS -->
  <!-- <link href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"> -->
  <link rel="stylesheet" href="/css/style.css">
  
    
    

</head>


<body class="main-center" itemscope itemtype="http://schema.org/WebPage">
  <header class="header" itemscope itemtype="http://schema.org/WPHeader">
  <div class="slimContent">
    <div class="navbar-header">
      
      
      <div class="profile-block text-center">
        <a id="avatar" href="https://github.com/cofess" target="_blank">
          <img class="img-circle img-rotate" src="/images/avatar.jpg" width="200" height="200">
        </a>
        <h2 id="name" class="hidden-xs hidden-sm">昵称</h2>
        <h3 id="title" class="hidden-xs hidden-sm hidden-md">Web Developer &amp; Designer</h3>
        <small id="location" class="text-muted hidden-xs hidden-sm"><i class="icon icon-map-marker"></i> Shenzhen, China</small>
      </div>
      
      <div class="search" id="search-form-wrap">

    <form class="search-form sidebar-form">
        <div class="input-group">
            <input type="text" class="search-form-input form-control" placeholder="Search" />
            <span class="input-group-btn">
                <button type="submit" class="search-form-submit btn btn-flat" onclick="return false;"><i class="icon icon-search"></i></button>
            </span>
        </div>
    </form>
    <div class="ins-search">
  <div class="ins-search-mask"></div>
  <div class="ins-search-container">
    <div class="ins-input-wrapper">
      <input type="text" class="ins-search-input" placeholder="Type something..." x-webkit-speech />
      <button type="button" class="close ins-close ins-selectable" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">×</span></button>
    </div>
    <div class="ins-section-wrapper">
      <div class="ins-section-container"></div>
    </div>
  </div>
</div>


</div>
      <button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <nav id="main-navbar" class="collapse navbar-collapse" itemscope itemtype="http://schema.org/SiteNavigationElement" role="navigation">
      <ul class="nav navbar-nav main-nav">
        
        
        
        <li class="menu-item menu-item-home">
          <a href="/.">
            
            <i class="icon icon-home-fill"></i>
            
            <span class="menu-title">Home</span>
          </a>
        </li>
        
        
        
        <li class="menu-item menu-item-archives">
          <a href="/archives">
            
            <i class="icon icon-archives-fill"></i>
            
            <span class="menu-title">Archives</span>
          </a>
        </li>
        
        
        
        <li class="menu-item menu-item-categories">
          <a href="/categories">
            
            <i class="icon icon-folder"></i>
            
            <span class="menu-title">Categories</span>
          </a>
        </li>
        
        
        
        <li class="menu-item menu-item-tags">
          <a href="/tags">
            
            <i class="icon icon-tags"></i>
            
            <span class="menu-title">Tags</span>
          </a>
        </li>
        
        
        
        <li class="menu-item menu-item-repository">
          <a href="/repository">
            
            <i class="icon icon-project"></i>
            
            <span class="menu-title">Repository</span>
          </a>
        </li>
        
        
        
        <li class="menu-item menu-item-books">
          <a href="/books">
            
            <i class="icon icon-book-fill"></i>
            
            <span class="menu-title">Books</span>
          </a>
        </li>
        
        
        
        <li class="menu-item menu-item-links">
          <a href="/links">
            
            <i class="icon icon-friendship"></i>
            
            <span class="menu-title">Links</span>
          </a>
        </li>
        
        
        
        <li class="menu-item menu-item-about">
          <a href="/about">
            
            <i class="icon icon-cup-fill"></i>
            
            <span class="menu-title">About</span>
          </a>
        </li>
        
      </ul>
      
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/cofess" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="http://weibo.com/cofess" target="_blank" title="Weibo" data-toggle=tooltip data-placement=top><i class="icon icon-weibo"></i></a></li>
        
        <li><a href="https://twitter.com/iwebued" target="_blank" title="Twitter" data-toggle=tooltip data-placement=top><i class="icon icon-twitter"></i></a></li>
        
        <li><a href="https://www.behance.net/cofess" target="_blank" title="Behance" data-toggle=tooltip data-placement=top><i class="icon icon-behance"></i></a></li>
        
        <li><a href="/atom.xml" target="_blank" title="Rss" data-toggle=tooltip data-placement=top><i class="icon icon-rss"></i></a></li>
        
    </ul>

    </nav>
  </div>
</header>

  
    <aside class="sidebar" itemscope itemtype="http://schema.org/WPSideBar">
  <div class="slimContent">
    
      <div class="widget">
    <h3 class="widget-title">Board</h3>
    <div class="widget-body">
        <div id="board">
            
            <p>您好，您是第<span id="busuanzi_value_site_uv">0</span>位访客</p>
            
            <div class="content">
                <p>欢迎交流与分享经验!</p>
            </div>
        </div>
    </div>
</div>

    
      

    
      

    
      
    
      
  <div class="widget">
    <h3 class="widget-title">Archive</h3>
    <div class="widget-body">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/02/">February 2018</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>


    
      
  <div class="widget">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget-body">
      <ul class="recent-post-list list-unstyled no-thumbnail">
        
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                
              </p>
              <p class="item-title">
                <a href="/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/readme/" class="title">(no title)</a>
              </p>
              <p class="item-date">
                <time datetime="2018-02-09T03:49:13.960Z" itemprop="datePublished">2018-02-09</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                
              </p>
              <p class="item-title">
                <a href="/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/Q&A 什么是 end-to-end exactly-once/" class="title">(no title)</a>
              </p>
              <p class="item-date">
                <time datetime="2018-02-09T03:49:13.954Z" itemprop="datePublished">2018-02-09</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                
              </p>
              <p class="item-title">
                <a href="/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/4.2 Driver 端长时容错详解/" class="title">(no title)</a>
              </p>
              <p class="item-date">
                <time datetime="2018-02-09T03:49:13.946Z" itemprop="datePublished">2018-02-09</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                
              </p>
              <p class="item-title">
                <a href="/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/4.1 Executor 端长时容错详解/" class="title">(no title)</a>
              </p>
              <p class="item-date">
                <time datetime="2018-02-09T03:49:13.940Z" itemprop="datePublished">2018-02-09</time>
              </p>
            </div>
          </li>
          
          <li>
            
            <div class="item-inner">
              <p class="item-category">
                
              </p>
              <p class="item-title">
                <a href="/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/3.3 ReceiverTraker, ReceivedBlockTracker 详解/" class="title">(no title)</a>
              </p>
              <p class="item-date">
                <time datetime="2018-02-09T03:49:13.930Z" itemprop="datePublished">2018-02-09</time>
              </p>
            </div>
          </li>
          
      </ul>
    </div>
  </div>
  

    
  </div>
</aside>

  
  
<main class="main" role="main">
  <div class="content">
  <article id="post-bigdata/spark/Spark Streaming 源码解析系列/0.1 Spark Streaming 实现思路与模块概述" class="article article-type-post" itemscope itemtype="http://schema.org/BlogPosting">
    
    <div class="article-header">
      
      <div class="article-meta">
        <span class="article-date">
    <i class="icon icon-calendar-check"></i>
	<a href="/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/0.1 Spark Streaming 实现思路与模块概述/" class="article-date">
	  <time datetime="2018-02-09T03:49:13.868Z" itemprop="datePublished">2018-02-09</time>
	</a>
</span>
        
        

        
	<span class="article-read hidden-xs">
	    <i class="icon icon-eye-fill" aria-hidden="true"></i>
	    <span id="busuanzi_container_page_pv">
			<span id="busuanzi_value_page_pv">0</span>
		</span>
	</span>


        <span class="post-comment"><i class="icon icon-comment"></i> <a href="/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/0.1 Spark Streaming 实现思路与模块概述/#comments" class="article-comment-link">Comments</a></span>
        
      </div>
    </div>
    <div class="article-entry markdown-body" itemprop="articleBody">
      
        <h1 id="Spark-Streaming-实现思路与模块概述"><a href="#Spark-Streaming-实现思路与模块概述" class="headerlink" title="Spark Streaming 实现思路与模块概述"></a>Spark Streaming 实现思路与模块概述</h1><p><strong><em>[酷玩 Spark] Spark Streaming 源码解析系列</em></strong> ，返回目录请 <a href="readme.md">猛戳这里</a></p>
<p><a href="http://e.qq.com" target="_blank" rel="noopener">「腾讯·广点通」</a>技术团队荣誉出品</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">本系列内容适用范围：</span><br><span class="line"></span><br><span class="line">* 2017.07.11 update, Spark 2.2 全系列 √ (已发布：2.2.0)</span><br><span class="line">* 2017.10.02 update, Spark 2.1 全系列 √ (已发布：2.1.0, 2.1.1, 2.1.2)</span><br><span class="line">* 2016.11.14 update, Spark 2.0 全系列 √ (已发布：2.0.0, 2.0.1, 2.0.2)</span><br></pre></td></tr></table></figure>
<p><br><br><br></p>
<h2 id="一、基于-Spark-做-Spark-Streaming-的思路"><a href="#一、基于-Spark-做-Spark-Streaming-的思路" class="headerlink" title="一、基于 Spark 做 Spark Streaming 的思路"></a>一、基于 Spark 做 Spark Streaming 的思路</h2><p>Spark Streaming 与 Spark Core 的关系可以用下面的经典部件图来表述：</p>
<p><img src="0.imgs/010.png" alt="image"></p>
<p>在本节，我们先探讨一下基于 Spark Core 的 RDD API，如何对 streaming data 进行处理。<strong>理解下面描述的这个思路非常重要，因为基于这个思路详细展开后，就能够充分理解整个 Spark Streaming 的模块划分和代码逻辑</strong>。</p>
<p>第一步，假设我们有一小块数据，那么通过 RDD API，我们能够构造出一个进行数据处理的 RDD DAG（如下图所示）。</p>
<p><img src="0.imgs/020.png" alt="image"></p>
<p>第二步，我们对连续的 streaming data 进行切片处理 —— 比如将最近 200ms 时间的 event 积攒一下 —— 每个切片就是一个 batch，然后使用第一步中的 RDD DAG 对这个 batch 的数据进行处理。</p>
<blockquote>
<p>注意: 这里我们使用的是 batch 的概念 —— 其实 200ms 在其它同类系统中通常叫做 mini-batch，不过既然 Spark Streaming 官方的叫法就是 batch，我们这里就用 batch 表达 mini-batch 的意思了 :)</p>
</blockquote>
<p>所以，针对连续不断的 streaming data 进行多次切片，就会形成多个 batch，也就对应出来多个 RDD DAG（每个 RDD DAG 针对一个 batch 的数据）。如此一来，<strong>这多个 RDD DAG 之间相互同构，却又是不同的实例</strong>。我们用下图来表示这个关系：</p>
<p><img src="0.imgs/030.png" alt="image"></p>
<p>所以，我们将需要：</p>
<ul>
<li><p>(1) 一个<strong>静态</strong>的 RDD DAG 的<strong>模板</strong>，来表示处理逻辑；</p>
</li>
<li><p>(2) 一个<strong>动态</strong>的<strong>工作控制器</strong>，将连续的 streaming data 切分数据片段，并按照模板<strong>复制</strong>出新的 RDD DAG 的<strong>实例</strong>，对数据片段进行处理；</p>
</li>
</ul>
<p><img src="0.imgs/032.png" alt="image"></p>
<p>第三步，我们回过头来看 streaming data 本身的产生。Hadoop MapReduce, Spark RDD API 进行批处理时，一般默认数据已经在 HDFS, HBase 或其它存储上。而 streaming data —— 比如 twitter 流 —— 又有可能是在系统外实时产生的，就需要能够将这些数据导入到 Spark Streaming 系统里，就像 Apache Storm 的 Spout，Apache S4 的 Adapter 能够把数据导入系统里的作用是一致的。所以，我们将需要：</p>
<ul>
<li>(3) 原始数据的产生和导入；</li>
</ul>
<p>第四步，我们考虑，有了以上 (1)(2)(3) 3 部分，就可以顺利用 RDD API 处理 streaming data 了吗？其实相对于 batch job 通常几个小时能够跑完来讲，streaming job 的运行时间是 +∞（正无穷大）的，所以我们还将需要：</p>
<ul>
<li>(4) 对长时运行任务的保障，包括输入数据的失效后的重构，处理任务的失败后的重调。</li>
</ul>
<p>至此，streaming data 的特点决定了，如果我们想基于 Spark Core 进行 streaming data 的处理，还需要在 Spark Core 的框架上解决刚才列出的 (1)(2)(3)(4) 这四点问题：</p>
<p><img src="0.imgs/035.png" alt="image"></p>
<h2 id="二、Spark-Streaming-的整体模块划分"><a href="#二、Spark-Streaming-的整体模块划分" class="headerlink" title="二、Spark Streaming 的整体模块划分"></a>二、Spark Streaming 的整体模块划分</h2><p>根据 Spark Streaming 解决这 4 个问题的不同 focus，可以将 Spark Streaming 划分为四个大的模块：</p>
<ul>
<li>模块 1：DAG 静态定义</li>
<li>模块 2：Job 动态生成</li>
<li>模块 3：数据产生与导入</li>
<li>模块 4：长时容错</li>
</ul>
<p>其中每个模块涉及到的主要的类，示意如下：</p>
<p><img src="0.imgs/040.png" alt="image"></p>
<p>这里先不用纠结每个类的具体用途，我们将在本文中简述，并在本系列的后续文章里对每个模块逐一详述。</p>
<h3 id="2-1-模块-1：DAG-静态定义"><a href="#2-1-模块-1：DAG-静态定义" class="headerlink" title="2.1 模块 1：DAG 静态定义"></a>2.1 模块 1：DAG 静态定义</h3><p>通过前面的描述我们知道，应该首先对计算逻辑描述为一个 RDD DAG 的“模板”，在后面 Job 动态生成的时候，针对每个 batch，Spark Streaming 都将根据这个“模板”生成一个 RDD DAG 的实例。</p>
<h4 id="DStream-和-DStreamGraph"><a href="#DStream-和-DStreamGraph" class="headerlink" title="DStream 和 DStreamGraph"></a>DStream 和 DStreamGraph</h4><p>其实在 Spark Streaming 里，这个 RDD “模板”对应的具体的类是 <code>DStream</code>，RDD DAG “模板”对应的具体类是 <code>DStreamGraph</code>。而 <code>RDD</code> 本身也有很多子类，几乎每个子类都有一个对应的 <code>DStream</code>，如 <code>UnionRDD</code> 的对应是 <code>UnionDStream</code>。<code>RDD</code> 通过 <code>transformation</code> 连接成 RDD DAG（但 RDD DAG 在 Spark Core 里没有对应的具体类），<code>DStream</code> 也通过 <code>transformation</code> 连接成 <code>DStreamGraph</code>。</p>
<pre><code>DStream      的全限定名是：org.apache.spark.streaming.dstream.DStream
DStreamGraph 的全限定名是：org.apache.spark.streaming.DStreamGraph
</code></pre><h4 id="DStream-和-RDD-的关系"><a href="#DStream-和-RDD-的关系" class="headerlink" title="DStream 和 RDD 的关系"></a>DStream 和 RDD 的关系</h4><p>既然 <code>DStream</code> 是 <code>RDD</code> 的模板，而且 <code>DStream</code> 和 <code>RDD</code> 具有相同的 <em>transformation</em> 操作，比如 map(), filter(), reduce() ……等等（正是这些相同的 <em>transformation</em> 使得 <code>DStreamGraph</code> 能够忠实记录 RDD DAG 的计算逻辑），那 <code>RDD</code> 和 <code>DStream</code> 有什么不一样吗？</p>
<p>还真不一样。</p>
<p>比如，<code>DStream</code> 维护了对每个产出的 <code>RDD</code> 实例的引用。比如下图里，<code>DStream A</code> 在 3 个 batch 里分别实例化了 3 个 <code>RDD</code>，分别是 <code>a[1]</code>, <code>a[2]</code>, <code>a[3]</code>，那么 <code>DStream A</code> 就保留了一个 <code>batch → 所产出的 RDD</code> 的哈希表，即包含 <code>batch 1 → a[1]</code>, <code>batch 2 → a[2]</code>, <code>batch 3 → a[3]</code> 这 3 项。</p>
<p><img src="0.imgs/045.png" alt="image"></p>
<p>另外，能够进行流量控制的 <code>DStream</code> 子类，如 <code>ReceiverInputDStream</code>，还会保存关于历次 batch 的源头数据条数、历次 batch 计算花费的时间等数值，用来实时计算准确的流量控制信息，这些都是记在 <code>DStream</code> 里的，而 <code>RDD a[1]</code> 等则不会保存这些信息。</p>
<p>我们在考虑的时候，可以认为，<code>RDD</code> 加上 batch 维度就是 <code>DStream</code>，<code>DStream</code> 去掉 batch 维度就是 <code>RDD</code> —— 就像 <code>RDD = DStream at batch T</code>。</p>
<p>不过这里需要特别说明的是，在 <code>DStreamGraph</code> 的图里，DStream（即数据）是顶点，<code>DStream</code> 之间的 transformation（即计算）是边，这与 Apache Storm 等是相反的。</p>
<p>在 Apache Storm 的 topology 里，计算是顶点，stream（连续的 tuple，即数据）是边。这一点也是比较熟悉 Storm 的同学刚开始一下子不太理解 DStream 的原因–我们再重复一遍，DStream 即是数据本身，在有向图里是顶点、而不是边。</p>
<p><img src="0.imgs/046.png" alt="image"></p>
<h3 id="2-2-模块-2：Job-动态生成"><a href="#2-2-模块-2：Job-动态生成" class="headerlink" title="2.2 模块 2：Job 动态生成"></a>2.2 模块 2：Job 动态生成</h3><p>现在有了 <code>DStreamGraph</code> 和 <code>DStream</code>，也就是静态定义了的计算逻辑，下面我们来看 Spark Streaming 是如何将其动态调度的。</p>
<p>在 Spark Streaming 程序的入口，我们都会定义一个 batchDuration，就是需要每隔多长时间就比照静态的 <code>DStreamGraph</code> 来动态生成一个 RDD DAG 实例。在 Spark Streaming 里，总体负责动态作业调度的具体类是 <code>JobScheduler</code>，在 Spark Streaming 程序开始运行的时候，会生成一个 <code>JobScheduler</code> 的实例，并被 start() 运行起来。</p>
<p><code>JobScheduler</code> 有两个非常重要的成员：<code>JobGenerator</code> 和 <code>ReceiverTracker</code>。<code>JobScheduler</code> 将每个 batch 的 RDD DAG 具体生成工作委托给 <code>JobGenerator</code>，而将源头输入数据的记录工作委托给 <code>ReceiverTracker</code>。</p>
<p><img src="0.imgs/050.png" alt="image"></p>
<pre><code>JobScheduler    的全限定名是：org.apache.spark.streaming.scheduler.JobScheduler
JobGenerator    的全限定名是：org.apache.spark.streaming.scheduler.JobGenerator
ReceiverTracker 的全限定名是：org.apache.spark.streaming.scheduler.ReceiverTracker
</code></pre><p><strong><code>JobGenerator</code> 维护了一个定时器</strong>，周期就是我们刚刚提到的 batchDuration，<strong>定时为每个 batch 生成 RDD DAG 的实例</strong>。具体的，每次 RDD DAG 实际生成包含 5 个步骤：</p>
<ul>
<li>(1) <strong>要求 <code>ReceiverTracker</code> 将目前已收到的数据进行一次 allocate</strong>，即将上次 batch 切分后的数据切分到到本次新的 batch 里；</li>
<li>(2) <strong>要求 <code>DStreamGraph</code> 复制出一套新的 RDD DAG 的实例</strong>，具体过程是：<code>DStreamGraph</code> 将要求图里的尾 <code>DStream</code> 节点生成具体的 RDD 实例，并递归的调用尾 <code>DStream</code> 的上游 <code>DStream</code> 节点……以此遍历整个 <code>DStreamGraph</code>，遍历结束也就正好生成了 RDD DAG 的实例；</li>
<li>(3) <strong>获取第 1 步 <code>ReceiverTracker</code> 分配到本 batch 的源头数据的 meta 信息</strong>；</li>
<li>(4) 将第 2 步生成的本 batch 的 RDD DAG，和第 3 步获取到的 meta 信息，<strong>一同提交给 <code>JobScheduler</code> 异步执行</strong>；</li>
<li>(5) 只要提交结束（不管是否已开始异步执行），就<strong>马上对整个系统的当前运行状态做一个 checkpoint</strong>。</li>
</ul>
<p>上述 5 个步骤的调用关系图如下：</p>
<p><img src="0.imgs/055.png" alt="image"></p>
<h3 id="2-3-模块-3：数据产生与导入"><a href="#2-3-模块-3：数据产生与导入" class="headerlink" title="2.3 模块 3：数据产生与导入"></a>2.3 模块 3：数据产生与导入</h3><p>下面我们看 Spark Streaming 解决第三个问题的模块分析，即数据的产生与导入。</p>
<p><code>DStream</code> 有一个重要而特殊的子类 <code>ReceiverInputDStream</code>：它除了需要像其它 <code>DStream</code> 那样在某个 batch 里实例化 <code>RDD</code> 以外，还需要额外的 <code>Receiver</code> 为这个 <code>RDD</code> 生产数据！</p>
<p>具体的，Spark Streaming 在程序刚开始运行时：</p>
<ul>
<li><p>(1) 由 <code>Receiver</code> 的总指挥 <code>ReceiverTracker</code> 分发多个 job（每个 job 有 1 个 task），到多个 executor 上分别启动 <code>ReceiverSupervisor</code> 实例；</p>
</li>
<li><p>(2) 每个 <code>ReceiverSupervisor</code> 启动后将马上生成一个用户提供的 <code>Receiver</code> 实现的实例 —— 该 <code>Receiver</code> 实现可以持续产生或者持续接收系统外数据，比如 <code>TwitterReceiver</code> 可以实时爬取 twitter 数据 —— 并在 <code>Receiver</code> 实例生成后调用 <code>Receiver.onStart()</code>；</p>
</li>
</ul>
<p><img src="0.imgs/060.png" alt="image"></p>
<pre><code>ReceiverSupervisor 的全限定名是：org.apache.spark.streaming.receiver.ReceiverSupervisor
Receiver           的全限定名是：org.apache.spark.streaming.receiver.Receiver
</code></pre><p>(1)(2) 的过程由上图所示，这时 <code>Receiver</code> 启动工作已运行完毕。</p>
<p>接下来 <code>ReceiverSupervisor</code> 将在 executor 端作为的主要角色，并且：</p>
<ul>
<li><p>(3) <code>Receiver</code> 在 <code>onStart()</code> 启动后，就将<strong>持续不断</strong>地接收外界数据，并持续交给 <code>ReceiverSupervisor</code> 进行数据转储；</p>
</li>
<li><p>(4) <code>ReceiverSupervisor</code> <strong>持续不断</strong>地接收到 <code>Receiver</code> 转来的数据：</p>
<ul>
<li>如果数据很细小，就需要 <code>BlockGenerator</code> 攒多条数据成一块(4a)、然后再成块存储(4b 或 4c)</li>
<li><p>反之就不用攒，直接成块存储(4b 或 4c)</p>
</li>
<li><p>这里 Spark Streaming 目前支持两种成块存储方式，一种是由 <code>BlockManagerBasedBlockHandler</code> 直接存到 executor 的内存或硬盘，另一种由 <code>WriteAheadLogBasedBlockHandler</code> 是同时写 WAL(4c) 和 executor 的内存或硬盘</p>
</li>
</ul>
</li>
<li><p>(5) 每次成块在 executor 存储完毕后，<code>ReceiverSupervisor</code> 就会及时上报块数据的 meta 信息给 driver 端的 <code>ReceiverTracker</code>；这里的 meta 信息包括数据的标识 id，数据的位置，数据的条数，数据的大小等信息；</p>
</li>
<li><p>(6) <code>ReceiverTracker</code> 再将收到的块数据 meta 信息直接转给自己的成员 <code>ReceivedBlockTracker</code>，由 <code>ReceivedBlockTracker</code> 专门管理收到的块数据 meta 信息。</p>
</li>
</ul>
<p><img src="0.imgs/065.png" alt="image"></p>
<pre><code>BlockGenerator                 的全限定名是：org.apache.spark.streaming.receiver.BlockGenerator
BlockManagerBasedBlockHandler  的全限定名是：org.apache.spark.streaming.receiver.BlockManagerBasedBlockHandler
WriteAheadLogBasedBlockHandler 的全限定名是：org.apache.spark.streaming.receiver.WriteAheadLogBasedBlockHandler
ReceivedBlockTracker           的全限定名是：org.apache.spark.streaming.scheduler.ReceivedBlockTracker
ReceiverInputDStream           的全限定名是：org.apache.spark.streaming.dstream.ReceiverInputDStream
</code></pre><p>这里 (3)(4)(5)(6) 的过程是一直<strong>持续不断</strong>地发生的，我们也将其在上图里标识出来。</p>
<p>后续在 driver 端，就由 <code>ReceiverInputDStream</code> 在每个 batch 去检查 <code>ReceiverTracker</code> 收到的块数据 meta 信息，界定哪些新数据需要在本 batch 内处理，然后生成相应的 <code>RDD</code> 实例去处理这些块数据，这个过程在<code>模块 1：DAG 静态定义</code> <code>模块2：Job 动态生成</code> 里描述过了。</p>
<h3 id="2-4-模块-4：长时容错"><a href="#2-4-模块-4：长时容错" class="headerlink" title="2.4 模块 4：长时容错"></a>2.4 模块 4：长时容错</h3><p>以上我们简述完成 Spark Streamimg 基于 Spark Core 所新增功能的 3 个模块，接下来我们看一看第 4 个模块将如何保障 Spark Streaming 的长时运行 —— 也就是，如何与前 3 个模块结合，保障前 3 个模块的长时运行。</p>
<p>通过前 3 个模块的关键类的分析，我们可以知道，保障模块 1 和 2 需要在 driver 端完成，保障模块 3 需要在 executor 端和 driver 端完成。</p>
<h4 id="executor-端长时容错"><a href="#executor-端长时容错" class="headerlink" title="executor 端长时容错"></a>executor 端长时容错</h4><p>先看 executor 端。</p>
<p>在 executor 端，<code>ReceiverSupervisor</code> 和 <code>Receiver</code> 失效后直接重启就 OK 了，关联是保障收到的块数据的安全。保障了源头块数据，就能够保障 RDD DAG （Spark Core 的 lineage）重做。</p>
<p>Spark Streaming 对源头块数据的保障，分为 4 个层次，全面、相互补充，又可根据不同场景灵活设置：</p>
<ul>
<li><strong>(1) 热备</strong>：热备是指在存储块数据时，将其存储到本 executor、并同时 replicate 到另外一个 executor 上去。这样在一个 replica 失效后，可以立刻无感知切换到另一份 replica 进行计算。实现方式是，在实现自己的 Receiver 时，即指定一下 <code>StorageLevel</code> 为 <code>MEMORY_ONLY_2</code> 或 <code>MEMORY_AND_DISK_2</code> 就可以了。</li>
</ul>
<blockquote>
<p>// 1.5.2 update 这已经是默认了。</p>
</blockquote>
<ul>
<li><strong>(2) 冷备</strong>：冷备是每次存储块数据前，先把块数据作为 log 写出到 <code>WriteAheadLog</code> 里，再存储到本 executor。executor 失效时，就由另外的 executor 去读 WAL，再重做 log 来恢复块数据。WAL 通常写到可靠存储如 HDFS 上，所以恢复时可能需要一段 recover time。</li>
</ul>
<p><img src="0.imgs/070.png" alt="image"></p>
<ul>
<li><p><strong>(3) 重放</strong>：如果上游支持重放，比如 Apache Kafka，那么就可以选择不用热备或者冷备来另外存储数据了，而是在失效时换一个 executor 进行数据重放即可。</p>
</li>
<li><p><strong>(4) 忽略</strong>：最后，如果应用的实时性需求大于准确性，那么一块数据丢失后我们也可以选择忽略、不恢复失效的源头数据。</p>
</li>
</ul>
<p>我们用一个表格来总结一下：</p>
<table><br><tr><br>    <td align="center"></td><br>    <td align="center"><strong>图示</strong></td><br>    <td align="center"><strong>优点</strong></td><br>    <td align="center"><strong>缺点</strong></td><br></tr><br><tr><br>    <td align="center"><strong>(1) 热备</strong></td><br>    <td align="center"><img src="0.imgs/075a.png"></td><br>    <td align="center">无 recover time</td><br>    <td align="center">需要占用双倍资源</td><br></tr><br><tr><br>    <td align="center"><strong>(2) 冷备</strong></td><br>    <td align="center"><img src="0.imgs/075b.png"></td><br>    <td align="center">十分可靠</td><br>    <td align="center">存在 recover time</td><br></tr><br><tr><br>    <td align="center"><strong>(3) 重放</strong></td><br>    <td align="center"><img src="0.imgs/075c.png"></td><br>    <td align="center">不占用额外资源</td><br>    <td align="center">存在 recover time</td><br></tr><br><tr><br>    <td align="center"><strong>(4) 忽略</strong></td><br>    <td align="center"><img src="0.imgs/075d.png"></td><br>    <td align="center">无 recover time</td><br>    <td align="center">准确性有损失</td><br></tr><br></table>

<h4 id="driver-端长时容错"><a href="#driver-端长时容错" class="headerlink" title="driver 端长时容错"></a>driver 端长时容错</h4><p>前面我们讲过，块数据的 meta 信息上报到 <code>ReceiverTracker</code>，然后交给 <code>ReceivedBlockTracker</code> 做具体的管理。<code>ReceivedBlockTracker</code> 也采用 WAL 冷备方式进行备份，在 driver 失效后，由新的 <code>ReceivedBlockTracker</code> 读取 WAL 并恢复 block 的 meta 信息。</p>
<p>另外，需要定时对 <code>DStreamGraph</code> 和 <code>JobScheduler</code> 做 <code>Checkpoint</code>，来记录整个 <code>DStreamGraph</code> 的变化、和每个 batch 的 job 的完成情况。</p>
<p>注意到这里采用的是完整 checkpoint 的方式，和之前的 WAL 的方式都不一样。<code>Checkpoint</code> 通常也是落地到可靠存储如 HDFS。<code>Checkpoint</code> 发起的间隔默认的是和 <code>batchDuration 一致</code>；即每次 batch 发起、提交了需要运行的 job 后就做 <code>Checkpoint</code>，另外在 job 完成了更新任务状态的时候再次做一下 <code>Checkpoint</code>。</p>
<p>这样一来，在 driver 失效并恢复后，可以读取最近一次的 <code>Checkpoint</code> 来恢复作业的 <code>DStreamGraph</code> 和 job 的运行及完成状态。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><table><br>    <tr><br>        <td align="center"><strong>模块</strong></td><br>        <td align="center" colspan="2"><strong>长时容错保障方式</strong></td><br>    </tr><br>    <tr><br>        <td align="center">模块 1-DAG 静态定义</td><br>        <td align="center">driver 端</td><br>        <td>定时对 DStreamGraph 做 Checkpoint，来记录整个 DStreamGraph 的变化</td><br>    </tr><br>    <tr><br>        <td align="center">模块 2-job 动态生成</td><br>        <td align="center">driver 端</td><br>        <td>定时对 JobScheduler 做 Checkpoint，来记录每个 batch 的 job 的完成情况</td><br>    </tr><br>    <tr><br>        <td align="center">模块 3-数据产生与导入</td><br>        <td align="center">driver 端</td><br>        <td>源头块数据的 meta 信息上报 ReceiverTracker 时，写入 WAL</td><br>    </tr><br>    <tr><br>        <td align="center">模块 3-数据产生与导入</td><br>        <td align="center">executor 端</td><br>        <td>对源头块数据的保障：(1) 热备；(2) 冷备；(3) 重放；(4) 忽略</td><br>    </tr><br></table>

<p>总结一下“模块4：长时容错”的内容为上述表格，可以看到，Spark Streaming 的长时容错特性，能够提供不重、不丢，exactly-once 的处理语义。</p>
<h2 id="三、入口：StreamingContext"><a href="#三、入口：StreamingContext" class="headerlink" title="三、入口：StreamingContext"></a>三、入口：StreamingContext</h2><p>上面我们花了很多篇幅来介绍 Spark Streaming 的四大模块，我们在最后介绍一下 <code>StreamingContext</code>。</p>
<p>下面我们用这段仅 11 行的完整 <a href="0.imgs/http://spark.apache.org/docs/latest/streaming-programming-guide.html#a-quick-example">quick example</a>，来说明用户 code 是怎么通过 <code>StreamingContext</code> 与前面几个模块进行交互的：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming._</span><br><span class="line"></span><br><span class="line"><span class="comment">// 首先配置一下本 quick example 将跑在本机，app name 是 NetworkWordCount</span></span><br><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[2]"</span>).setAppName(<span class="string">"NetworkWordCount"</span>)</span><br><span class="line"><span class="comment">// batchDuration 设置为 1 秒，然后创建一个 streaming 入口</span></span><br><span class="line"><span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// ssc.socketTextStream() 将创建一个 SocketInputDStream；这个 InputDStream 的 SocketReceiver 将监听本机 9999 端口</span></span><br><span class="line"><span class="keyword">val</span> lines = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> words = lines.flatMap(_.split(<span class="string">" "</span>))      <span class="comment">// DStream transformation</span></span><br><span class="line"><span class="keyword">val</span> pairs = words.map(word =&gt; (word, <span class="number">1</span>))     <span class="comment">// DStream transformation</span></span><br><span class="line"><span class="keyword">val</span> wordCounts = pairs.reduceByKey(_ + _)    <span class="comment">// DStream transformation</span></span><br><span class="line">wordCounts.print()                           <span class="comment">// DStream output</span></span><br><span class="line"><span class="comment">// 上面 4 行利用 DStream transformation 构造出了 lines -&gt; words -&gt; pairs -&gt; wordCounts -&gt; .print() 这样一个 DStreamGraph</span></span><br><span class="line"><span class="comment">// 但注意，到目前是定义好了产生数据的 SocketReceiver，以及一个 DStreamGraph，这些都是静态的</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 下面这行 start() 将在幕后启动 JobScheduler, 进而启动 JobGenerator 和 ReceiverTracker</span></span><br><span class="line"><span class="comment">// ssc.start()</span></span><br><span class="line"><span class="comment">//    -&gt; JobScheduler.start()</span></span><br><span class="line"><span class="comment">//        -&gt; JobGenerator.start();    开始不断生成一个一个 batch</span></span><br><span class="line"><span class="comment">//        -&gt; ReceiverTracker.start(); 开始往 executor 上分布 ReceiverSupervisor 了，也会进一步创建和启动 Receiver</span></span><br><span class="line">ssc.start()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 然后用户 code 主线程就 block 在下面这行代码了</span></span><br><span class="line"><span class="comment">// block 的后果就是，后台的 JobScheduler 线程周而复始的产生一个一个 batch 而不停息</span></span><br><span class="line"><span class="comment">// 也就是在这里，我们前面静态定义的 DStreamGraph 的 print()，才一次一次被在 RDD 实例上调用，一次一次打印出当前 batch 的结果</span></span><br><span class="line">ssc.awaitTermination()</span><br></pre></td></tr></table></figure>
<p>所以我们看到，<code>StreamingContext</code> 是 Spark Streaming 提供给用户 code 的、与前述 4 个模块交互的一个简单和统一的入口。</p>
<h2 id="四、总结与回顾"><a href="#四、总结与回顾" class="headerlink" title="四、总结与回顾"></a>四、总结与回顾</h2><p>在最后我们再把 [Sark Streaming 官方 Programming Guide] (<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html#a-quick-example" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/streaming-programming-guide.html#a-quick-example</a>) 的部分内容放在这里，作为本文的一个回顾和总结。请大家看一看，如果看懂了本文的内容，是不是读下面这些比较 high-level 的介绍会清晰化很多 :-)</p>
<blockquote>
<p><strong>Spark Streaming</strong> is an extension of the <strong>core Spark API</strong> that enables <strong>scalable</strong>, <strong>high-throughput</strong>, <strong>fault-tolerant stream processing of live data streams</strong>. Data can be ingested from many sources like Kafka, Flume, Twitter, ZeroMQ, Kinesis, or TCP sockets, and can be processed using complex algorithms expressed with high-level functions like map, reduce, join and window. Finally, processed data can be pushed out to filesystems, databases, and live dashboards. In fact, you can apply Spark’s machine learning and graph processing algorithms on data streams.</p>
<p><img src="0.imgs/streaming-arch.png" alt=""></p>
<p>Internally, it works as follows. <strong>Spark Streaming receives live input data streams and divides the data into batches, which are then processed by the Spark engine to generate the final stream of results in batches</strong>.</p>
<p><img src="0.imgs/streaming-flow.png" alt=""></p>
<p>Spark Streaming provides a high-level abstraction called <strong>discretized stream</strong> or <strong>DStream</strong>, which represents a continuous stream of data. DStreams can be created either from input data streams from sources such as Kafka, Flume, and Kinesis, or by applying high-level operations on other DStreams. <strong>Internally, a DStream is represented as a sequence of RDDs</strong>.</p>
<p>…</p>
</blockquote>
<p>##知识共享</p>
<p><img src="https://licensebuttons.net/l/by-nc/4.0/88x31.png" alt=""></p>
<p>除非另有注明，本文及本《Spark Streaming 源码解析系列》系列文章使用 <a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC BY-NC（署名-非商业性使用）</a> 知识共享许可协议。</p>
<p><br><br><br></p>
<p>（本文完，参与本文的讨论请 <a href="https://github.com/proflin/CoolplaySpark/issues/1" target="_blank" rel="noopener">猛戳这里</a>，返回目录请 <a href="readme.md">猛戳这里</a>）</p>

      
    </div>
    <div class="article-footer">
      <blockquote class="mt-2x">
  <ul class="post-copyright list-unstyled">
    
    <li class="post-copyright-link hidden-xs">
      <strong>本文链接：</strong>
      <a href="http://yoursite.com/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/0.1 Spark Streaming 实现思路与模块概述/" title="" target="_blank" rel="external">http://yoursite.com/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/0.1 Spark Streaming 实现思路与模块概述/</a>
    </li>
    
    <li class="post-copyright-license">
      <strong>版权声明： </strong> 本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by/4.0/deed.zh" target="_blank" rel="external">CC BY 4.0 CN协议</a> 许可协议。转载请注明出处！
    </li>
  </ul>
</blockquote>


<div class="panel panel-default panel-badger">
  <div class="panel-body">
    <figure class="media">
      <div class="media-left">
        <a href="https://github.com/cofess" target="_blank" class="img-burn thumb-sm visible-lg">
          <img src="/images/avatar.jpg" class="img-rounded w-full" alt="">
        </a>
      </div>
      <div class="media-body">
        <h3 class="media-heading"><a href="https://github.com/cofess" target="_blank"><span class="text-dark">昵称</span><small class="ml-1x">Web Developer &amp; Designer</small></a></h3>
        <div>个人简介。</div>
      </div>
    </figure>
  </div>
</div>


    </div>
  </article>
  
    
  <section id="comments">
  	
       
    <div id="uyan_frame"></div>

    
  </section>


  
</div>

  <nav class="bar bar-footer clearfix" data-stick-bottom>
  <div class="bar-inner">
  
  <ul class="pager pull-left">
    
    <li class="prev">
      <a href="/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/1.1 DStream, DStreamGraph 详解/" title="(no title)"><i class="icon icon-angle-left" aria-hidden="true"></i>&nbsp;&nbsp;Newer</a>
    </li>
    
    
    <li class="next">
      <a href="/2018/01/29/hello-world/" title="Hello World">Older&nbsp;&nbsp;<i class="icon icon-angle-right" aria-hidden="true"></i></a>
    </li>
    
  </ul>
  
  
  <!-- Button trigger modal -->
  <button type="button" class="btn btn-fancy btn-donate pop-onhover bg-gradient-warning hidden-xs" data-toggle="modal" data-target="#donateModal"><span>$</span></button>
  
  
  <div class="bar-right">
    
    <div class="share-component" data-sites="weibo,qq,wechat,facebook,twitter" data-mobile-sites="weibo,qq,qzone"></div>
    
    
  </div>
  </div>
</nav>
  
<!-- Modal -->
<div class="modal modal-center modal-xs-full fade" id="donateModal" tabindex="-1" role="dialog">
  <div class="modal-dialog" role="document">
    <div class="modal-content">
      <button type="button" class="close" data-dismiss="modal" aria-label="Close"><span aria-hidden="true">&times;</span></button>
      <div class="modal-body">
        <div class="donate-box">
          <div class="donate-tit">
            <p>Thank you for your support, I will continue to work hard!</p>
          </div>
          <div class="donate-payimg">
            <img src="/images/donate/alipayimg.png" alt="Scan Qrcode" title="Scan" />
          </div>
          <p class="text-muted mv">Scan this qrcode</p>
          <div class="donate-payselect">
            <div class="pay_item checked" data-id="alipay" data-src="/images/donate/alipayimg.png">
              <div class="radio">
                <input type="radio" name="payment" id="input-alipay" value="alipay" checked>
                <label class="pay_logo clickable" for="input-alipay"><img src="/images/donate/alipay.jpg" alt="alipay" /></label>
              </div>
            </div>
            <div class="pay_item" data-id="weipay" data-src="/images/donate/weipayimg.png">
              <div class="radio">
                <input type="radio" name="payment" id="input-weipay" value="weipay">
                <label class="pay_logo clickable" for="input-weipay"><img src="/images/donate/weipay.jpg" alt="weipay" /></label>
              </div>
            </div>
          </div>
          <div class="text-grey">
            <p>Scan this qrcode, you can sweep yards reward oh!</p>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>



</main>

  <footer class="footer" itemscope itemtype="http://schema.org/WPFooter">
	
	
    <ul class="social-links">
    	
        <li><a href="https://github.com/cofess" target="_blank" title="Github" data-toggle=tooltip data-placement=top><i class="icon icon-github"></i></a></li>
        
        <li><a href="http://weibo.com/cofess" target="_blank" title="Weibo" data-toggle=tooltip data-placement=top><i class="icon icon-weibo"></i></a></li>
        
        <li><a href="https://twitter.com/iwebued" target="_blank" title="Twitter" data-toggle=tooltip data-placement=top><i class="icon icon-twitter"></i></a></li>
        
        <li><a href="https://www.behance.net/cofess" target="_blank" title="Behance" data-toggle=tooltip data-placement=top><i class="icon icon-behance"></i></a></li>
        
        <li><a href="/atom.xml" target="_blank" title="Rss" data-toggle=tooltip data-placement=top><i class="icon icon-rss"></i></a></li>
        
    </ul>

    <div class="copyright">
    	
        <div class="publishby">
        	Theme by <a href="https://github.com/cofess" target="_blank"> cofess </a>base on <a href="https://github.com/cofess/hexo-theme-pure" target="_blank">pure</a>.
        </div>
    </div>
</footer>
  <script src="https://cdn.bootcss.com/jquery/1.12.4/jquery.min.js"></script>
<script>
window.jQuery || document.write('<script src="js/jquery.min.js"><\/script>')
</script>
<script src="/js/plugin.min.js"></script>
<script src="/js/application.js"></script>
  
    
    
    
        <script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>
    
    
    
        
<script defer src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>



    
    
        
    
    <script defer type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid=[object Object]"></script>


    
    



</body>
</html>