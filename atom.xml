<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-02-09T03:48:41.442Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Liu Xi</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97/readme/"/>
    <id>http://yoursite.com/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/readme/</id>
    <published>2018-02-09T03:49:13.960Z</published>
    <updated>2018-02-09T03:48:41.442Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Spark-Streaming-源码解析系列"><a href="#Spark-Streaming-源码解析系列" class="headerlink" title="Spark Streaming 源码解析系列"></a>Spark Streaming 源码解析系列</h2><p><a href="http://e.qq.com" target="_blank" rel="noopener">「腾讯·广点通」</a>技术团队荣誉出品</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">本系列内容适用范围：</span><br><span class="line"></span><br><span class="line">* 2017.07.11 update, Spark 2.2 全系列 √ (已发布：2.2.0)</span><br><span class="line">* 2017.10.02 update, Spark 2.1 全系列 √ (已发布：2.1.0, 2.1.1, 2.1.2)</span><br><span class="line">* 2016.11.14 update, Spark 2.0 全系列 √ (已发布：2.0.0, 2.0.1, 2.0.2)</span><br></pre></td></tr></table></figure><ul><li><em>概述</em><ul><li><a href="0.1%20Spark%20Streaming%20实现思路与模块概述.md">0.1 Spark Streaming 实现思路与模块概述</a></li></ul></li><li><em>模块 1：DAG 静态定义</em><ul><li><a href="1.1%20DStream%2C%20DStreamGraph%20详解.md">1.1 DStream, DStreamGraph 详解</a></li><li><a href="1.2%20DStream%20生成%20RDD%20实例详解.md">1.2 DStream 生成 RDD 实例详解</a></li></ul></li><li><em>模块 2：Job 动态生成</em><ul><li><a href="2.1%20JobScheduler%2C%20Job%2C%20JobSet%20详解.md">2.1 JobScheduler, Job, JobSet 详解</a></li><li><a href="2.2%20JobGenerator%20详解.md">2.2 JobGenerator 详解</a></li></ul></li><li><em>模块 3：数据产生与导入</em><ul><li><a href="3.1%20Receiver%20分发详解.md">3.1 Receiver 分发详解</a> </li><li><a href="3.2%20Receiver%2C%20ReceiverSupervisor%2C%20BlockGenerator%2C%20ReceivedBlockHandler%20详解.md">3.2 Receiver, ReceiverSupervisor, BlockGenerator, ReceivedBlockHandler 详解</a></li><li><a href="3.3%20ReceiverTraker%2C%20ReceivedBlockTracker%20详解.md">3.3 ReceiverTraker, ReceivedBlockTracker 详解</a></li></ul></li><li><em>模块 4：长时容错</em><ul><li><a href="4.1%20Executor%20端长时容错详解.md">4.1 Executor 端长时容错详解</a></li><li><a href="4.2%20Driver%20端长时容错详解.md">4.2 Driver 端长时容错详解</a></li></ul></li><li><em>StreamingContext</em><ul><li>5.1 StreamingContext 详解</li></ul></li><li><em>一些资源和 Q&amp;A</em><ul><li><a href="https://github.com/lw-lin/CoolplaySpark/tree/master/Spark%20%E8%B5%84%E6%BA%90%E9%9B%86%E5%90%88" target="_blank" rel="noopener">Spark 资源集合</a> (包括 Spark Summit 视频，Spark 中文微信群等资源集合)<br><img src="../Spark%20%E8%B5%84%E6%BA%90%E9%9B%86%E5%90%88/resources/wechat_spark_streaming_small_.PNG" alt="wechat_spark_streaming_small"></li><li><a href="Q%26A%20什么是%20end-to-end%20exactly-once.md">(Q&amp;A) 什么是 end-to-end exactly-once?</a></li></ul></li></ul><h2 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h2><ul><li>Github @wongxingjun 同学指出 3 处 typo，并提 Pull Request 修正（PR 已合并）</li><li>Github @endymecy 同学指出 2 处 typo，并提 Pull Request 修正（PR 已合并）</li><li>Github @xiaoguoqiang 同学指出 1 处 typo，并提 Pull Request 修正（PR 已合并）</li><li>Github 张瀚 (@AntikaSmith) 同学指出 1 处 问题（已修正）</li><li>Github Tao Meng (@mtunique) 同学指出 1 处 typo，并提 Pull Request 修正（PR 已合并）</li><li>Github @ouyangshourui 同学指出 1 处问题，并提 Pull Request 修正（PR 已合并）</li><li>Github @jacksu 同学指出 1 处问题，并提 Pull Request 修正（PR 已合并）</li><li>Github @klion26 同学指出 1 处 typo（已修正）</li><li>Github @397090770 同学指出 1 处配图笔误（已修正）</li><li>Github @ubtaojiang1982 同学指出 1 处 typo（已修正）</li><li>Github @marlin5555 同学指出 1 处配图遗漏信息（已修正）</li><li>Weibo @wyggggo 同学指出 1 处 typo（已修正）</li></ul><h2 id="Spark-Streaming-史前史-1"><a href="#Spark-Streaming-史前史-1" class="headerlink" title="Spark Streaming 史前史(1)"></a>Spark Streaming 史前史(1)</h2><p>作为跑在商业硬件上的大数据处理框架，Apache Hadoop 在诞生后的几年内（2005~今）火的一塌糊涂，几乎成为了业界处理大数据的事实上的标准工具：</p><p><img src="0.imgs/001.png" alt="iamge"></p><h2 id="Spark-Streaming-史前史-2"><a href="#Spark-Streaming-史前史-2" class="headerlink" title="Spark Streaming 史前史(2)"></a>Spark Streaming 史前史(2)</h2><p>不过大家逐渐发现还需要有单独针对流式数据（其特点是源数据实时性高，要求处理延迟低）的处理需求；于是自 2010 年起又流行起了很多通用流数据处理框架，这种与 Hadoop 等批处理框架配合使用的“批+实时”的双引擎架构又成为了当前事实上的标准：</p><p><img src="0.imgs/002.png" alt="iamge"></p><p>  ps: 前段时间跟一位前 Googler（很巧他是 MillWheel 的第一批用户）一起吃饭时，了解到 MillWheel 原来是 2010 年左右开发的，据说极其极其好用。</p><h2 id="Spark-Streaming-诞生"><a href="#Spark-Streaming-诞生" class="headerlink" title="Spark Streaming 诞生"></a>Spark Streaming 诞生</h2><p><img src="0.imgs/005.png" alt="iamge"></p><p><img src="0.imgs/006.png" alt="iamge"></p><p>本系列文章，就来详解发布于 2013 年的 Spark Streaming。</p><h2 id="知识共享"><a href="#知识共享" class="headerlink" title="知识共享"></a>知识共享</h2><p><img src="https://licensebuttons.net/l/by-nc/4.0/88x31.png" alt=""></p><p>除非另有注明，本《Spark Streaming 源码解析系列》系列文章使用 <a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC BY-NC（署名-非商业性使用）</a> 知识共享许可协议。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Spark-Streaming-源码解析系列&quot;&gt;&lt;a href=&quot;#Spark-Streaming-源码解析系列&quot; class=&quot;headerlink&quot; title=&quot;Spark Streaming 源码解析系列&quot;&gt;&lt;/a&gt;Spark Streaming 源码解析
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97/Q&amp;A%20%E4%BB%80%E4%B9%88%E6%98%AF%20end-to-end%20exactly-once/"/>
    <id>http://yoursite.com/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/Q&amp;A 什么是 end-to-end exactly-once/</id>
    <published>2018-02-09T03:49:13.954Z</published>
    <updated>2018-02-09T03:48:41.440Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Q-什么是-end-to-end-exactly-once"><a href="#Q-什么是-end-to-end-exactly-once" class="headerlink" title="[Q] 什么是 end-to-end exactly-once ?"></a>[Q] 什么是 end-to-end exactly-once ?</h2><p>[A] 一般我们把上游数据源 (Source) 看做一个 end，把下游数据接收 (Sink) 看做另一个 end：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Source  --&gt;  Spark Streaming  --&gt;  Sink</span><br><span class="line">[end]                             [end]</span><br></pre></td></tr></table></figure><p>目前的 Spark Streaming 处理过程<strong>自身</strong>是 exactly-once 的，而且对上游这个 end 的数据管理做得也不错（比如在 direct 模式里自己保存 Kafka 的偏移），但对下游除 HDFS 外的如 HBase, MySQL, Redis 等诸多 end 还不太友好，需要 user code 来实现幂等逻辑、才能保证 end-to-end 的 exactly-once。</p><p>而在 Spark 2.0 引入的 Structured Streaming 里，将把常见的下游 end 也管理起来（比如通过 batch id 来原生支持幂等），那么不需要 user code 做什么就可以保证 end-to-end 的 exactly-once 了，请见下面一张来自 databricks 的 slide[1]:</p><p> <img src="q%26a.imgs/end-to-end%20exactly-once.png" alt="end-to-end exactly-once"></p><ul><li>[1] Reynold Xin (Databricks), <em>“the Future of Real-time in Spark”</em>, 2016.02, <a href="http://www.slideshare.net/rxin/the-future-of-realtime-in-spark" target="_blank" rel="noopener">http://www.slideshare.net/rxin/the-future-of-realtime-in-spark</a>.</li></ul><p>–</p><p>（本文完，参与本文的讨论请 <a href="https://github.com/lw-lin/CoolplaySpark/issues/25" target="_blank" rel="noopener">猛戳这里</a>，返回目录请 <a href="readme.md">猛戳这里</a>）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Q-什么是-end-to-end-exactly-once&quot;&gt;&lt;a href=&quot;#Q-什么是-end-to-end-exactly-once&quot; class=&quot;headerlink&quot; title=&quot;[Q] 什么是 end-to-end exactly-once ?&quot;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97/4.2%20Driver%20%E7%AB%AF%E9%95%BF%E6%97%B6%E5%AE%B9%E9%94%99%E8%AF%A6%E8%A7%A3/"/>
    <id>http://yoursite.com/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/4.2 Driver 端长时容错详解/</id>
    <published>2018-02-09T03:49:13.946Z</published>
    <updated>2018-02-09T03:48:41.439Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Driver-端长时容错详解"><a href="#Driver-端长时容错详解" class="headerlink" title="Driver 端长时容错详解"></a>Driver 端长时容错详解</h2><p><strong><em>[酷玩 Spark] Spark Streaming 源码解析系列</em></strong> ，返回目录请 <a href="readme.md">猛戳这里</a></p><p><a href="http://e.qq.com" target="_blank" rel="noopener">「腾讯·广点通」</a>技术团队荣誉出品</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">本系列内容适用范围：</span><br><span class="line"></span><br><span class="line">* 2017.07.11 update, Spark 2.2 全系列 √ (已发布：2.2.0)</span><br><span class="line">* 2017.10.02 update, Spark 2.1 全系列 √ (已发布：2.1.0, 2.1.1, 2.1.2)</span><br><span class="line">* 2016.11.14 update, Spark 2.0 全系列 √ (已发布：2.0.0, 2.0.1, 2.0.2)</span><br></pre></td></tr></table></figure><p><br><br><br></p><p>阅读本文前，请一定先阅读 <a href="0.1 Spark Streaming 实现思路与模块概述.md">Spark Streaming 实现思路与模块概述</a> 一文，其中概述了 Spark Streaming 的 4 大模块的基本作用，有了全局概念后再看本文对 <code>模块 4：长时容错</code> 细节的解释。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>之前的详解我们详解了完成 Spark Streamimg 基于 Spark Core 所新增功能的 3 个模块，接下来我们看一看第 4 个模块将如何保障 Spark Streaming 的长时运行 —— 也就是，如何与前 3 个模块结合，保障前 3 个模块的长时运行。</p><p>通过前 3 个模块的关键类的分析，我们可以知道，保障模块 1 和 2 需要在 driver 端完成，保障模块 3 需要在 executor 端和 driver 端完成。</p><p><img src="0.imgs/040.png" alt="image"></p><p>本文我们详解 driver 端的保障。具体的，包括两部分：</p><ul><li>(1) ReceivedBlockTracker 容错<ul><li>采用 WAL 冷备方式</li></ul></li><li>(2) DStream, JobGenerator 容错<ul><li>采用 Checkpoint 冷备方式</li></ul></li></ul><h2 id="1-ReceivedBlockTracker-容错详解"><a href="#1-ReceivedBlockTracker-容错详解" class="headerlink" title="(1)  ReceivedBlockTracker 容错详解"></a>(1)  ReceivedBlockTracker 容错详解</h2><p>前面我们讲过，块数据的 meta 信息上报到 <code>ReceiverTracker</code>，然后交给 <code>ReceivedBlockTracker</code> 做具体的管理。<code>ReceivedBlockTracker</code> 也采用 WAL 冷备方式进行备份，在 driver 失效后，由新的 <code>ReceivedBlockTracker</code> 读取 WAL 并恢复 block 的 meta 信息。</p><p><code>WriteAheadLog</code> 的方式在单机 RDBMS、NoSQL/NewSQL 中都有广泛应用，前者比如记录 transaction log 时，后者比如 HBase 插入数据可以先写到 HLog 里。</p><p><code>WriteAheadLog</code> 的特点是顺序写入，所以在做数据备份时效率较高，但在需要恢复数据时又需要顺序读取，所以需要一定 recovery time。</p><p><code>WriteAheadLog</code> 及其基于 rolling file 的实现 <code>FileBasedWriteAheadLog</code> 我们在 <a href="4.1 Executor 端长时容错详解.md">Executor 端长时容错详解</a> 详解过了，下面我们主要看 <code>ReceivedBlockTracker</code> 如何使用 WAL。</p><p><code>ReceivedBlockTracker</code> 里有一个 <code>writeToLog()</code> 方法，会将具体的 log 信息写到 rolling log 里。我们看代码有哪些地方用到了 <code>writeToLog()</code>：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addBlock</span></span>(receivedBlockInfo: <span class="type">ReceivedBlockInfo</span>): <span class="type">Boolean</span> = synchronized &#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 【在收到了 Receiver 报上来的 meta 信息后，先通过 writeToLog() 写到 WAL】</span></span><br><span class="line">  writeToLog(<span class="type">BlockAdditionEvent</span>(receivedBlockInfo))</span><br><span class="line">  <span class="comment">// 【再将 meta 信息索引起来】</span></span><br><span class="line">  getReceivedBlockQueue(receivedBlockInfo.streamId) += receivedBlockInfo</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">allocateBlocksToBatch</span></span>(batchTime: <span class="type">Time</span>): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 【在收到了 JobGenerator 的为最新的 batch 划分 meta 信息的要求后，先通过 writeToLog() 写到 WAL】</span></span><br><span class="line">  writeToLog(<span class="type">BatchAllocationEvent</span>(batchTime, allocatedBlocks))</span><br><span class="line">  <span class="comment">// 【再将 meta 信息划分到最新的 batch 里】</span></span><br><span class="line">  timeToAllocatedBlocks(batchTime) = allocatedBlocks</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cleanupOldBatches</span></span>(cleanupThreshTime: <span class="type">Time</span>, waitForCompletion: <span class="type">Boolean</span>): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 【在收到了 JobGenerator 的清除过时的 meta 信息要求后，先通过 writeToLog() 写到 WAL】</span></span><br><span class="line">  writeToLog(<span class="type">BatchCleanupEvent</span>(timesToCleanup))</span><br><span class="line">  <span class="comment">// 【再将过时的 meta 信息清理掉】</span></span><br><span class="line">  timeToAllocatedBlocks --= timesToCleanup</span><br><span class="line">  <span class="comment">// 【再将 WAL 里过时的 meta 信息对应的 log 清理掉】</span></span><br><span class="line">  writeAheadLogOption.foreach(_.clean(cleanupThreshTime.milliseconds, waitForCompletion))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过上面的代码可以看到，有 3 种消息 —— <code>BlockAdditionEvent</code>, <code>BatchAllocationEvent</code>, <code>BatchCleanupEvent</code> —— 会被保存到 WAL 里。</p><p>也就是，如果我们从 WAL 中恢复，能够拿到这 3 种消息，然后从头开始重做这些 log，就能重新构建出 <code>ReceivedBlockTracker</code> 的状态成员：</p><p><img src="3.imgs/070.png" alt="image"></p><h2 id="2-DStream-JobGenerator-容错详解"><a href="#2-DStream-JobGenerator-容错详解" class="headerlink" title="(2) DStream, JobGenerator 容错详解"></a>(2) DStream, JobGenerator 容错详解</h2><p>另外，需要定时对 <code>DStreamGraph</code> 和 <code>JobScheduler</code> 做 Checkpoint，来记录整个 <code>DStreamGraph</code> 的变化、和每个 batch 的 job 的完成情况。</p><p>注意到这里采用的是完整 checkpoint 的方式，和之前的 WAL 的方式都不一样。Checkpoint 通常也是落地到可靠存储如 HDFS。Checkpoint 发起的间隔默认的是和 batchDuration 一致；即每次 batch 发起、提交了需要运行的 job 后就做 Checkpoint，另外在 job 完成了更新任务状态的时候再次做一下 Checkpoint。</p><p>具体的，<code>JobGenerator.doCheckpoint()</code> 实现是，<code>new</code> 一个当前状态的 <code>Checkpoint</code>，然后通过 <code>CheckpointWriter</code> 写出去：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 JobGenerator</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">doCheckpoint</span></span>(time: <span class="type">Time</span>, clearCheckpointDataLater: <span class="type">Boolean</span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> (shouldCheckpoint &amp;&amp; (time - graph.zeroTime).isMultipleOf(ssc.checkpointDuration)) &#123;</span><br><span class="line">    logInfo(<span class="string">"Checkpointing graph for time "</span> + time)</span><br><span class="line">    ssc.graph.updateCheckpointData(time)</span><br><span class="line">    <span class="comment">// 【new 一个当前状态的 Checkpoint，然后通过 CheckpointWriter 写出去】</span></span><br><span class="line">    checkpointWriter.write(<span class="keyword">new</span> <span class="type">Checkpoint</span>(ssc, time), clearCheckpointDataLater)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后我们看 <code>JobGenerator.doCheckpoint()</code> 在哪里被调用：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 JobGenerator</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processEvent</span></span>(event: <span class="type">JobGeneratorEvent</span>) &#123;</span><br><span class="line">  logDebug(<span class="string">"Got event "</span> + event)</span><br><span class="line">  event <span class="keyword">match</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// 【是异步地收到 DoCheckpoint 消息后，在一个线程池里执行 doCheckpoint() 方法】</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">DoCheckpoint</span>(time, clearCheckpointDataLater) =&gt;</span><br><span class="line">      doCheckpoint(time, clearCheckpointDataLater)</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所以进一步看，到底哪里发送过 <code>DoCheckpoint</code> 消息：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 JobGenerator</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">generateJobs</span></span>(time: <span class="type">Time</span>) &#123;</span><br><span class="line">  <span class="type">SparkEnv</span>.set(ssc.env)</span><br><span class="line">  <span class="type">Try</span> &#123;</span><br><span class="line">    jobScheduler.receiverTracker.allocateBlocksToBatch(time)                 <span class="comment">// 【步骤 (1)】</span></span><br><span class="line">    graph.generateJobs(time)                                                 <span class="comment">// 【步骤 (2)】</span></span><br><span class="line">  &#125; <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Success</span>(jobs) =&gt;</span><br><span class="line">      <span class="keyword">val</span> streamIdToInputInfos = jobScheduler.inputInfoTracker.getInfo(time) <span class="comment">// 【步骤 (3)】</span></span><br><span class="line">      jobScheduler.submitJobSet(<span class="type">JobSet</span>(time, jobs, streamIdToInputInfos))    <span class="comment">// 【步骤 (4)】</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">Failure</span>(e) =&gt;</span><br><span class="line">      jobScheduler.reportError(<span class="string">"Error generating jobs for time "</span> + time, e)</span><br><span class="line">  &#125;</span><br><span class="line">  eventLoop.post(<span class="type">DoCheckpoint</span>(time, clearCheckpointDataLater = <span class="literal">false</span>))       <span class="comment">// 【步骤 (5)】</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 来自 JobScheduler</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">clearMetadata</span></span>(time: <span class="type">Time</span>) &#123;</span><br><span class="line">  ssc.graph.clearMetadata(time)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (shouldCheckpoint) &#123;</span><br><span class="line">    <span class="comment">// 【一个 batch 做完，需要 clean 元数据时】</span></span><br><span class="line">    eventLoop.post(<span class="type">DoCheckpoint</span>(time, clearCheckpointDataLater = <span class="literal">true</span>))</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>原来是两处会发送 <code>DoCheckpoint</code> 消息：</p><ul><li>第 1 处就是经典的 <code>JobGenerator.generateJob()</code> 的第 (5) 步<ul><li>是在第 (4) 步提交了 <code>JobSet</code> 给 <code>JobScheduler</code> 异步执行后，就马上执行第 (5) 步来发送 <code>DoCheckpoint</code> 消息（如下图）</li><li><img src="0.imgs/055.png" alt="image"></li></ul></li><li>第 2 处是 <code>JobScheduler</code> 成功执行完了提交过来的 <code>JobSet</code> 后，就可以清除此 batch 的相关信息了<ul><li>这时是先 clear 各种信息</li><li>然后发送 <code>DoCheckpoint</code> 消息，触发 <code>doCheckpoint()</code>，就会记录下来我们已经做完了一个 batch </li></ul></li></ul><p>解决了什么时候 <code>doCheckpoint()</code>，现在唯一的问题就是 <code>Checkpoint</code> 都会包含什么内容了。</p><h2 id="Checkpoint-详解"><a href="#Checkpoint-详解" class="headerlink" title="Checkpoint 详解"></a>Checkpoint 详解</h2><p>我们看看 <code>Checkpoint</code> 的具体内容，整个列表如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">来自 <span class="type">Checkpoint</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> checkpointTime: <span class="type">Time</span></span><br><span class="line"><span class="keyword">val</span> master: <span class="type">String</span> = ssc.sc.master</span><br><span class="line"><span class="keyword">val</span> framework: <span class="type">String</span> = ssc.sc.appName</span><br><span class="line"><span class="keyword">val</span> jars: <span class="type">Seq</span>[<span class="type">String</span>] = ssc.sc.jars</span><br><span class="line"><span class="keyword">val</span> graph: <span class="type">DStreamGraph</span> = ssc.graph <span class="comment">// 【重要】</span></span><br><span class="line"><span class="keyword">val</span> checkpointDir: <span class="type">String</span> = ssc.checkpointDir</span><br><span class="line"><span class="keyword">val</span> checkpointDuration: <span class="type">Duration</span> = ssc.checkpointDuration</span><br><span class="line"><span class="keyword">val</span> pendingTimes: <span class="type">Array</span>[<span class="type">Time</span>] = ssc.scheduler.getPendingTimes().toArray <span class="comment">// 【重要】</span></span><br><span class="line"><span class="keyword">val</span> delaySeconds: <span class="type">Int</span> = <span class="type">MetadataCleaner</span>.getDelaySeconds(ssc.conf)</span><br><span class="line"><span class="keyword">val</span> sparkConfPairs: <span class="type">Array</span>[(<span class="type">String</span>, <span class="type">String</span>)] = ssc.conf.getAll</span><br></pre></td></tr></table></figure><p><br><br><br></p><p>（本文完，参与本文的讨论请 <a href="https://github.com/proflin/CoolplaySpark/issues/12" target="_blank" rel="noopener">猛戳这里</a>，返回目录请 <a href="readme.md">猛戳这里</a>）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Driver-端长时容错详解&quot;&gt;&lt;a href=&quot;#Driver-端长时容错详解&quot; class=&quot;headerlink&quot; title=&quot;Driver 端长时容错详解&quot;&gt;&lt;/a&gt;Driver 端长时容错详解&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;[酷玩 Spark]
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97/4.1%20Executor%20%E7%AB%AF%E9%95%BF%E6%97%B6%E5%AE%B9%E9%94%99%E8%AF%A6%E8%A7%A3/"/>
    <id>http://yoursite.com/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/4.1 Executor 端长时容错详解/</id>
    <published>2018-02-09T03:49:13.940Z</published>
    <updated>2018-02-09T03:48:41.438Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Executor-端长时容错详解"><a href="#Executor-端长时容错详解" class="headerlink" title="Executor 端长时容错详解"></a>Executor 端长时容错详解</h1><p><strong><em>[酷玩 Spark] Spark Streaming 源码解析系列</em></strong> ，返回目录请 <a href="readme.md">猛戳这里</a></p><p><a href="http://e.qq.com" target="_blank" rel="noopener">「腾讯·广点通」</a>技术团队荣誉出品</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">本系列内容适用范围：</span><br><span class="line"></span><br><span class="line">* 2017.07.11 update, Spark 2.2 全系列 √ (已发布：2.2.0)</span><br><span class="line">* 2017.10.02 update, Spark 2.1 全系列 √ (已发布：2.1.0, 2.1.1, 2.1.2)</span><br><span class="line">* 2016.11.14 update, Spark 2.0 全系列 √ (已发布：2.0.0, 2.0.1, 2.0.2)</span><br></pre></td></tr></table></figure><p><br><br><br></p><p>阅读本文前，请一定先阅读 <a href="0.1 Spark Streaming 实现思路与模块概述.md">Spark Streaming 实现思路与模块概述</a> 一文，其中概述了 Spark Streaming 的 4 大模块的基本作用，有了全局概念后再看本文对 <code>模块 4：长时容错</code> 细节的解释。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>之前的详解我们详解了完成 Spark Streamimg 基于 Spark Core 所新增功能的 3 个模块，接下来我们看一看第 4 个模块将如何保障 Spark Streaming 的长时运行 —— 也就是，如何与前 3 个模块结合，保障前 3 个模块的长时运行。</p><p>通过前 3 个模块的关键类的分析，我们可以知道，保障模块 1 和 2 需要在 driver 端完成，保障模块 3 需要在 executor 端和 driver 端完成。</p><p><img src="0.imgs/040.png" alt="image"></p><p>本文我们详解 executor 端的保障。</p><p>在 executor 端，<code>ReceiverSupervisor</code> 和 <code>Receiver</code> 失效后直接重启就 OK 了，关联是保障收到的块数据的安全。保障了源头块数据，就能够保障 RDD DAG （Spark Core 的 lineage）重做。</p><p>Spark Streaming 对源头块数据的保障，分为 4 个层次，全面、相互补充，又可根据不同场景灵活设置：</p><ul><li>(1) 热备</li><li>(2) 冷备</li><li>(3) 重放</li><li>(4) 忽略</li></ul><h2 id="1-热备"><a href="#1-热备" class="headerlink" title="(1) 热备"></a>(1) 热备</h2><p>热备是指在存储块数据时，将其存储到本 executor、并同时 replicate 到另外一个 executor 上去。这样在一个 replica 失效后，可以立刻无感知切换到另一份 replica 进行计算。</p><p>实现方式是，在实现自己的 <code>Receiver</code> 时，即指定一下 <code>StorageLevel</code> 为 <code>MEMORY_ONLY_2</code> 或 <code>MEMORY_AND_DISK_2</code> 就可以了。</p><p>比如这样：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyReceiver</span> <span class="keyword">extends</span> <span class="title">Receiver</span>(<span class="params"><span class="type">StorageLevel</span>.<span class="type">MEMORY_ONLY_2</span></span>) </span>&#123;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onStart</span></span>(): <span class="type">Unit</span> = &#123;&#125;</span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onStop</span></span>(): <span class="type">Unit</span> = &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样，<code>Receiver</code> 在将数据 <code>store()</code> 给 <code>ReceiverSupervisorImpl</code> 的时候，将同时指明此 <code>storageLevel</code>。<code>ReceiverSupervisorImpl</code> 也将根据此 <code>storageLevel</code> 将块数据具体的存储给 <code>BlockManager</code>。</p><p>然后就是依靠 <code>BlockManager</code> 进行热备。具体的 —— 我们以 <code>ReceiverSupervisorImpl</code> 向 <code>BlockManager</code> 存储一个 <code>byteBuffer</code> 为例 ——  <code>BlockManager</code> 在收到 <code>putBytes(byteBuffer)</code> 时，实际是直接调用 <code>doPut(byteBuffer)</code> 的。 那么我们看 <code>doPut(...)</code> 方法（友情提醒，主要看代码里的注释）：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">doPut</span></span>(blockId: <span class="type">BlockId</span>, data: <span class="type">BlockValues</span>, level: <span class="type">StorageLevel</span>, ...)</span><br><span class="line">  : <span class="type">Seq</span>[(<span class="type">BlockId</span>, <span class="type">BlockStatus</span>)] = &#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">//【如果  putLevel.replication &gt; 1 的话，就定义这个 future，复制数据到另外的 executor 上】</span></span><br><span class="line">  <span class="keyword">val</span> replicationFuture = data <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> b: <span class="type">ByteBufferValues</span> <span class="keyword">if</span> putLevel.replication &gt; <span class="number">1</span> =&gt;</span><br><span class="line">      <span class="keyword">val</span> bufferView = b.buffer.duplicate()</span><br><span class="line">      <span class="type">Future</span> &#123;</span><br><span class="line">        <span class="comment">//【这里非常重要，会在 future 启动时去实际调用 replicate() 方法，复制数据到另外的 executor 上】</span></span><br><span class="line">        replicate(blockId, bufferView, putLevel)</span><br><span class="line">      &#125;(futureExecutionContext)</span><br><span class="line">    <span class="keyword">case</span> _ =&gt; <span class="literal">null</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  putBlockInfo.synchronized &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// 【存储到本机 blockManager 的 blockStore 里】</span></span><br><span class="line">    <span class="keyword">val</span> result = data <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">IteratorValues</span>(iterator) =&gt;</span><br><span class="line">        blockStore.putIterator(blockId, iterator, putLevel, returnValues)</span><br><span class="line">      <span class="keyword">case</span> <span class="type">ArrayValues</span>(array) =&gt;</span><br><span class="line">        blockStore.putArray(blockId, array, putLevel, returnValues)</span><br><span class="line">      <span class="keyword">case</span> <span class="type">ByteBufferValues</span>(bytes) =&gt;</span><br><span class="line">        bytes.rewind()</span><br><span class="line">        blockStore.putBytes(blockId, bytes, putLevel)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">      </span><br><span class="line">  <span class="comment">//【再次判断  putLevel.replication &gt; 1】</span></span><br><span class="line">  <span class="keyword">if</span> (putLevel.replication &gt; <span class="number">1</span>) &#123;</span><br><span class="line">    data <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">ByteBufferValues</span>(bytes) =&gt;</span><br><span class="line">        <span class="comment">//【如果之前启动了 replicate 的 future，那么这里就同步地等这个 future 结束】</span></span><br><span class="line">        <span class="keyword">if</span> (replicationFuture != <span class="literal">null</span>) &#123;</span><br><span class="line">          <span class="type">Await</span>.ready(replicationFuture, <span class="type">Duration</span>.<span class="type">Inf</span>)</span><br><span class="line">        &#125;</span><br><span class="line">      <span class="keyword">case</span> _ =&gt;</span><br><span class="line">        <span class="keyword">val</span> remoteStartTime = <span class="type">System</span>.currentTimeMillis</span><br><span class="line">        <span class="keyword">if</span> (bytesAfterPut == <span class="literal">null</span>) &#123;</span><br><span class="line">          <span class="keyword">if</span> (valuesAfterPut == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(</span><br><span class="line">              <span class="string">"Underlying put returned neither an Iterator nor bytes! This shouldn't happen."</span>)</span><br><span class="line">          &#125;</span><br><span class="line">          bytesAfterPut = dataSerialize(blockId, valuesAfterPut)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//【否则之前没有启动 replicate 的 future，那么这里就同步地调用 replicate() 方法，复制数据到另外的 executor 上】</span></span><br><span class="line">        replicate(blockId, bytesAfterPut, putLevel)</span><br><span class="line">        logDebug(<span class="string">"Put block %s remotely took %s"</span></span><br><span class="line">          .format(blockId, <span class="type">Utils</span>.getUsedTimeMs(remoteStartTime)))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所以，可以看到， <code>BlockManager</code> 的 <code>putBytes()</code> 语义就是承诺了，如果指定需要 replicate，那么当 <code>putBytes()</code> 方法返回时，就一定是存储到本机、并且一定 replicate 到另外的 executor 上了。对于 <code>BlockManager</code> 的 <code>putIterator()</code> 也是同样的语义，因为  <code>BlockManager</code> 的 <code>putIterator()</code> 和 <code>BlockManager</code> 的 <code>putBytes()</code> 一样，都是基于  <code>BlockManager</code> 的 <code>doPut()</code> 来实现的。</p><p>简单总结本小节的解析，<code>Receiver</code> 收到的数据，通过 <code>ReceiverSupervisorImpl</code>，将数据交给 <code>BlockManager</code> 存储；而 <code>BlockManager</code> 本身支持将数据 <code>replicate()</code> 到另外的 executor 上，这样就完成了 <code>Receiver</code> 源头数据的热备过程。</p><p>而在计算时，计算任务首先将获取需要的块数据，这是如果一个 executor 失效导致一份数据丢失，那么计算任务将转而向另一个 executor 上的同一份数据获取数据。因为另一份块数据是现成的、不需要像冷备那样重新读取的，所以这里不会有 recovery time。</p><h2 id="2-冷备"><a href="#2-冷备" class="headerlink" title="(2) 冷备"></a>(2) 冷备</h2><p>!!! 需要同时修改</p><p>冷备是每次存储块数据时，除了存储到本 executor，还会把块数据作为 log 写出到 WriteAheadLog 里作为冷备。这样当 executor 失效时，就由另外的 executor 去读 WAL，再重做 log 来恢复块数据。WAL 通常写到可靠存储如 HDFS 上，所以恢复时可能需要一段 recover time。</p><p>冷备的写出过程如下图 4(c) 过程所示：</p><p><img src="0.imgs/065.png" alt="image"></p><p>这里我们需要插播一下详解 <code>WriteAheadLog</code> 框架。</p><h3 id="WriteAheadLog-框架"><a href="#WriteAheadLog-框架" class="headerlink" title="WriteAheadLog 框架"></a>WriteAheadLog 框架</h3><p><code>WriteAheadLog</code> 的方式在单机 RDBMS、NoSQL/NewSQL 中都有广泛应用，前者比如记录 transaction log 时，后者比如 HBase 插入数据可以先写到 HLog 里。</p><p><code>WriteAheadLog</code> 的特点是顺序写入，所以在做数据备份时效率较高，但在需要恢复数据时又需要顺序读取，所以需要一定 recovery time。</p><p>不过对于 Spark Streaming 的块数据冷备来讲，在恢复时也非常方便。这是因为，对某个块数据的操作只有一次（即新增块数据），而没有后续对块数据的追加、修改、删除操作，这就使得在 WAL 里只会有一条此块数据的 log entry。所以，我们在恢复时只要 seek 到这条 log entry 并读取就可以了，而不需要顺序读取整个 WAL。</p><p>也就是，Spark Streaming 基于 WAL 冷备进行恢复，需要的 recovery time 只是 seek 到并读一条 log entry 的时间，而不是读取整个 WAL 的时间，这个是个非常大的节省。</p><p>Spark Streaming 里的 WAL 框架，由一组抽象类，和一组基于文件的具体实现组成。其类结构关系如下：</p><p><img src="img.png" alt="image"></p><h3 id="WriteAheadLog-WriteAheadLogRecordHandle"><a href="#WriteAheadLog-WriteAheadLogRecordHandle" class="headerlink" title="WriteAheadLog, WriteAheadLogRecordHandle"></a>WriteAheadLog, WriteAheadLogRecordHandle</h3><p><code>WriteAheadLog</code> 是多条 log 的集合，每条具体的 log 的引用就是一个 <code>LogRecordHandle</code>。这两个 abstract 的接口定义如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//  来自 WriteAheadLog</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@org</span>.apache.spark.annotation.<span class="type">DeveloperApi</span></span><br><span class="line">public <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">WriteAheadLog</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 【写方法：写入一条 log，将返回一个指向这条 log 的句柄引用】</span></span><br><span class="line">  <span class="keyword">abstract</span> public <span class="type">WriteAheadLogRecordHandle</span> write(<span class="type">ByteBuffer</span> record, long time);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 【读方法：给定一条 log 的句柄引用，读出这条 log】</span></span><br><span class="line">  <span class="keyword">abstract</span> public <span class="type">ByteBuffer</span> read(<span class="type">WriteAheadLogRecordHandle</span> handle);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 【读方法：读取全部 log】</span></span><br><span class="line">  <span class="keyword">abstract</span> public <span class="type">Iterator</span>&lt;<span class="type">ByteBuffer</span>&gt; readAll();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 【清理过时的 log 条目】</span></span><br><span class="line">  <span class="keyword">abstract</span> public void clean(long threshTime, boolean waitForCompletion);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 【关闭方法】</span></span><br><span class="line">  <span class="keyword">abstract</span> public void close();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//  来自 WriteAheadLogRecordHandle</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@org</span>.apache.spark.annotation.<span class="type">DeveloperApi</span></span><br><span class="line">public <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">WriteAheadLogRecordHandle</span> <span class="title">implements</span> <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 【Handle 则是一个空接口，需要具体的子类定义真正的内容】</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里 <code>WriteAheadLog</code> 基于文件的具体实现是 <code>FileBasedWriteAheadLog</code>，<code>WriteAheadLogRecordHandle</code> 基于文件的具体实现是 <code>FileBasedWriteAheadLogSegment</code>，下面我们详细看看这两个具体的类。</p><h3 id="FileBasedWriteAheadLogSegment"><a href="#FileBasedWriteAheadLogSegment" class="headerlink" title="FileBasedWriteAheadLogSegment"></a>FileBasedWriteAheadLogSegment</h3><p><code>FileBasedWriteAheadLog</code> 有 3 个重要的配置项或成员：</p><ul><li><p>rolling 配置项</p><ul><li><code>FileBasedWriteAheadLog</code> 的实现把 log 写到一个文件里（一般是 HDFS 等可靠存储上的文件），然后每隔一段时间就关闭已有文件，产生一些新文件继续写，也就是 rolling 写的方式</li><li>rolling 写的好处是单个文件不会太大，而且删除不用的旧数据特别方便</li><li>这里 rolling 的间隔是由参数 <code>spark.streaming.receiver.writeAheadLog.rollingIntervalSecs（默认 = 60 秒）</code> 控制的</li></ul></li><li><p>WAL 存放的目录：<code>{checkpointDir}/receivedData/{receiverId}</code></p><ul><li><code>{checkpointDir}</code> 在 <code>ssc.checkpoint(checkpointDir)</code> 指定的</li><li><code>{receiverId}</code> 是 <code>Receiver</code> 的 id</li><li>在这个 WAL 目录里，不同的 rolling log 文件的命名规则是 <code>log-{startTime}-{stopTime}</code></li></ul></li><li><p>然后就是 <code>FileBasedWriteAheadLog.currentLogWriter</code></p><ul><li>一个 <code>LogWriter</code> 对应一个 log file，而且 log 文件本身是 rolling 的，那么前一个 log 文件写完成后，对应的 writer 就可以 <code>close()</code> 了，而由新的 writer 负责写新的文件</li><li>这里最新的 <code>LogWriter</code> 就由 <code>currentLogWriter</code> 来指向</li></ul></li></ul><p>接下来就是 <code>FileBasedWriteAheadLog</code>  的读写方法了：</p><ul><li><code>write(byteBuffer: ByteBuffer, time: Long)</code><ul><li>最重要的是先调用 <code>getCurrentWriter()</code>，获取当前的 currentWriter</li><li>注意这里，如果 log file 需要 rolling 成新的了，那么 currentWriter 也需要随之更新；上面  <code>getCurrentWriter()</code> 会完成这个按需更新 <code>currentWriter</code>  的过程</li><li>然后就可以调用 <code>writer.write(byteBuffer)</code> 就可以了</li></ul></li><li><code>read(segment: WriteAheadLogRecordHandle): ByteBuffer</code><ul><li>直接调用 <code>reader.read(fileSegment)</code></li><li>在 reader 的实现里，因为给定了 <code>segment</code> —— 也就是 <code>WriteAheadLogRecordHandle</code>，而 <code>segment</code> 里包含了具体的 log file 和 offset，就可以直接 seek 到这条 log，读出数据并返回</li></ul></li></ul><p>所以总结下可以看到，<code>FileBasedWriteAheadLog</code> 主要是进行 rolling file 的管理，然后将具体的写方法、读方法是由具体的 <code>LogWriter</code> 和 <code>LogReader</code> 来做的。</p><h3 id="WriteAheadLogRecordHandle"><a href="#WriteAheadLogRecordHandle" class="headerlink" title="WriteAheadLogRecordHandle"></a>WriteAheadLogRecordHandle</h3><p>前面我们刚说，<code>WriteAheadLogRecordHandle</code> 是一个 log 句柄的空实现，需要子类指定具体的 log 句柄内容。</p><p>然后在基于的 file 的子类实现 <code>WriteAheadLogRecordHandle</code> 里，就记录了 3 方面内容：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 FileBasedWriteAheadLogSegment</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[streaming] <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">FileBasedWriteAheadLogSegment</span>(<span class="params">path: <span class="type">String</span>, offset: <span class="type">Long</span>, length: <span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class">  <span class="keyword">extends</span> <span class="title">WriteAheadLogRecordHandle</span></span></span><br></pre></td></tr></table></figure><ul><li><code>path: String</code></li><li><code>offset: Long</code></li><li><code>length: Int</code></li></ul><p>这 3 方面内容就非常直观了，给定文件、偏移和长度，就可以唯一确定一条 log。</p><h3 id="FileBasedWriteAheadLogWriter"><a href="#FileBasedWriteAheadLogWriter" class="headerlink" title="FileBasedWriteAheadLogWriter"></a>FileBasedWriteAheadLogWriter</h3><p><code>FileBasedWriteAheadLogWriter</code> 的实现，就是给定一个文件、给定一个块数据，将数据写到文件里面去。</p><p>然后在完成的时候，记录一下文件 path、offset 和 length，封装为一个 <code>FileBasedWriteAheadLogSegment</code> 返回。</p><p>这里需要注意下的是，在具体的写 HDFS 数据块的时候，需要判断一下具体用的方法，优先使用 <code>hflush()</code>，没有的话就使用 <code>sync()</code>：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 FileBasedWriteAheadLogWriter</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">lazy</span> <span class="keyword">val</span> hadoopFlushMethod = &#123;</span><br><span class="line">  <span class="comment">// Use reflection to get the right flush operation</span></span><br><span class="line">  <span class="keyword">val</span> cls = classOf[<span class="type">FSDataOutputStream</span>]</span><br><span class="line">  <span class="type">Try</span>(cls.getMethod(<span class="string">"hflush"</span>)).orElse(<span class="type">Try</span>(cls.getMethod(<span class="string">"sync"</span>))).toOption</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="FileBasedWriteAheadLogRandomReader"><a href="#FileBasedWriteAheadLogRandomReader" class="headerlink" title="FileBasedWriteAheadLogRandomReader"></a>FileBasedWriteAheadLogRandomReader</h3><p><code>FileBasedWriteAheadLogRandomReader</code> 的主要方法是 <code>read(segment: FileBasedWriteAheadLogSegment): ByteBuffer</code>，即给定一个 log 句柄，返回一条具体的 log。</p><p>这里主要代码如下，注意到其中最关键的是 <code>seek(segment.offset)</code> !</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 FileBasedWriteAheadLogRandomReader</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read</span></span>(segment: <span class="type">FileBasedWriteAheadLogSegment</span>): <span class="type">ByteBuffer</span> = synchronized &#123;</span><br><span class="line">  assertOpen()</span><br><span class="line">  <span class="comment">// 【seek 到这条 log 所在的 offset】</span></span><br><span class="line">  instream.seek(segment.offset)</span><br><span class="line">  <span class="comment">// 【读一下 length】</span></span><br><span class="line">  <span class="keyword">val</span> nextLength = instream.readInt()</span><br><span class="line">  <span class="type">HdfsUtils</span>.checkState(nextLength == segment.length,</span><br><span class="line">    <span class="string">s"Expected message length to be <span class="subst">$&#123;segment.length&#125;</span>, but was <span class="subst">$nextLength</span>"</span>)</span><br><span class="line">  <span class="keyword">val</span> buffer = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Byte</span>](nextLength)</span><br><span class="line">  <span class="comment">// 【读一下具体的内容】</span></span><br><span class="line">  instream.readFully(buffer)</span><br><span class="line">  <span class="comment">// 【以 ByteBuffer 的形式，返回具体的内容】</span></span><br><span class="line">  <span class="type">ByteBuffer</span>.wrap(buffer)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="FileBasedWriteAheadLogReader"><a href="#FileBasedWriteAheadLogReader" class="headerlink" title="FileBasedWriteAheadLogReader"></a>FileBasedWriteAheadLogReader</h3><p><code>FileBasedWriteAheadLogReader</code> 实现跟 <code>FileBasedWriteAheadLogRandomReader</code> 差不多，不过是不需要给定 log 的句柄，而是迭代遍历所有 log：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 FileBasedWriteAheadLogReader</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 【迭代方法：hasNext()】</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">hasNext</span></span>: <span class="type">Boolean</span> = synchronized &#123;</span><br><span class="line">  <span class="keyword">if</span> (closed) &#123;</span><br><span class="line">    <span class="comment">// 【如果已关闭，就肯定不 hasNext 了】</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (nextItem.isDefined) &#123;</span><br><span class="line">    <span class="literal">true</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 【读出来下一条，如果有，就说明还确实 hasNext】</span></span><br><span class="line">      <span class="keyword">val</span> length = instream.readInt()</span><br><span class="line">      <span class="keyword">val</span> buffer = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Byte</span>](length)</span><br><span class="line">      instream.readFully(buffer)</span><br><span class="line">      nextItem = <span class="type">Some</span>(<span class="type">ByteBuffer</span>.wrap(buffer))</span><br><span class="line">      logTrace(<span class="string">"Read next item "</span> + nextItem.get)</span><br><span class="line">      <span class="literal">true</span></span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">     ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 【迭代方法：next()】</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">next</span></span>(): <span class="type">ByteBuffer</span> = synchronized &#123;</span><br><span class="line">  <span class="comment">// 【直接返回在 hasNext() 方法里实际读出来的数据】</span></span><br><span class="line">  <span class="keyword">val</span> data = nextItem.getOrElse &#123;</span><br><span class="line">    close()</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalStateException</span>(</span><br><span class="line">      <span class="string">"next called without calling hasNext or after hasNext returned false"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  nextItem = <span class="type">None</span> <span class="comment">// Ensure the next hasNext call loads new data.</span></span><br><span class="line">  data</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="WAL-总结"><a href="#WAL-总结" class="headerlink" title="WAL 总结"></a>WAL 总结</h3><p>通过上面几个小节，我们看到，Spark Streaming 有一套基于 rolling file 的 WAL 实现，提供一个写方法，两个读方法：</p><ul><li><code>WriteAheadLogRecordHandle write(ByteBuffer record, long time)</code><ul><li>由 <code>FileBasedWriteAheadLogWriter</code> 具体实现</li></ul></li><li>ByteBuffer read(WriteAheadLogRecordHandle handle)`<ul><li>由 <code>FileBasedWriteAheadLogRandomReader</code> 具体实现</li></ul></li><li><code>Iterator&lt;ByteBuffer&gt; readAll()</code><ul><li>由 <code>FileBasedWriteAheadLogReader</code> 具体实现</li></ul></li></ul><h2 id="3-重放"><a href="#3-重放" class="headerlink" title="(3) 重放"></a>(3) 重放</h2><p>如果上游支持重放，比如 Apache Kafka，那么就可以选择不用热备或者冷备来另外存储数据了，而是在失效时换一个 executor 进行数据重放即可。</p><p>具体的，<a href="http://spark.apache.org/docs/latest/streaming-kafka-integration.html" target="_blank" rel="noopener">Spark Streaming 从 Kafka 读取方式有两种</a>：</p><ul><li>基于 <code>Receiver</code> 的<ul><li>这种是将 Kafka Consumer 的偏移管理交给 Kafka —— 将存在 ZooKeeper 里，失效后由 Kafka 去基于 offset 进行重放</li><li>这样可能的问题是，Kafka 将同一个 offset 的数据，重放给两个 batch 实例 —— 从而只能保证 at least once 的语义</li></ul></li><li>Direct 方式，不基于 <code>Receiver</code><ul><li>由 Spark Streaming 直接管理 offset —— 可以给定 offset 范围，直接去 Kafka 的硬盘上读数据，使用 Spark Streaming 自身的均衡来代替 Kafka 做的均衡</li><li>这样可以保证，每个 offset 范围属于且只属于一个 batch，从而保证 exactly-once</li></ul></li></ul><p>这里我们以 Direct 方式为例，详解一下 Spark Streaming 在源头数据实效后，是如果从上游重放数据的。</p><p>这里的实现分为两个层面：</p><ul><li><code>DirectKafkaInputDStream</code>：负责侦测最新 offset，并将 offset 分配至唯一个 batch<ul><li>会在每次 batch 生成时，依靠 <code>latestLeaderOffsets()</code> 方法去侦测最新的 offset</li><li>然后与上一个 batch 侦测到的 offset 相减，就能得到一个 offset 的范围 <code>offsetRange</code></li><li>把这个 offset 范围内的数据，唯一分配到本 batch 来处理</li></ul></li><li><code>KafkaRDD</code>：负责去读指定 offset 范围内的数据，并基于此数据进行计算<ul><li>会生成一个 Kafka 的 <code>SimpleConsumer</code> —— <code>SimpleConsumer</code> 是 Kafka 最底层、直接对着 Kafka 硬盘上的文件读数据的类</li><li>如果 <code>Task</code> 失败，导致任务重新下发，那么 offset 范围仍然维持不变，将直接重新生成一个 Kafka 的 <code>SimpleConsumer</code> 去读数据</li></ul></li></ul><p>所以看 Direct 的方式，归根结底是由 Spark Streaming 框架来负责整个 offset 的侦测、batch 分配、实际读取数据；并且这些分 batch 的信息都是 checkpoint 到可靠存储（一般是 HDFS）了。这就没有用到 Kafka 使用 ZooKeeper 来均衡 consumer 和记录 offset 的功能，而是把 Kafka 直接当成一个底层的文件系统来使用了。</p><p>当然，我们讲上游重放并不只局限于 Kafka，而是说凡是支持消息重放的上游都可以 —— 比如，HDFS 也可以看做一个支持重放的可靠上游 —— FileInputDStream 就是利用重放的方式，保证了 executor 失效后的源头数据的可读性。</p><h2 id="4-忽略"><a href="#4-忽略" class="headerlink" title="(4) 忽略"></a>(4) 忽略</h2><p>最后，如果应用的实时性需求大于准确性，那么一块数据丢失后我们也可以选择忽略、不恢复失效的源头数据。</p><p>假设我们有 r1, r2, r3 这三个 <code>Receiver</code>，而且每 5 秒产生一个 Block，每 15 秒产生一个 batch。那么，每个 batch 有 <code>15 s ÷ 5 block/s/receiver × 3 receiver = 9 block</code>。现在假设 r1 失效，随之也丢失了 3 个 block。</p><p>那么上层应用如何进行忽略？有两种粒度的做法。</p><h3 id="粗粒度忽略"><a href="#粗粒度忽略" class="headerlink" title="粗粒度忽略"></a>粗粒度忽略</h3><p>粗粒度的做法是，如果计算任务试图读取丢失的源头数据时出错，会导致部分 task 计算失败，会进一步导致整个 batch 的 job 失败，最终在 driver 端以 <code>SparkException</code> 的形式报出来 —— 此时我们 catch 住这个 <code>SparkException</code>，就能够屏蔽这个 batch 的 job 失败了。</p><p>粗粒度的这个做法实现起来非常简单，问题是会忽略掉整个 batch 的计算结果。虽然我们还有 6 个 block 是好的，但所有 9 个的数据都会被忽略。</p><h3 id="细粒度忽略"><a href="#细粒度忽略" class="headerlink" title="细粒度忽略"></a>细粒度忽略</h3><p>细粒度的做法是，只将忽略部分局限在丢失的 3 个 block 上，其它部分 6 部分继续保留。目前原生的 Spark Streaming 还不能完全做到，但我们对 Spark Streaming 稍作修改，就可以做到了。</p><p>细粒度基本思路是，在一个计算的 task 发现作为源数据的 block 失效后，不是直接报错，而是另外生成一个空集合作为“修正”了的源头数据，然后继续 task 的计算，并将成功。</p><p>如此一来，仅局限在发生数据丢失的 3 个块数据才会进行“忽略”的过程，6 个好的块数据将正常进行计算。最后整个 job 是成功的。</p><p>当然这里对 Spark Streaming 本身的改动，还需要考虑一些细节，比如只在 Spark Streaming 里生效、不要影响到 Spark Core、SparkSQL，再比如 task 通常都是会失效重试的，我们希望前几次现场重试，只在最后一次重试仍不成功的时候再进行忽略。</p><p>我们把修改的代码，以及使用方法放在这里了，请随用随取。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>我们上面分四个小节介绍了 Spark Streaming 对源头数据的高可用的保障方式，我们用一个表格来总结一下：</p><table><br><tr><br>    <td></td><br>    <td>图示</td><br>    <td>优点</td><br>    <td>缺点</td><br></tr><br><tr><br>    <td>(1) 热备</td><br>    <td><img src="0.imgs/075a.png"></td><br>    <td>无 recover time</td><br>    <td>需要占用双倍资源</td><br></tr><br><tr><br>    <td>(2) 冷备</td><br>    <td><img src="0.imgs/075b.png"></td><br>    <td>十分可靠</td><br>    <td>存在 recover time</td><br></tr><br><tr><br>    <td>(3) 重放</td><br>    <td><img src="0.imgs/075c.png"></td><br>    <td>不占用额外资源</td><br>    <td>存在 recover time</td><br></tr><br><tr><br>    <td>(4) 忽略</td><br>    <td><img src="0.imgs/075d.png"></td><br>    <td>无 recover time</td><br>    <td>准确性有损失</td><br></tr><br></table><p><br><br><br></p><p>（本文完，参与本文的讨论请 <a href="https://github.com/proflin/CoolplaySpark/issues/11" target="_blank" rel="noopener">猛戳这里</a>，返回目录请 <a href="readme.md">猛戳这里</a>）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Executor-端长时容错详解&quot;&gt;&lt;a href=&quot;#Executor-端长时容错详解&quot; class=&quot;headerlink&quot; title=&quot;Executor 端长时容错详解&quot;&gt;&lt;/a&gt;Executor 端长时容错详解&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;[酷
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97/3.3%20ReceiverTraker,%20ReceivedBlockTracker%20%E8%AF%A6%E8%A7%A3/"/>
    <id>http://yoursite.com/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/3.3 ReceiverTraker, ReceivedBlockTracker 详解/</id>
    <published>2018-02-09T03:49:13.930Z</published>
    <updated>2018-02-09T03:48:41.428Z</updated>
    
    <content type="html"><![CDATA[<h1 id="ReceiverTraker-ReceivedBlockTracker-详解"><a href="#ReceiverTraker-ReceivedBlockTracker-详解" class="headerlink" title="ReceiverTraker, ReceivedBlockTracker 详解"></a>ReceiverTraker, ReceivedBlockTracker 详解</h1><p><strong><em>[酷玩 Spark] Spark Streaming 源码解析系列</em></strong> ，返回目录请 <a href="readme.md">猛戳这里</a></p><p><a href="http://e.qq.com" target="_blank" rel="noopener">「腾讯·广点通」</a>技术团队荣誉出品</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">本系列内容适用范围：</span><br><span class="line"></span><br><span class="line">* 2017.07.11 update, Spark 2.2 全系列 √ (已发布：2.2.0)</span><br><span class="line">* 2017.10.02 update, Spark 2.1 全系列 √ (已发布：2.1.0, 2.1.1, 2.1.2)</span><br><span class="line">* 2016.11.14 update, Spark 2.0 全系列 √ (已发布：2.0.0, 2.0.1, 2.0.2)</span><br></pre></td></tr></table></figure><p><br><br><br></p><p>阅读本文前，请一定先阅读 <a href="0.1 Spark Streaming 实现思路与模块概述.md">Spark Streaming 实现思路与模块概述</a> 一文，其中概述了 Spark Streaming 的 4 大模块的基本作用，有了全局概念后再看本文对 <code>模块 3：数据产生与导入</code> 细节的解释。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>我们在 <a href="0.1 Spark Streaming 实现思路与模块概述.md">Spark Streaming 实现思路与模块概述</a> 给出了 <code>模块 3：数据产生与导入</code> 的基本工作流程：</p><ul><li><p>(1) 由 <code>Receiver</code> 的总指挥 <code>ReceiverTracker</code> 分发多个 job（每个 job 有 1 个 task），到多个 executor 上分别启动 <code>ReceiverSupervisor</code> 实例；</p></li><li><p>(2) 每个 <code>ReceiverSupervisor</code> 启动后将马上生成一个用户提供的 <code>Receiver</code> 实现的实例 —— 该 <code>Receiver</code> 实现可以持续产生或者持续接收系统外数据，比如 <code>TwitterReceiver</code> 可以实时爬取 twitter 数据 —— 并在 <code>Receiver</code> 实例生成后调用 <code>Receiver.onStart()</code>。</p></li></ul><p><img src="0.imgs/060.png" alt="image"></p><p>(1)(2) 的过程由上图所示，这时 <code>Receiver</code> 启动工作已运行完毕。</p><p>接下来 <code>ReceiverSupervisor</code> 将在 executor 端作为的主要角色，并且：</p><ul><li><p>(3) <code>Receiver</code> 在 <code>onStart()</code> 启动后，就将<strong>持续不断</strong>地接收外界数据，并持续交给 <code>ReceiverSupervisor</code> 进行数据转储；</p></li><li><p>(4) <code>ReceiverSupervisor</code> <strong>持续不断</strong>地接收到 <code>Receiver</code> 转来的数据：</p><ul><li>如果数据很细小，就需要 <code>BlockGenerator</code> 攒多条数据成一块(4a)、然后再成块存储(4b 或 4c)</li><li><p>反之就不用攒，直接成块存储(4b 或 4c)</p></li><li><p>这里 Spark Streaming 目前支持两种成块存储方式，一种是由 <code>blockManagerskManagerBasedBlockHandler</code> 直接存到 executor 的内存或硬盘，另一种由 <code>WriteAheadLogBasedBlockHandler</code> 是同时写 WAL(4c) 和 executor 的内存或硬盘</p></li></ul></li><li><p>(5) 每次成块在 executor 存储完毕后，<code>ReceiverSupervisor</code> 就会及时上报块数据的 meta 信息给 driver 端的 <code>ReceiverTracker</code>；这里的 meta 信息包括数据的标识 id，数据的位置，数据的条数，数据的大小等信息。</p></li><li><p>(6) <code>ReceiverTracker</code> 再将收到的块数据 meta 信息直接转给自己的成员 <code>ReceivedBlockTracker</code>，由 <code>ReceivedBlockTracker</code> 专门管理收到的块数据 meta 信息。</p></li></ul><p><img src="0.imgs/065.png" alt="image"></p><p>这里 (3)(4)(5)(6) 的过程是一直<strong>持续不断</strong>地发生的，我们也将其在上图里标识出来。</p><p>上面的内容我们已经在 <a href="3.1 Receiver 分发详解.md">Receiver 分发详解</a> 和 <a href="3.2 Receiver, ReceiverSupervisor, BlockGenerator, ReceivedBlockHandler 详解.md">Receiver, ReceiverSupervisor, BlockGenerator, ReceivedBlockHandler 详解</a> 中介绍过了。</p><p>本文我们详解的是 driver 端的 <code>ReceiverTracker</code> 和 <code>ReceivedBlockTracker</code></p><pre><code>ReceiverTracker      的全限定名是：org.apache.spark.streaming.scheduler.ReceiverTrackerReceivedBlockTracker 的全限定名是：org.apache.spark.streaming.scheduler.ReceivedBlockTracker</code></pre><h2 id="ReceiverTracker-详解"><a href="#ReceiverTracker-详解" class="headerlink" title="ReceiverTracker 详解"></a>ReceiverTracker 详解</h2><p><code>ReceiverTracker</code> 在 Spark 1.5.0 版本里的代码变动比较大，不过其主要功能还是没怎么改变，我们一一来看：</p><ul><li>(1) <code>ReceiverTracker</code> 分发和监控 <code>Receiver</code><ul><li><code>ReceiverTracker</code> 负责 <code>Receiver</code> 在各个 executor 上的分发</li><li>包括 <code>Receiver</code> 的失败重启</li></ul></li><li>(2) <code>ReceiverTracker</code> 作为 <code>RpcEndpoint</code><ul><li><code>ReceiverTracker</code> 作为 <code>Receiver</code> 的管理者，是各个 <code>Receiver</code> 上报信息的入口</li><li>也是 driver 下达管理命令到 <code>Receiver</code> 的出口</li></ul></li><li>(3) <code>ReceiverTracker</code> 管理已上报的块数据 meta 信息</li></ul><p>整体来看，<code>ReceiverTracker</code> 就是 <code>Receiver</code> 相关信息的中枢。</p><h3 id="1-ReceiverTracker-分发和监控-Receiver"><a href="#1-ReceiverTracker-分发和监控-Receiver" class="headerlink" title="(1) ReceiverTracker 分发和监控 Receiver"></a>(1) ReceiverTracker 分发和监控 Receiver</h3><p><code>ReceiverTracker</code> 分发和监控 <code>Receiver</code> 的内容我们已经在 <a href="3.1 Receiver 分发详解.md">Receiver 分发详解.md</a> 详解过了，我们这里总结一下。</p><p>在 <code>ssc.start()</code> 时，将隐含地调用 <code>ReceiverTracker.start()</code>；而 <code>ReceiverTracker.start()</code> 最重要的任务就是调用自己的 <code>launchReceivers()</code> 方法将 <code>Receiver</code> 分发到多个 executor 上去。然后在每个 executor 上，由 <code>ReceiverSupervisor</code> 来分别启动一个 <code>Receiver</code> 接收数据。这个过程用下图表示：</p><p><img src="0.imgs/060.png" alt="image"></p><p>而且在 1.5.0 版本以来引入了 <code>ReceiverSchedulingPolicy</code>，是在 Spark Streaming 层面添加对 <code>Receiver</code> 的分发目的地的计算，相对于之前版本依赖 Spark Core 的 <code>TaskScheduler</code> 进行通用分发，新的 <code>ReceiverSchedulingPolicy</code> 会对 Streaming 应用的更好的语义理解，也能计算出更好的分发策略。</p><p>并且还通过每个 <code>Receiver</code> 对应 <code>1</code> 个 <code>Job</code> 的方式，保证了 <code>Receiver</code> 的多次分发，和失效后的重启、永活。</p><p>从本小节 <code>ReceiverTracker</code> 分发和监控 <code>Receiver</code> 的角度，我们对以前版本的 Spark Streaming(以 1.4.0 为代表)、和新版本的 Spark Streaming(以 1.5.0 为代表)有总结对比：</p><table><br>    <tr><br>        <td align="center"></td><br>        <td align="center"><strong>Spark Streaming 1.4.0</strong></td><br>        <td align="center"><strong>Spark Streaming 1.5.0</strong></td><br>    </tr><br>    <tr><br>        <td align="center"><strong>Receiver 活性</strong></td><br>        <td align="center">不保证永活</td><br>        <td align="center">无限重试、保证永活</td><br>    </tr><br>    <tr><br>        <td align="center"><strong>Receiver 均衡分发</strong></td><br>        <td align="center">无保证</td><br>        <td align="center">round-robin 策略</td><br>    </tr><br>    <tr><br>        <td align="center"><strong>自定义 Receiver 分发</strong></td><br>        <td align="center">很 tricky</td><br>        <td align="center">方便</td><br>    </tr><br></table><h3 id="2-ReceiverTracker-作为-RpcEndpoint"><a href="#2-ReceiverTracker-作为-RpcEndpoint" class="headerlink" title="(2) ReceiverTracker 作为 RpcEndpoint"></a>(2) ReceiverTracker 作为 RpcEndpoint</h3><p><code>RpcEndPoint</code> 可以理解为 RPC 的 server 端，供 client 调用。</p><p><code>ReceiverTracker</code> 作为 <code>RpcEndPoint</code> 的地址 —— 即 driver 的地址 —— 是公开的，可供 <code>Receiver</code> 连接；如果某个 <code>Receiver</code> 连接成功，那么 <code>ReceiverTracker</code> 也就持有了这个 <code>Receiver</code> 的 <code>RpcEndPoint</code>。这样以来，通过发送消息，就可以实现双向通信。</p><p>1.5.0 版本以来，<code>ReceiverTracker</code> 支持的消息有 10 种，我们进行一个总结：</p><table><br>    <tr><br>        <td>StopAllReceivers 消息</td><br>        <td>消息</td><br>        <td>解释</td><br>    </tr><br>    <tr><br>        <td rowspan="5">ReceiverTracker<br>只接收、不回复</td><br>        <td>StartAllReceivers 消息</td><br>        <td>在 ReceiverTracker 刚启动时，发给自己这个消息，触发具体的 schedulingPolicy 计算，和后续分发</td><br>    </tr><br>    <tr><br>        <td>RestartReceiver 消息</td><br>        <td>当初始分发的 executor 不对，或者 Receiver 失效等情况出现，发给自己这个消息，触发 Receiver 重新分发</td><br>    </tr><br>    <tr><br>        <td>CleanupOldBlocks 消息</td><br>        <td>当块数据已完成计算不再需要时，发给自己这个消息，将给所有的 Receiver 转发此 CleanupOldBlocks 消息</td><br>    </tr><br>    <tr><br>        <td>UpdateReceiverRateLimit 消息</td><br>        <td>ReceiverTracker 动态计算出某个 Receiver 新的 rate limit，将给具体的 Receiver 发送 UpdateRateLimit 消息</td><br>    </tr><br>    <tr><br>        <td>ReportError 消息</td><br>        <td>是由 Receiver 上报上来的，将触发 reportError() 方法向 listenerBus 扩散此 error 消息 </td><br>    </tr><br>    <tr><br>        <td rowspan="5">ReceiverTracker<br>接收并回复</td><br>        <td>RegisterReceiver 消息</td><br>        <td>由 Receiver 在试图启动的过程中发来，将回复允许启动，或不允许启动</td><br>    </tr><br>    <tr><br>        <td>AddBlock 消息</td><br>        <td>具体的块数据 meta 上报消息，由 Receiver 发来，将返回成功或失败</td><br>    </tr><br>    <tr><br>        <td>DeregisterReceiver 消息</td><br>        <td>由 Receiver 发来，处理后，无论如何都返回 true</td><br>    </tr><br>    <tr><br>        <td>AllReceiverIds 消息</td><br>        <td>在 ReceiverTracker stop() 的过程中，查询是否还有活跃的 Receiver</td><br>    </tr><br>    <tr><br>        <td>StopAllReceivers 消息</td><br>        <td>在 ReceiverTracker stop() 的过程刚开始时，要求 stop 所有的 Receiver；将向所有的 Receiver 发送 stop 信息</td><br>    </tr><br></table><h3 id="3-ReceiverTracker-管理块数据的-meta-信息"><a href="#3-ReceiverTracker-管理块数据的-meta-信息" class="headerlink" title="(3) ReceiverTracker 管理块数据的 meta 信息"></a>(3) ReceiverTracker 管理块数据的 meta 信息</h3><p>一方面 <code>Receiver</code> 将通过 <code>AddBlock</code> 消息上报 meta 信息给 <code>ReceiverTracker</code>，另一方面 <code>JobGenerator</code> 将在每个 batch 开始时要求 <code>ReceiverTracker</code> 将已上报的块信息进行 batch 划分，<code>ReceiverTracker</code> 完整了块数据的 meta 信息管理工作。</p><p>具体的，<code>ReceiverTracker</code> 有一个成员 <code>ReceivedBlockTracker</code>，专门负责已上报的块数据 meta 信息管理。</p><h2 id="ReceivedBlockTracker-详解"><a href="#ReceivedBlockTracker-详解" class="headerlink" title="ReceivedBlockTracker 详解"></a>ReceivedBlockTracker 详解</h2><p>我们刚刚将，<code>ReceivedBlockTracker</code> 专门负责已上报的块数据 meta 信息管理，但 <code>ReceivedBlockTracker</code> 本身不负责对外交互，一切都是通过 <code>ReceiverTracker</code> 来转发 —— 这里 <code>ReceiverTracker</code> 相当于是 <code>ReceivedBlockTracker</code> 的门面（可参考 <a href="http://www.cnblogs.com/zhenyulu/articles/55992.html" target="_blank" rel="noopener">门面模式</a>）。</p><p>在 <code>ReceivedBlockTracker</code> 内部，有几个重要的成员，它们的关系如下：</p><p><img src="3.imgs/070.png" alt="image"> <em>//TODO(lwlin): 此图风格与本系列文章不符，需要美化</em></p><ul><li><code>streamIdToUnallocatedBlockQueues</code><ul><li>维护了上报上来的、但尚未分配入 batch 的 <code>Block</code> 块数据的 meta</li><li>为每个 <code>Receiver</code> 单独维护一个 queue，所以是一个 <code>HashMap：receiverId → mutable.Queue[ReceivedBlockInfo]</code></li></ul></li><li><code>timeToAllocatedBlocks</code><ul><li>维护了上报上来的、已分配入 batch 的 <code>Block</code> 块数据的 meta</li><li>按照 batch 进行一级索引、再按照 <code>receiverId</code> 进行二级索引的 queue，所以是一个 <code>HashMap: time → HashMap</code></li></ul></li><li><code>lastAllocatedBatchTime</code><ul><li>记录了最近一个分配完成的 batch 是哪个</li></ul></li></ul><p>上面是用于状态记录的主要数据结构。对这些状态存取主要是 4 个方法：</p><ul><li><code>addBlock(receivedBlockInfo: ReceivedBlockInfo)</code><ul><li>收到某个 <code>Receiver</code> 上报上来的块数据 meta 信息，将其加入到 <code>streamIdToUnallocatedBlockQueues</code> 里</li></ul></li><li><code>allocateBlocksToBatch(batchTime: Time)</code><ul><li>主要是 <code>JobGenerator</code> 在发起新 batch 的计算时，第一步就调用本方法</li><li>是将 <code>streamIdToUnallocatedBlockQueues</code> 的内容，以传入的 <code>batchTime</code> 参数为 key，添加到 <code>timeToAllocatedBlocks</code> 里</li><li>并更新 <code>lastAllocatedBatchTime</code></li></ul></li><li><code>getBlocksOfBatch(batchTime: Time)</code><ul><li>主要是 <code>JobGenerator</code> 在发起新 batch 的计算时，由 <code>DStreamGraph</code> 生成 RDD DAG 实例时，将调用本方法</li><li>调用本方法查 <code>timeToAllocatedBlocks</code>，获得划入本 batch 的块数据元信息，由此生成处理对应块数据的 RDD</li></ul></li><li><code>cleanupOldBatches(cleanupThreshTime: Time, ...)</code><ul><li>主要是当一个 batch 已经计算完成、可以把已追踪的块数据的 meta 信息清理掉时调用</li><li>将清理 <code>timeToAllocatedBlocks</code> 表里对应 <code>cleanupThreshTime</code> 之前的所有 batch 块数据 meta 信息</li></ul></li></ul><p>这 4 个方法，和对应信息状态的修改关系如下图总结：</p><p><img src="3.imgs/075.png" alt="image"> <em>//TODO(lwlin): 此图风格与本系列文章不符，需要美化</em></p><p>上面即是 <code>ReceivedBlockTracker</code> 的主体内容。</p><p>但我们还需要强调一点非常重要的内容，即 <code>ReceivedBlockTracker</code> 需要对 driver 进行容错保障。也就是，如果 driver 失效，新起来的 driver 必须能够通过 WAL 恢复出失效前的  <code>ReceivedBlockTracker</code> 状态，具体的就需要包括 <code>streamIdToUnallocatedBlockQueues</code>, <code>timeToAllocatedBlocks</code>, <code>lastAllocatedBatchTime</code> 等内容，也即需要前面讲的 4 个方法在修改 <code>ReceivedBlockTracker</code> 的状态信息的时候，要首先写入 WAL，才能在失效后从 WAL 恢复出相关信息。</p><p>有关 WAL 写入和故障恢复的内容，我们将在 <code>模块 4：长时容错</code> 里系统性的详解。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文主要详解了 driver 端的 <code>Receiver</code> 管理者 —— <code>ReceiverTracker</code> —— 的主要功能：</p><ul><li>(1) <code>ReceiverTracker</code> 分发和监控 <code>Receiver</code><ul><li><code>ReceiverTracker</code> 负责 <code>Receiver</code> 在各个 executor 上的分发</li><li>包括 <code>Receiver</code> 的失败重启</li></ul></li><li>(2) <code>ReceiverTracker</code> 作为 <code>RpcEndpoint</code><ul><li><code>ReceiverTracker</code> 作为 <code>Receiver</code> 的管理者，是各个 <code>Receiver</code> 上报信息的入口</li><li>也是 driver 下达管理命令到 <code>Receiver</code> 的出口</li></ul></li><li>(3) <code>ReceiverTracker</code> 管理已上报的块数据 meta 信息<ul><li>委托给自己的成员 <code>ReceivedBlockManager</code> 进行具体管理</li></ul></li></ul><p><br><br><br></p><p>（本文完，参与本文的讨论请 <a href="https://github.com/proflin/CoolplaySpark/issues/8" target="_blank" rel="noopener">猛戳这里</a>，返回目录请 <a href="readme.md">猛戳这里</a>）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;ReceiverTraker-ReceivedBlockTracker-详解&quot;&gt;&lt;a href=&quot;#ReceiverTraker-ReceivedBlockTracker-详解&quot; class=&quot;headerlink&quot; title=&quot;ReceiverTraker, 
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97/3.2%20Receiver,%20ReceiverSupervisor,%20BlockGenerator,%20ReceivedBlockHandler%20%E8%AF%A6%E8%A7%A3/"/>
    <id>http://yoursite.com/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/3.2 Receiver, ReceiverSupervisor, BlockGenerator, ReceivedBlockHandler 详解/</id>
    <published>2018-02-09T03:49:13.923Z</published>
    <updated>2018-02-09T03:48:41.427Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Receiver-ReceiverSupervisor-BlockGenerator-ReceivedBlockHandler-详解"><a href="#Receiver-ReceiverSupervisor-BlockGenerator-ReceivedBlockHandler-详解" class="headerlink" title="Receiver, ReceiverSupervisor, BlockGenerator, ReceivedBlockHandler 详解"></a>Receiver, ReceiverSupervisor, BlockGenerator, ReceivedBlockHandler 详解</h1><p><strong><em>[酷玩 Spark] Spark Streaming 源码解析系列</em></strong> ，返回目录请 <a href="readme.md">猛戳这里</a></p><p><a href="http://e.qq.com" target="_blank" rel="noopener">「腾讯·广点通」</a>技术团队荣誉出品</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">本系列内容适用范围：</span><br><span class="line"></span><br><span class="line">* 2017.07.11 update, Spark 2.2 全系列 √ (已发布：2.2.0)</span><br><span class="line">* 2017.10.02 update, Spark 2.1 全系列 √ (已发布：2.1.0, 2.1.1, 2.1.2)</span><br><span class="line">* 2016.11.14 update, Spark 2.0 全系列 √ (已发布：2.0.0, 2.0.1, 2.0.2)</span><br></pre></td></tr></table></figure><p><br><br><br></p><p>阅读本文前，请一定先阅读 <a href="0.1 Spark Streaming 实现思路与模块概述.md">Spark Streaming 实现思路与模块概述</a> 一文，其中概述了 Spark Streaming 的 4 大模块的基本作用，有了全局概念后再看本文对 <code>模块 3：数据产生与导入</code> 细节的解释。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>我们在前面 <a href="0.1 Spark Streaming 实现思路与模块概述.md">Spark Streaming 实现思路与模块概述</a> 中分析过，Spark Streaming 在程序刚开始运行时：</p><ul><li><p>(1) 由 <code>Receiver</code> 的总指挥 <code>ReceiverTracker</code> 分发多个 job（每个 job 有 1 个 task），到多个 executor 上分别启动 <code>ReceiverSupervisor</code> 实例；</p></li><li><p>(2) 每个 <code>ReceiverSupervisor</code> 启动后将马上生成一个用户提供的 <code>Receiver</code> 实现的实例 —— 该 <code>Receiver</code> 实现可以持续产生或者持续接收系统外数据，比如 <code>TwitterReceiver</code> 可以实时爬取 twitter 数据 —— 并在 <code>Receiver</code> 实例生成后调用 <code>Receiver.onStart()</code>。</p></li></ul><p><img src="0.imgs/060.png" alt="image"></p><pre><code>ReceiverSupervisor 的全限定名是：org.apache.spark.streaming.receiver.ReceiverSupervisorReceiver           的全限定名是：org.apache.spark.streaming.receiver.Receiver</code></pre><p>(1)(2) 的过程由上图所示，这时 <code>Receiver</code> 启动工作已运行完毕。</p><p>接下来 <code>ReceiverSupervisor</code> 将在 executor 端作为的主要角色，并且：</p><ul><li><p>(3) <code>Receiver</code> 在 <code>onStart()</code> 启动后，就将<strong>持续不断</strong>地接收外界数据，并持续交给 <code>ReceiverSupervisor</code> 进行数据转储；</p></li><li><p>(4) <code>ReceiverSupervisor</code> <strong>持续不断</strong>地接收到 <code>Receiver</code> 转来的数据：</p><ul><li>如果数据很细小，就需要 <code>BlockGenerator</code> 攒多条数据成一块(4a)、然后再成块存储(4b 或 4c)</li><li><p>反之就不用攒，直接成块存储(4b 或 4c)</p></li><li><p>这里 Spark Streaming 目前支持两种成块存储方式，一种是由 <code>blockManagerskManagerBasedBlockHandler</code> 直接存到 executor 的内存或硬盘，另一种由 <code>WriteAheadLogBasedBlockHandler</code> 是同时写 WAL(4c) 和 executor 的内存或硬盘</p></li></ul></li><li><p>(5) 每次成块在 executor 存储完毕后，<code>ReceiverSupervisor</code> 就会及时上报块数据的 meta 信息给 driver 端的 <code>ReceiverTracker</code>；这里的 meta 信息包括数据的标识 id，数据的位置，数据的条数，数据的大小等信息。</p></li><li><p>(6) <code>ReceiverTracker</code> 再将收到的块数据 meta 信息直接转给自己的成员 <code>ReceivedBlockTracker</code>，由 <code>ReceivedBlockTracker</code> 专门管理收到的块数据 meta 信息。</p></li></ul><p><img src="0.imgs/065.png" alt="image"></p><pre><code>BlockGenerator                 的全限定名是：org.apache.spark.streaming.receiver.BlockGeneratorBlockManagerBasedBlockHandler  的全限定名是：org.apache.spark.streaming.receiver.BlockManagerBasedBlockHandlerWriteAheadLogBasedBlockHandler 的全限定名是：org.apache.spark.streaming.receiver.WriteAheadLogBasedBlockHandlerReceivedBlockTracker           的全限定名是：org.apache.spark.streaming.scheduler.ReceivedBlockTrackerReceiverInputDStream           的全限定名是：org.apache.spark.streaming.dstream.ReceiverInputDStream</code></pre><p>这里 (3)(4)(5)(6) 的过程是一直<strong>持续不断</strong>地发生的，我们也将其在上图里标识出来。</p><p>后续在 driver 端，就由 <code>ReceiverInputDStream</code> 在每个 batch 去检查 <code>ReceiverTracker</code> 收到的块数据 meta 信息，界定哪些新数据需要在本 batch 内处理，然后生成相应的 <code>RDD</code> 实例去处理这些块数据。</p><p>下面我们来详解 Receiver, ReceiverSupervisor, BlockGenerator 这三个类。</p><h2 id="Receiver-详解"><a href="#Receiver-详解" class="headerlink" title="Receiver 详解"></a>Receiver 详解</h2><p><code>Receiver</code> 是一个 abstract 的基类：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 Receiver</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Receiver</span>[<span class="type">T</span>](<span class="params">val storageLevel: <span class="type">StorageLevel</span></span>) <span class="keyword">extends</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 需要子类实现</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">onStart</span></span>()</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">onStop</span></span>()</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 基类实现，供子类调用</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">store</span></span>(dataItem: <span class="type">T</span>) &#123;...&#125;                  <span class="comment">// 【存储单条小数据】</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">store</span></span>(dataBuffer: <span class="type">ArrayBuffer</span>[<span class="type">T</span>]) &#123;...&#125;   <span class="comment">// 【存储数组形式的块数据】</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">store</span></span>(dataIterator: <span class="type">Iterator</span>[<span class="type">T</span>]) &#123;...&#125;    <span class="comment">// 【存储 iterator 形式的块数据】</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">store</span></span>(bytes: <span class="type">ByteBuffer</span>) &#123;...&#125;            <span class="comment">// 【存储 ByteBuffer 形式的块数据】</span></span><br><span class="line">  </span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里需要 <code>Receiver</code> 子类具体实现的是，<code>onStart()</code> 和 <code>onStop()</code> 方法。<code>onStart()</code> 是在 executor 端被 <code>ReceiverSupervisor</code> 调用的，而且 <code>onStart()</code> 的实现应该很快就能返回，不要写成阻塞式的。</p><p>比如，Spark Streaming 自带的 <code>SocketReceiver</code> 的 <code>onStart()</code> 实现如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 SocketReceiver</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">onStart</span></span>() &#123;</span><br><span class="line">  <span class="keyword">new</span> <span class="type">Thread</span>(<span class="string">"Socket Receiver"</span>) &#123;</span><br><span class="line">    setDaemon(<span class="literal">true</span>)</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123; receive() &#125;</span><br><span class="line">  &#125;.start()  <span class="comment">// 【仅新拉起了一个线程来接收数据】</span></span><br><span class="line">  <span class="comment">// 【onStart() 方法很快就返回了】</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>另外的 <code>onStop()</code> 实现，就是在 <code>Receiver</code> 被关闭时调用了，可以做一些 close 工作。</p><p>我们看当 <code>Receiver</code> 真正启动起来后，可以开始产生或者接收数据了，那接收到的数据该怎么存到 Spark Streaming 里？</p><p>答案很简单，就是直接调用 <code>store()</code> 方法即可。<code>Receiver</code> 基类提供了 4 种签名的 <code>store()</code> 方法，分别可用于存储：</p><ul><li>(a) 单条小数据</li><li>(b) 数组形式的块数据</li><li>(c) iterator 形式的块数据</li><li>(d) ByteBuffer 形式的块数据</li></ul><p>这 4 种签名的 <code>store()</code> 的实现都是直接将数据转给 <code>ReceiverSupervisor</code>，由 <code>ReceiverSupervisor</code> 来具体负责存储。</p><p>所以，一个具体的 <code>Receiver</code> 子类实现，只要在 <code>onStart()</code> 里新拉起数据接收线程，并在接收到数据时 <code>store()</code> 到 Spark Streamimg 框架就可以了。</p><h2 id="ReceiverSupervisor-详解"><a href="#ReceiverSupervisor-详解" class="headerlink" title="ReceiverSupervisor 详解"></a>ReceiverSupervisor 详解</h2><p>我们在 <a href="3.1 Receiver 分发详解.md">Receiver 分发详解</a> 里分析过，在 executor 端，分发 <code>Receiver</code> 的 <code>Job</code> 的 <code>Task</code> 执行的实现是：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">(iterator: <span class="type">Iterator</span>[<span class="type">Receiver</span>[_]]) =&gt; &#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">val</span> receiver = iterator.next()</span><br><span class="line">  assert(iterator.hasNext == <span class="literal">false</span>)</span><br><span class="line">  <span class="comment">// 【ReceiverSupervisor 的具体实现 ReceiverSupervisorImpl】</span></span><br><span class="line">  <span class="keyword">val</span> supervisor = <span class="keyword">new</span> <span class="type">ReceiverSupervisorImpl</span>(receiver, ...)</span><br><span class="line">  supervisor.start()</span><br><span class="line">  supervisor.awaitTermination()</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>ReceiverSupervisor</code> 定义了一些方法接口，其具体的实现类是 <code>ReceiverSupervisorImpl</code>。</p><p>我们看到在上面的代码中，executor 端会先 <code>new</code> 一个 <code>ReceiverSupervisorImpl</code>，然后 <code>ReceiverSupervisorImpl.start()</code>。这里 <code>.start()</code> 很重要的工作就是调用 <code>Receiver.onStart()</code>，来启动 <code>Receiver</code> 的数据接收线程：</p><p><img src="3.imgs/050.png" alt="image"></p><p><code>start()</code> 成功后，<code>ReceiverSurpervisorImpl</code> 最重要的工作就是接收 <code>Receiver</code> 给 <code>store()</code> 过来的数据了。</p><p><code>ReceiverSurpervisorImpl</code> 有 4 种签名的 <code>push()</code> 方法，被 <code>Receiver</code> 的 4 种 <code>store()</code> 一一调用。不过接下来对单条小数据和三种块数据的处理稍有区别。</p><p>单条的情况，<code>ReceiverSupervisorImpl</code> 要在 <code>BlockGenerator</code> 的协助下，将多个单条的数据积攒为一个块数据，然后重新调用 <code>push</code> 交给 <code>ReceiverSurpervisorImpl</code> 来处理这个块数据。我们一会再详解 <code>BlockGenerator</code> 的这个过程。</p><p>所以接下来，我们主要看这 3 个存储块数据的 <code>push...()</code> 方法，它们的实现非常简单：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 ReceiverSupervisorImpl</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pushArrayBuffer</span></span>(arrayBuffer: <span class="type">ArrayBuffer</span>[_], ...) &#123;</span><br><span class="line">  pushAndReportBlock(<span class="type">ArrayBufferBlock</span>(...), ...)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pushIterator</span></span>(iterator: <span class="type">Iterator</span>[_], ...) &#123;</span><br><span class="line">  pushAndReportBlock(<span class="type">IteratorBlock</span>(...), ...)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pushBytes</span></span>(bytes: <span class="type">ByteBuffer</span>, ...)&#123;</span><br><span class="line">  pushAndReportBlock(<span class="type">ByteBufferBlock</span>(...), ...)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pushAndReportBlock</span></span>(receivedBlock: <span class="type">ReceivedBlock</span>, ...) &#123;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>顾名思义，这 3 个存储块数据的 <code>push...()</code> 方法即是将自己的数据统一包装为 <code>ReceivedBlock</code>，然后由 <code>pushAndReportBlock()</code> 做两件事情：</p><ul><li>(a) push：将 <code>ReceivedBlock</code> 交给 <code>ReceivedBlockHandler</code> 来存储，具体的，可以在 <code>ReceivedBlockHandler</code>  的两种存储实现里二选一</li><li>(b) report：将已存储好的 <code>ReceivedBlock</code> 的块数据 meta 信息报告给 <code>ReceiverTracker</code></li></ul><p>上面的过程可以总结为：</p><p><img src="0.imgs/065.png" alt="image"></p><h2 id="ReceivedBlockHandler-详解"><a href="#ReceivedBlockHandler-详解" class="headerlink" title="ReceivedBlockHandler 详解"></a>ReceivedBlockHandler 详解</h2><p><code>ReceivedBlockHandler</code> 是一个接口类，在 executor 端负责对接收到的块数据进行具体的存储和清理：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 ReceivedBlockHandler</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[streaming] <span class="class"><span class="keyword">trait</span> <span class="title">ReceivedBlockHandler</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Store a received block with the given block id and return related metadata */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">storeBlock</span></span>(blockId: <span class="type">StreamBlockId</span>, receivedBlock: <span class="type">ReceivedBlock</span>): <span class="type">ReceivedBlockStoreResult</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Cleanup old blocks older than the given threshold time */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">cleanupOldBlocks</span></span>(threshTime: <span class="type">Long</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>ReceivedBlockHandler</code> 有两个具体的存储策略的实现：</p><ul><li>(a) <code>BlockManagerBasedBlockHandler</code>，是直接存到 executor 的内存或硬盘</li><li>(b) <code>WriteAheadLogBasedBlockHandler</code>，是先写 WAL，再存储到 executor 的内存或硬盘</li></ul><h3 id="a-BlockManagerBasedBlockHandler-实现"><a href="#a-BlockManagerBasedBlockHandler-实现" class="headerlink" title="(a) BlockManagerBasedBlockHandler 实现"></a>(a) BlockManagerBasedBlockHandler 实现</h3><p><code>BlockManagerBasedBlockHandler</code> 主要是直接存储到 Spark Core 里的 <code>BlockManager</code> 里。</p><p><code>BlockManager</code> 将在 executor 端接收 <code>Block</code> 数据，而在 driver 端维护 <code>Block</code> 的 meta 信息。 <code>BlockManager</code> 根据存储者的 <code>StorageLevel</code> 要求来存到本 executor 的 <code>RAM</code> 或者 <code>DISK</code>，也可以同时再额外复制一份到其它 executor 的 <code>RAM</code> 或者 <code>DISK</code>。<a href="http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence" target="_blank" rel="noopener">点这里</a>查看 <code>StorageLevel</code> 支持的所有枚举值。</p><p>下面是 <code>BlockManagerBasedBlockHandler.store()</code> 向 <code>BlockManager</code> 存储 3 种块数据的具体实现：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 BlockManagerBasedBlockHandler</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">storeBlock</span></span>(blockId: <span class="type">StreamBlockId</span>, block: <span class="type">ReceivedBlock</span>): <span class="type">ReceivedBlockStoreResult</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> putResult: <span class="type">Seq</span>[(<span class="type">BlockId</span>, <span class="type">BlockStatus</span>)] = block <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">ArrayBufferBlock</span>(arrayBuffer) =&gt;</span><br><span class="line">      blockManager.putIterator(blockId, arrayBuffer.iterator, ...)   <span class="comment">// 【存储数组到 blockManager 里】</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">IteratorBlock</span>(iterator) =&gt;</span><br><span class="line">      blockManager.putIterator(blockId, countIterator, ...)          <span class="comment">// 【存储 iterator 到 blockManager 里】</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">ByteBufferBlock</span>(byteBuffer) =&gt;</span><br><span class="line">      blockManager.putBytes(blockId, byteBuffer, ...)                <span class="comment">// 【存储 ByteBuffer 到 blockManager 里】</span></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h3 id="b-WriteAheadLogBasedBlockHandler-实现"><a href="#b-WriteAheadLogBasedBlockHandler-实现" class="headerlink" title="(b) WriteAheadLogBasedBlockHandler 实现"></a>(b) WriteAheadLogBasedBlockHandler 实现</h3><p><code>WriteAheadLogBasedBlockHandler</code> 的实现则是同时写到可靠存储的 WAL 中和 executor 的 <code>BlockManager</code> 中；在两者都写完成后，再上报块数据的 meta 信息。</p><p><code>BlockManager</code> 中的块数据是计算时首选使用的，只有在 executor 失效时，才去 WAL 中读取写入过的数据。</p><p>同其它系统的 WAL 一样，数据是完全顺序地写入 WAL 的；在稍后上报块数据的 meta 信息，就额外包含了块数据所在的 WAL 的路径，及在 WAL 文件内的偏移地址和长度。</p><p>具体的写入逻辑如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 WriteAheadLogBasedBlockHandler</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">storeBlock</span></span>(blockId: <span class="type">StreamBlockId</span>, block: <span class="type">ReceivedBlock</span>): <span class="type">ReceivedBlockStoreResult</span> = &#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 【生成向 BlockManager 存储数据的 future】</span></span><br><span class="line">  <span class="keyword">val</span> storeInBlockManagerFuture = <span class="type">Future</span> &#123;</span><br><span class="line">    <span class="keyword">val</span> putResult =</span><br><span class="line">      blockManager.putBytes(blockId, serializedBlock, effectiveStorageLevel, tellMaster = <span class="literal">true</span>)</span><br><span class="line">    <span class="keyword">if</span> (!putResult.map &#123; _._1 &#125;.contains(blockId)) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(</span><br><span class="line">        <span class="string">s"Could not store <span class="subst">$blockId</span> to block manager with storage level <span class="subst">$storageLevel</span>"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 【生成向 WAL 存储数据的 future】</span></span><br><span class="line">  <span class="keyword">val</span> storeInWriteAheadLogFuture = <span class="type">Future</span> &#123;</span><br><span class="line">    writeAheadLog.write(serializedBlock, clock.getTimeMillis())</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 【开始执行两个 future、等待两个 future 都结束】</span></span><br><span class="line">  <span class="keyword">val</span> combinedFuture = storeInBlockManagerFuture.zip(storeInWriteAheadLogFuture).map(_._2)</span><br><span class="line">  <span class="keyword">val</span> walRecordHandle = <span class="type">Await</span>.result(combinedFuture, blockStoreTimeout)</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 【返回存储结果，用于后续的块数据 meta 上报】</span></span><br><span class="line">  <span class="type">WriteAheadLogBasedStoreResult</span>(blockId, numRecords, walRecordHandle)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="BlockGenerator-详解"><a href="#BlockGenerator-详解" class="headerlink" title="BlockGenerator 详解"></a>BlockGenerator 详解</h2><p>最后我们来补充一下 <code>ReceiverSupervisorImpl</code> 在收到单块条小数据后，委托 <code>BlockGenerator</code> 进行积攒，并封装多条小数据为一整个块数据的详细过程。</p><p><code>BlockGenerator</code> 在内部主要是维护一个临时的变长数组 <code>currentBuffer</code>，每收到一条 <code>ReceiverSupervisorImpl</code> 转发来的数据就加入到这个 <code>currentBuffer</code> 数组中。</p><p>这里非常需要注意的地方，就是在加入 <code>currentBuffer</code> 数组时会先由 <code>rateLimiter</code> 检查一下速率，是否加入的频率已经太高。如果太高的话，就需要 block 住，等到下一秒再开始添加。这里的最高频率是由 <code>spark.streaming.receiver.maxRate (default = Long.MaxValue)</code> 控制的，是单个 <code>Receiver</code> 每秒钟允许添加的条数。控制了这个速率，就控制了整个 Spark Streaming 系统每个 batch 需要处理的最大数据量。之前版本的 Spark Streaming 是静态设置了这样的一个上限并由所有 <code>Receiver</code> 统一遵守；但在 1.5.0 以来，Spark Streaming 加入了分别动态控制每个 <code>Receiver</code> 速率的特性，这个我们会单独有一篇文章介绍。</p><p>然后会维护一个定时器，每隔 <code>blockInterval</code> 的时间就生成一个新的空变长数组替换老的数组作为新的 <code>currentBuffer</code> ，并把老的数组加入到一个自己的一个 <code>blocksForPushing</code> 的队列里。</p><p>这个 <code>blocksForPushing</code> 队列实际上是一个 <code>ArrayBlockingQueue</code>，大小由 <code>spark.streaming.blockQueueSize（默认 = 10）</code> 来控制。然后就有另外的一个线程专门从这个队列里取出来已经包装好的块数据，然后调用 <code>ReceiverSupervisorImpl.pushArrayBuffer(...)</code> 来将块数据交回给 <code>ReceiverSupervisorImpl</code>。</p><p><code>BlockGenerator</code> 工作的整个过程示意图如下：</p><p><img src="3.imgs/060.png" alt="image"> <em>//TODO(lwlin): 此图风格与本系列文章不符，需要美化</em></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>总结我们在本文所做的详解 —— <code>ReceiverSupervisor</code> 将在 executor 端作为的主要角色，并且：</p><ul><li><p>(3) <code>Receiver</code> 在 <code>onStart()</code> 启动后，就将<strong>持续不断</strong>地接收外界数据，并持续交给 <code>ReceiverSupervisor</code> 进行数据转储；</p></li><li><p>(4) <code>ReceiverSupervisor</code> <strong>持续不断</strong>地接收到 <code>Receiver</code> 转来的数据：</p><ul><li>如果数据很细小，就需要 <code>BlockGenerator</code> 攒多条数据成一块(4a)、然后再成块存储(4b 或 4c)</li><li><p>反之就不用攒，直接成块存储(4b 或 4c)</p></li><li><p>这里 Spark Streaming 目前支持两种成块存储方式，一种是由 <code>blockManagerskManagerBasedBlockHandler</code> 直接存到 executor 的内存或硬盘，另一种由 <code>WriteAheadLogBasedBlockHandler</code> 是同时写 WAL(4c) 和 executor 的内存或硬盘</p></li></ul></li><li><p>(5) 每次成块在 executor 存储完毕后，<code>ReceiverSupervisor</code> 就会及时上报块数据的 meta 信息给 driver 端的 <code>ReceiverTracker</code>；这里的 meta 信息包括数据的标识 id，数据的位置，数据的条数，数据的大小等信息。</p></li><li><p>(6) <code>ReceiverTracker</code> 再将收到的块数据 meta 信息直接转给自己的成员 <code>ReceivedBlockTracker</code>，由 <code>ReceivedBlockTracker</code> 专门管理收到的块数据 meta 信息。</p></li></ul><p><img src="0.imgs/065.png" alt="image"></p><p><br><br><br></p><p>（本文完，参与本文的讨论请 <a href="https://github.com/proflin/CoolplaySpark/issues/7" target="_blank" rel="noopener">猛戳这里</a>，返回目录请 <a href="readme.md">猛戳这里</a>）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Receiver-ReceiverSupervisor-BlockGenerator-ReceivedBlockHandler-详解&quot;&gt;&lt;a href=&quot;#Receiver-ReceiverSupervisor-BlockGenerator-ReceivedBlo
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97/3.1%20Receiver%20%E5%88%86%E5%8F%91%E8%AF%A6%E8%A7%A3/"/>
    <id>http://yoursite.com/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/3.1 Receiver 分发详解/</id>
    <published>2018-02-09T03:49:13.914Z</published>
    <updated>2018-02-09T03:48:41.427Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Receiver-分发详解"><a href="#Receiver-分发详解" class="headerlink" title="Receiver 分发详解"></a>Receiver 分发详解</h1><p><strong><em>[酷玩 Spark] Spark Streaming 源码解析系列</em></strong> ，返回目录请 <a href="readme.md">猛戳这里</a></p><p><a href="http://e.qq.com" target="_blank" rel="noopener">「腾讯·广点通」</a>技术团队荣誉出品</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">本系列内容适用范围：</span><br><span class="line"></span><br><span class="line">* 2017.07.11 update, Spark 2.2 全系列 √ (已发布：2.2.0)</span><br><span class="line">* 2017.10.02 update, Spark 2.1 全系列 √ (已发布：2.1.0, 2.1.1, 2.1.2)</span><br><span class="line">* 2016.11.14 update, Spark 2.0 全系列 √ (已发布：2.0.0, 2.0.1, 2.0.2)</span><br></pre></td></tr></table></figure><p><br><br><br></p><p>阅读本文前，请一定先阅读 <a href="0.1 Spark Streaming 实现思路与模块概述.md">Spark Streaming 实现思路与模块概述</a> 一文，其中概述了 Spark Streaming 的 4 大模块的基本作用，有了全局概念后再看本文对 <code>模块 3：数据产生与导入</code> 细节的解释。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>我们前面在 <a href="1.1 DStream, DStreamGraph 详解.md">DStream, DStreamGraph 详解</a> 讲到，整个 <code>DStreamGraph</code> 是由 <code>output stream</code> 通过 <em>dependency</em> 引用关系，索引到上游 <code>DStream</code> 节点。而递归的追溯到最上游的 <code>InputDStream</code> 节点时，就没有对其它 <code>DStream</code> 节点的依赖了，因为 <code>InputDStream</code> 节点本身就代表了最原始的数据集。</p><p><img src="1.imgs/035.png" alt="image"></p><p>我们对 <code>模块 3：数据产生与导入</code> 细节的解释，是仅针对 <code>ReceiverInputDStream</code> 及其子类的；其它 <code>InputDStream</code> 子类的讲解，我们在另外的文章中进行。即，本模块的讨论范围是：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">- <span class="type">ReceiverInputDStream</span></span><br><span class="line">  - 子类 <span class="type">SocketInputDStream</span></span><br><span class="line">  - 子类 <span class="type">TwitterInputDStream</span></span><br><span class="line">  - 子类 <span class="type">RawInputDStream</span></span><br><span class="line">  - 子类 <span class="type">FlumePollingInputDStream</span></span><br><span class="line">  - 子类 <span class="type">MQTTInputDStream</span></span><br><span class="line">  - 子类 <span class="type">FlumeInputDStream</span></span><br><span class="line">  - 子类 <span class="type">PluggableInputDStream</span></span><br><span class="line">  - 子类 <span class="type">KafkaInputDStream</span></span><br></pre></td></tr></table></figure><h2 id="ReceiverTracker-分发-Receiver-过程"><a href="#ReceiverTracker-分发-Receiver-过程" class="headerlink" title="ReceiverTracker 分发 Receiver 过程"></a>ReceiverTracker 分发 Receiver 过程</h2><p>我们已经知道，<code>ReceiverTracker</code> 自身运行在 driver 端，是一个管理分布在各个 executor 上的 <code>Receiver</code> 的总指挥者。</p><p>在 <code>ssc.start()</code> 时，将隐含地调用 <code>ReceiverTracker.start()</code>；而 <code>ReceiverTracker.start()</code> 最重要的任务就是调用自己的 <code>launchReceivers()</code> 方法将 <code>Receiver</code> 分发到多个 executor 上去。然后在每个 executor 上，由 <code>ReceiverSupervisor</code> 来分别启动一个 <code>Receiver</code> 接收数据。这个过程用下图表示：</p><p><img src="0.imgs/060.png" alt="image"></p><p>我们将以 1.4.0 和 1.5.0 这两个版本为代表，仔细分析一下 launchReceivers() 的实现。</p><pre><code>1.4.0 代表了 1.5.0 以前的版本，如 1.2.x, 1.3.x, 1.4.x1.5.0 代表了 1.5.0 以来的版本，如 1.5.x, 1.6.x</code></pre><h2 id="Spark-1-4-0-的-launchReceivers-实现"><a href="#Spark-1-4-0-的-launchReceivers-实现" class="headerlink" title="Spark 1.4.0 的 launchReceivers() 实现"></a>Spark 1.4.0 的 launchReceivers() 实现</h2><p>Spark 1.4.0 的 <code>launchReceivers()</code> 的过程如下：</p><ul><li><p>(1.a) <strong>构造 Receiver RDD</strong>。具体的，是先遍历所有的 <code>ReceiverInputStream</code>，获得将要启动的所有 <code>x</code> 个 <code>Receiver</code> 的实例。然后，把这些实例当做 <code>x</code> 份数据，在 driver 端构造一个 <code>RDD</code> 实例，这个 <code>RDD</code> 分为 <code>x</code> 个 partition，每个 partition 包含一个 <code>Receiver</code> 数据（即 <code>Receiver</code> 实例）。</p></li><li><p>(1.b) <strong>定义计算 func</strong>。我们将在多个 executor 上共启动 <code>x</code> 个 <code>Task</code>，每个 <code>Task</code> 负责一个 partition 的数据，即一个 <code>Receiver</code> 实例。我们要对这个 <code>Receiver</code> 实例做的计算定义为 <code>func</code> 函数，具体的，<code>func</code> 是：</p><ul><li>以这个 <code>Receiver</code> 实例为参数，构造新的 <code>ReceiverSupervisor</code> 实例 <code>supervisor</code>：<code>supervisor = new ReceiverSupervisorImpl(receiver, ...)</code></li><li><code>supervisor.start()</code>；这一步将启动新线程启动 <code>Receiver</code> 实例，然后很快返回</li><li><code>supervisor.awaitTermination()</code>；将一直 block 住当前 <code>Task</code> 的线程</li></ul></li><li><p>(1.c) <strong>分发 RDD(Receiver) 和 func 到具体的 executor</strong>。上面 (a)(b) 两步只是在 driver 端定义了 <code>RDD[Receiver]</code> 和 这个 <code>RDD</code> 之上将执行的 <code>func</code>，但并没有具体的去做。这一步是将两者的定义分发到 executor 上去，马上就可以实际执行了。</p></li><li><p>(2) <strong>在各个 executor 端，执行(1.b) 中定义的 <code>func</code></strong>。即启动 <code>Receiver</code> 实例，并一直 block 住当前线程。</p></li></ul><p>这样，通过 1 个 <code>RDD</code> 实例包含 <code>x</code> 个 <code>Receiver</code>，对应启动 1 个 <code>Job</code> 包含 <code>x</code> 个 <code>Task</code>，就可以完成 <code>Receiver</code> 的分发和部署了。上述 (1.a)(1.b)(1.c)(2) 的过程示意如下图：</p><p><img src="3.imgs/020.png" alt="image"></p><p>这里 Spark Streaming 下层的 Spark Core 对 <code>Receiver</code> 分发是毫无感知的，它只是执行了“应用层面” – 对 Spark Core 来讲，Spark Streaming 就是“应用层面”– 的一个普通 <code>Job</code>；但 Spark Streaming 只通过这个普通 <code>Job</code> 即可完“特殊功能”的 <code>Receiver</code> 分发，可谓巧妙巧妙。</p><p>上述逻辑实现的源码请到 <a href="https://github.com/apache/spark/blob/v1.4.0/streaming/src/main/scala/org/apache/spark/streaming/scheduler/ReceiverTracker.scala" target="_blank" rel="noopener">Spark 1.4.0 的 ReceiverTracker</a> 查看。</p><h2 id="Spark-1-5-0-的-launchReceivers-实现"><a href="#Spark-1-5-0-的-launchReceivers-实现" class="headerlink" title="Spark 1.5.0 的 launchReceivers() 实现"></a>Spark 1.5.0 的 launchReceivers() 实现</h2><p>其实上面这个实现，这个长时运行的分发 <code>Job</code> 还存在一些问题：</p><ul><li>如果某个 <code>Task</code> 失败超过 <code>spark.task.maxFailures(默认=4)</code> 次的话，整个 <code>Job</code> 就会失败。这个在长时运行的 Spark Streaming 程序里，<code>Executor</code> 多失效几次就有可能导致 <code>Task</code> 失败达到上限次数了。</li><li>如果某个 <code>Task</code> 失效一下，Spark Core 的 <code>TaskScheduler</code> 会将其重新部署到另一个 executor 上去重跑。但这里的问题在于，负责重跑的 executor 可能是在下发重跑的那一刻是正在执行 <code>Task</code> 数较少的，但不一定能够将 <code>Receiver</code> 分布的最均衡的。</li><li>有个用户 code 可能会想自定义一个 <code>Receiver</code> 的分布策略，比如所有的 <code>Receiver</code> 都部署到同一个节点上去。</li></ul><p>从 1.5.0 开始，Spark Streaming 添加了增强的 <code>Receiver</code> 分发策略。对比之前的版本，主要的变更在于：</p><ol><li>添加可插拔的 <code>ReceiverSchedulingPolicy</code></li><li>把 <code>1</code> 个 <code>Job</code>（包含 <code>x</code> 个 <code>Task</code>），改为 <code>x</code> 个 <code>Job</code>（每个 <code>Job</code> 只包含 <code>1</code> 个 <code>Task</code>）</li><li>添加对 <code>Receiver</code> 的监控重启机制</li></ol><p>我们一个一个看一看。</p><h3 id="1-可插拔的-ReceiverSchedulingPolicy"><a href="#1-可插拔的-ReceiverSchedulingPolicy" class="headerlink" title="(1) 可插拔的 ReceiverSchedulingPolicy"></a>(1) 可插拔的 ReceiverSchedulingPolicy</h3><p><code>ReceiverSchedulingPolicy</code> 的主要目的，是在 Spark Streaming 层面添加对 <code>Receiver</code> 的分发目的地的计算，相对于之前版本依赖 Spark Core 的 <code>TaskScheduler</code> 进行通用分发，新的 <code>ReceiverSchedulingPolicy</code> 会对 Streaming 应用的更好的语义理解，也能计算出更好的分发策略。</p><p><code>ReceiverSchedulingPolicy</code> 有两个方法，分别用于：</p><ul><li><p>在 Streaming 程序首次启动时：</p><ul><li>收集所有 <code>InputDStream</code> 包含的所有 <code>Receiver</code> 实例 —— <code>receivers</code></li><li>收集所有的 executor —— <code>executors</code> —— 作为候选目的地</li><li>然后就调用 <code>ReceiverSchedulingPolicy.scheduleReceivers(receivers, executors)</code> 来计算每个 <code>Receiver</code> 的目的地 executor 列表</li></ul></li><li><p>在 Streaming 程序运行过程中，如果需要重启某个 <code>Receiver</code>：</p><ul><li>将首先看一看之前计算过的目的地 executor 有没有还 alive 的</li><li>如果没有，就需要 <code>ReceiverSchedulingPolicy.rescheduleReceiver(receiver, ...)</code> 来重新计算这个 <code>Receiver</code> 的目的地 executor 列表</li></ul></li></ul><p><a href="https://github.com/apache/spark/blob/master/streaming/src/main/scala/org/apache/spark/streaming/scheduler/ReceiverSchedulingPolicy.scala" target="_blank" rel="noopener">默认的 <code>ReceiverSchedulingPolicy</code></a> 是实现为 <code>round-robin</code> 式的了。我们举例说明下这两个方法：</p><p><img src="3.imgs/030.png" alt="image"></p><p>其中，在 <code>Receiver y</code> 失效时，以前的 Spark Streaming 有可能会在 executor 1 上重启 <code>Receiver y</code>，而 1.5.0 以来，将在 executor 3 上重启 <code>Receiver y</code>。</p><h3 id="2-每个-Receiver-分发有单独的-Job-负责"><a href="#2-每个-Receiver-分发有单独的-Job-负责" class="headerlink" title="(2) 每个 Receiver 分发有单独的 Job 负责"></a>(2) 每个 Receiver 分发有单独的 Job 负责</h3><p>1.5.0 版本以来的 Spark Streaming，是为每个 <code>Receiver</code> 都分配单独的只有 1 个 <code>Task</code> 的 <code>Job</code> 来尝试分发，这与以前版本将 <code>x</code> 个 <code>Receiver</code> 都放到一个有 <code>x</code> 个 <code>Task</code> 的 <code>Job</code> 里分发是很不一样的。</p><p>而且，对于这仅有的一个 <code>Task</code>，只在第 1 次执行时，才尝试启动 <code>Receiver</code>；如果该 <code>Task</code> 因为失效而被调度到其它 executor 执行时，就不再尝试启动 <code>Receiver</code>、只做一个空操作，从而导致本 <code>Job</code> 的状态是成功执行已完成。<code>ReceiverTracker</code> 会另外调起一个 <code>Job</code> ——  有可能会重新计算 <code>Receiver</code> 的目的地 —— 来继续尝试 <code>Receiver</code> 分发……如此直到成功为止。</p><p>另外，由于 Spark Core 的 <code>Task</code> 下发时只会参考并大部分时候尊重 Spark Streaming 设置的 <code>preferredLocation</code> 目的地信息，还是有一定可能该分发 <code>Receiver</code> 的 <code>Job</code> 并没有在我们想要调度的 executor 上运行。此时，在第 1 次执行 <code>Task</code> 时，会首先向 <code>ReceiverTracker</code> 发送 <code>RegisterReceiver</code> 消息，只有得到肯定的答复时，才真正启动 <code>Receiver</code>，否则就继续做一个空操作，导致本 <code>Job</code> 的状态是成功执行已完成。当然，<code>ReceiverTracker</code> 也会另外调起一个 <code>Job</code>，来继续尝试 <code>Receiver</code> 分发……如此直到成功为止。</p><p>我们用图示来表达这个改动：</p><p><img src="3.imgs/040.png" alt="image"></p><p>所以通过上面可以看到，一个 <code>Receiver</code> 的分发 <code>Job</code> 是有可能没有完成分发 <code>Receiver</code> 的目的的，所以 <code>ReceiverTracker</code> 会继续再起一个 <code>Job</code> 来尝试 <code>Receiver</code> 分发。这个机制保证了，如果一次 <code>Receiver</code> 如果没有抵达预先计算好的 executor，就有机会再次进行分发，从而实现在 Spark Streaming 层面对 <code>Receiver</code> 所在位置更好的控制。</p><h3 id="3-对-Receiver-的监控重启机制"><a href="#3-对-Receiver-的监控重启机制" class="headerlink" title="(3) 对 Receiver 的监控重启机制"></a>(3) 对 <code>Receiver</code> 的监控重启机制</h3><p>上面分析了每个 <code>Receiver</code> 都有专门的 <code>Job</code> 来保证分发后，我们发现这样一来，<code>Receiver</code> 的失效重启就不受 <code>spark.task.maxFailures(默认=4)</code> 次的限制了。</p><p>因为现在的 <code>Receiver</code> 重试不是在 <code>Task</code> 级别，而是在 <code>Job</code> 级别；并且 <code>Receiver</code> 失效后并不会导致前一次 <code>Job</code> 失败，而是前一次 <code>Job</code> 成功、并新起一个 <code>Job</code> 再次进行分发。这样一来，不管 Spark Streaming 运行多长时间，<code>Receiver</code> 总是保持活性的，不会随着 executor 的丢失而导致 <code>Receiver</code> 死去。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>我们再简单对比一下 1.4.0 和 1.5.0 版本在 <code>Receiver</code> 分发上的区别：</p><p><img src="3.imgs/020.png" alt="image"><br><img src="3.imgs/040.png" alt="image"></p><p>通过以上分析，我们总结：</p><table><br>    <tr><br>        <td align="center"></td><br>        <td align="center"><strong>Spark Streaming 1.4.0</strong></td><br>        <td align="center"><strong>Spark Streaming 1.5.0</strong></td><br>    </tr><br>    <tr><br>        <td align="center"><strong>Receiver 活性</strong></td><br>        <td align="center">不保证永活</td><br>        <td align="center">无限重试、保证永活</td><br>    </tr><br>    <tr><br>        <td align="center"><strong>Receiver 均衡分发</strong></td><br>        <td align="center">无保证</td><br>        <td align="center">round-robin 策略</td><br>    </tr><br>    <tr><br>        <td align="center"><strong>自定义 Receiver 分发</strong></td><br>        <td align="center">很 tricky</td><br>        <td align="center">方便</td><br>    </tr><br></table><h2 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h2><p>本文所分析的 1.5.0 以来增强的 <code>Receiver</code> 分发策略，是由朱诗雄同学强势贡献给社区的：</p><ul><li><img src="https://avatars2.githubusercontent.com/u/1000778?v=3&amp;s=80" alt="朱诗雄"></li><li>朱诗雄，Apache Spark Committer, Databricks 的中国籍牛牛工程师，已为 Spark 持续贡献代码近两年时间</li><li>强势围观 <a href="https://github.com/zsxwing" target="_blank" rel="noopener">他的 Github</a>，和 <a href="https://github.com/apache/spark/commits/master?author=zsxwing" target="_blank" rel="noopener">他正为 Spark 贡献的代码</a></li></ul><p><br><br><br></p><p>（本文完，参与本文的讨论请 <a href="https://github.com/proflin/CoolplaySpark/issues/6" target="_blank" rel="noopener">猛戳这里</a>，返回目录请 <a href="readme.md">猛戳这里</a>）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Receiver-分发详解&quot;&gt;&lt;a href=&quot;#Receiver-分发详解&quot; class=&quot;headerlink&quot; title=&quot;Receiver 分发详解&quot;&gt;&lt;/a&gt;Receiver 分发详解&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;[酷玩 Spark] Spa
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97/2.2%20JobGenerator%20%E8%AF%A6%E8%A7%A3/"/>
    <id>http://yoursite.com/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/2.2 JobGenerator 详解/</id>
    <published>2018-02-09T03:49:13.906Z</published>
    <updated>2018-02-09T03:48:41.424Z</updated>
    
    <content type="html"><![CDATA[<h1 id="JobGenerator-详解"><a href="#JobGenerator-详解" class="headerlink" title="JobGenerator 详解"></a>JobGenerator 详解</h1><p><strong><em>[酷玩 Spark] Spark Streaming 源码解析系列</em></strong> ，返回目录请 <a href="readme.md">猛戳这里</a></p><p><a href="http://e.qq.com" target="_blank" rel="noopener">「腾讯·广点通」</a>技术团队荣誉出品</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">本系列内容适用范围：</span><br><span class="line"></span><br><span class="line">* 2017.07.11 update, Spark 2.2 全系列 √ (已发布：2.2.0)</span><br><span class="line">* 2017.10.02 update, Spark 2.1 全系列 √ (已发布：2.1.0, 2.1.1, 2.1.2)</span><br><span class="line">* 2016.11.14 update, Spark 2.0 全系列 √ (已发布：2.0.0, 2.0.1, 2.0.2)</span><br></pre></td></tr></table></figure><p><br><br><br></p><p>阅读本文前，请一定先阅读 <a href="0.1 Spark Streaming 实现思路与模块概述.md">Spark Streaming 实现思路与模块概述</a> 一文，其中概述了 Spark Streaming 的 4 大模块的基本作用，有了全局概念后再看本文对 <code>模块 2：Job 动态生成</code> 细节的解释。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>前面在 <a href="0.1 Spark Streaming 实现思路与模块概述.md">Spark Streaming 实现思路与模块概述</a> 和 <a href="1.2 DStream 生成 RDD 实例详解.md">DStream 生成 RDD 实例详解</a> 里我们分析了 <code>DStreamGraph</code> 和 <code>DStream</code> 具有能够实例化 <code>RDD</code> 和 <code>RDD</code> DAG 的能力，下面我们来看 Spark Streaming 是如何将其动态调度的。</p><p>在 Spark Streaming 程序的入口，我们都会定义一个 <code>batchDuration</code>，就是需要每隔多长时间就比照静态的 <code>DStreamGraph</code> 来动态生成一个 RDD DAG 实例。在 Spark Streaming 里，总体负责动态作业调度的具体类是 <code>JobScheduler</code>，</p><p><code>JobScheduler</code> 有两个非常重要的成员：<code>JobGenerator</code> 和 <code>ReceiverTracker</code>。<code>JobScheduler</code> 将每个 batch 的 RDD DAG 具体生成工作委托给 <code>JobGenerator</code>，而将源头输入数据的记录工作委托给 <code>ReceiverTracker</code>。</p><p><img src="0.imgs/050.png" alt="image"></p><pre><code>JobScheduler    的全限定名是：org.apache.spark.streaming.scheduler.JobSchedulerJobGenerator    的全限定名是：org.apache.spark.streaming.scheduler.JobGeneratorReceiverTracker 的全限定名是：org.apache.spark.streaming.scheduler.ReceiverTracker</code></pre><p>本文我们来详解 <code>JobScheduler</code>。</p><h2 id="JobGenerator-启动"><a href="#JobGenerator-启动" class="headerlink" title="JobGenerator 启动"></a>JobGenerator 启动</h2><p>在用户 code 最后调用 <code>ssc.start()</code> 时，将隐含的导致一系列模块的启动，其中对我们 <code>JobGenerator</code> 这里的启动调用关系如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 StreamingContext.start(), JobScheduler.start(), JobGenerator.start()</span></span><br><span class="line"></span><br><span class="line">ssc.start()                              <span class="comment">// 【用户 code：StreamingContext.start()】</span></span><br><span class="line">    -&gt; scheduler.start()                 <span class="comment">// 【JobScheduler.start()】</span></span><br><span class="line">                 -&gt; jobGenerator.start() <span class="comment">// 【JobGenerator.start()】</span></span><br></pre></td></tr></table></figure></p><p>具体的看，<code>JobGenerator.start()</code> 的代码如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 JobGenerator.start()</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start</span></span>(): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">  ...</span><br><span class="line">  eventLoop.start()                      <span class="comment">// 【启动 RPC 处理线程】</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (ssc.isCheckpointPresent) &#123;</span><br><span class="line">    restart()                            <span class="comment">// 【如果不是第一次启动，就需要从 checkpoint 恢复】</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    startFirstTime()                     <span class="comment">// 【第一次启动，就 startFirstTime()】</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，在启动了 RPC 处理线程 <code>eventLoop</code> 后，就会根据是否是第一次启动，也就是是否存在 checkpoint，来具体的决定是 <code>restart()</code> 还是 <code>startFirstTime()</code>。</p><p>后面我们会分析失效后重启的 <code>restart()</code> 流程，这里我们来关注 <code>startFirstTime()</code>:</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 JobGenerator.startFirstTime()</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">startFirstTime</span></span>() &#123;</span><br><span class="line">  <span class="keyword">val</span> startTime = <span class="keyword">new</span> <span class="type">Time</span>(timer.getStartTime())</span><br><span class="line">  graph.start(startTime - graph.batchDuration)</span><br><span class="line">  timer.start(startTime.milliseconds)</span><br><span class="line">  logInfo(<span class="string">"Started JobGenerator at "</span> + startTime)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，这里首次启动时做的工作，先是通过 <code>graph.start()</code> 来告知了 <code>DStreamGraph</code> 第 1 个 batch 的启动时间，然后就是 <code>timer.start()</code> 启动了关键的定时器。</p><p>当定时器 <code>timer</code> 启动以后，<code>JobGenerator</code> 的 <code>startFirstTime()</code> 就完成了。</p><h2 id="RecurringTimer"><a href="#RecurringTimer" class="headerlink" title="RecurringTimer"></a>RecurringTimer</h2><p>通过之前几篇文章的分析我们知道，<strong><code>JobGenerator</code> 维护了一个定时器</strong>，周期就是用户设置的 <code>batchDuration</code>，<strong>定时为每个 batch 生成 RDD DAG 的实例</strong>。</p><p>具体的，这个定时器实例就是：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 JobGenerator</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[streaming]</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JobGenerator</span>(<span class="params">jobScheduler: <span class="type">JobScheduler</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">...</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> timer = <span class="keyword">new</span> <span class="type">RecurringTimer</span>(clock, ssc.graph.batchDuration.milliseconds,</span><br><span class="line">      longTime =&gt; eventLoop.post(<span class="type">GenerateJobs</span>(<span class="keyword">new</span> <span class="type">Time</span>(longTime))), <span class="string">"JobGenerator"</span>)</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>通过代码也可以看到，整个 <code>timer</code> 的调度周期就是 <code>batchDuration</code>，每次调度起来就是做一个非常简单的工作：往 <code>eventLoop</code> 里发送一个消息 —— 该为当前 batch (<code>new Time(longTime)</code>) GenerateJobs 了！</p><h2 id="GenerateJobs"><a href="#GenerateJobs" class="headerlink" title="GenerateJobs"></a>GenerateJobs</h2><p>接下来，<code>eventLoop</code> 收到消息时，会在一个消息处理的线程池里，执行对应的操作。在这里，处理 <code>GenerateJobs(time)</code> 消息的对应操作是 <code>generateJobs(time)</code>：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">generateJobs</span></span>(time: <span class="type">Time</span>) &#123;</span><br><span class="line">  <span class="type">SparkEnv</span>.set(ssc.env)</span><br><span class="line">  <span class="type">Try</span> &#123;</span><br><span class="line">    jobScheduler.receiverTracker.allocateBlocksToBatch(time)                 <span class="comment">// 【步骤 (1)】</span></span><br><span class="line">    graph.generateJobs(time)                                                 <span class="comment">// 【步骤 (2)】</span></span><br><span class="line">  &#125; <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Success</span>(jobs) =&gt;</span><br><span class="line">      <span class="keyword">val</span> streamIdToInputInfos = jobScheduler.inputInfoTracker.getInfo(time) <span class="comment">// 【步骤 (3)】</span></span><br><span class="line">      jobScheduler.submitJobSet(<span class="type">JobSet</span>(time, jobs, streamIdToInputInfos))    <span class="comment">// 【步骤 (4)】</span></span><br><span class="line">    <span class="keyword">case</span> <span class="type">Failure</span>(e) =&gt;</span><br><span class="line">      jobScheduler.reportError(<span class="string">"Error generating jobs for time "</span> + time, e)</span><br><span class="line">  &#125;</span><br><span class="line">  eventLoop.post(<span class="type">DoCheckpoint</span>(time, clearCheckpointDataLater = <span class="literal">false</span>))       <span class="comment">// 【步骤 (5)】</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码异常精悍，包含了 <code>JobGenerator</code> 主要工作 —— 如下图所示 —— 的 5 个步骤！</p><p><img src="0.imgs/055.png" alt="image"></p><ul><li>(1) <strong>要求 <code>ReceiverTracker</code> 将目前已收到的数据进行一次 allocate</strong>，即将上次 batch 切分后的数据切分到到本次新的 batch 里<ul><li>这里 <code>ReceiverTracker</code> 对已收到数据的 meta 信息进行 <code>allocateBlocksToBatch(time)</code>，与 <code>ReceiverTracker</code> 自己接收 <code>ReceiverSupervisorImpl</code> 上报块数据 meta 信息的过程，是相互独立的，但通过 <code>synchronized</code> 关键字来互斥同步</li><li>即是说，不管 <code>ReceiverSupervisorImpl</code> 形成块数据的时间戳 <code>t1</code>、<code>ReceiverSupervisorImpl</code> 发送块数据的时间戳 <code>t2</code>、<code>ReceiverTracker</code> 收到块数据的时间戳 <code>t3</code> 分别是啥，最终块数据划入哪个 batch，还是由 <code>ReceiverTracker.allocateBlocksToBatch(time)</code> 方法获得 <code>synchronized</code> 锁的那一刻，还有未划入之前任何一个 batch 的块数据 meta，将被划分入最新的 batch</li><li>所以，每个块数据的 meta 信息，将被划入一个、且只被划入一个 batch</li></ul></li></ul><p><br></p><ul><li>(2) <strong>要求 <code>DStreamGraph</code> 复制出一套新的 RDD DAG 的实例</strong>，具体过程是：<code>DStreamGraph</code> 将要求图里的尾 <code>DStream</code> 节点生成具体的 RDD 实例，并递归的调用尾 <code>DStream</code> 的上游 <code>DStream</code> 节点……以此遍历整个 <code>DStreamGraph</code>，遍历结束也就正好生成了 RDD DAG 的实例<ul><li>这个过程的详解，请参考前面的文章 <a href="1.2 DStream 生成 RDD 实例详解.md">DStream 生成 RDD 实例详解</a></li><li>精确的说，整个 <code>DStreamGraph.generateJobs(time)</code> 遍历结束的返回值是 <code>Seq[Job]</code></li></ul></li></ul><p><br></p><ul><li>(3) <strong>获取第 1 步 <code>ReceiverTracker</code> 分配到本 batch 的源头数据的 meta 信息</strong><ul><li>第 1 步中 <code>ReceiverTracker</code> 只是对 batch 的源头数据 meta 信息进行了 batch 的分配，本步骤是按照 batch 时间来向 <code>ReceiverTracker</code> 查询得到划分到本 batch 的块数据 meta 信息</li></ul></li></ul><p><br></p><ul><li>(4) 将第 2 步生成的本 batch 的 RDD DAG，和第 3 步获取到的 meta 信息，<strong>一同提交给 <code>JobScheduler</code> 异步执行</strong><ul><li>这里我们提交的是将 (a) <code>time</code> (b) <code>Seq[job]</code> (c) <code>块数据的 meta 信息</code> 这三者包装为一个 <code>JobSet</code>，然后调用 <code>JobScheduler.submitJobSet(JobSet)</code> 提交给 <code>JobScheduler</code></li><li>这里的向 <code>JobScheduler</code> 提交过程与 <code>JobScheduler</code> 接下来在 <code>jobExecutor</code> 里执行过程是异步分离的，因此本步将非常快即可返回</li></ul></li></ul><p><br></p><ul><li>(5) 只要提交结束（不管是否已开始异步执行），就<strong>马上对整个系统的当前运行状态做一个 checkpoint</strong><ul><li>这里做 checkpoint 也只是异步提交一个 <code>DoCheckpoint</code> 消息请求，不用等 checkpoint 真正写完成即可返回</li><li>这里也简单描述一下 checkpoint 包含的内容，包括已经提交了的、但尚未运行结束的 JobSet 等实际运行时信息。</li></ul></li></ul><p><br><br><br></p><p>（本文完，参与本文的讨论请 <a href="https://github.com/proflin/CoolplaySpark/issues/5" target="_blank" rel="noopener">猛戳这里</a>，返回目录请 <a href="readme.md">猛戳这里</a>）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;JobGenerator-详解&quot;&gt;&lt;a href=&quot;#JobGenerator-详解&quot; class=&quot;headerlink&quot; title=&quot;JobGenerator 详解&quot;&gt;&lt;/a&gt;JobGenerator 详解&lt;/h1&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;[酷玩 Sp
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97/2.1%20JobScheduler,%20Job,%20JobSet%20%E8%AF%A6%E8%A7%A3/"/>
    <id>http://yoursite.com/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/2.1 JobScheduler, Job, JobSet 详解/</id>
    <published>2018-02-09T03:49:13.899Z</published>
    <updated>2018-02-09T03:48:41.423Z</updated>
    
    <content type="html"><![CDATA[<h1 id="JobScheduler-Job-JobSet-详解"><a href="#JobScheduler-Job-JobSet-详解" class="headerlink" title="JobScheduler, Job, JobSet 详解"></a>JobScheduler, Job, JobSet 详解</h1><p><strong><em>[酷玩 Spark] Spark Streaming 源码解析系列</em></strong> ，返回目录请 <a href="readme.md">猛戳这里</a></p><p><a href="http://e.qq.com" target="_blank" rel="noopener">「腾讯·广点通」</a>技术团队荣誉出品</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">本系列内容适用范围：</span><br><span class="line"></span><br><span class="line">* 2017.07.11 update, Spark 2.2 全系列 √ (已发布：2.2.0)</span><br><span class="line">* 2017.10.02 update, Spark 2.1 全系列 √ (已发布：2.1.0, 2.1.1, 2.1.2)</span><br><span class="line">* 2016.11.14 update, Spark 2.0 全系列 √ (已发布：2.0.0, 2.0.1, 2.0.2)</span><br></pre></td></tr></table></figure><p><br><br><br></p><p>阅读本文前，请一定先阅读 <a href="0.1 Spark Streaming 实现思路与模块概述.md">Spark Streaming 实现思路与模块概述</a> 一文，其中概述了 Spark Streaming 的 4 大模块的基本作用，有了全局概念后再看本文对 <code>模块 2：Job 动态生成</code> 细节的解释。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>前面在 <a href="0.1 Spark Streaming 实现思路与模块概述.md">Spark Streaming 实现思路与模块概述</a> 和 <a href="1.2 DStream 生成 RDD 实例详解.md">DStream 生成 RDD 实例详解</a> 里我们分析了 <code>DStreamGraph</code> 和 <code>DStream</code> 具有能够实例化 <code>RDD</code> 和 <code>RDD</code> DAG 的能力，下面我们来看 Spark Streaming 是如何将其动态调度的。</p><p>在 Spark Streaming 程序的入口，我们都会定义一个 <code>batchDuration</code>，就是需要每隔多长时间就比照静态的 <code>DStreamGraph</code> 来动态生成一个 RDD DAG 实例。在 Spark Streaming 里，总体负责动态作业调度的具体类是 <code>JobScheduler</code>，在 Spark Streaming 程序在 <code>ssc.start()</code> 开始运行时，将 <code>JobScheduler</code> 的实例给 start() 运行起来。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 StreamingContext</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start</span></span>(): <span class="type">Unit</span> = synchronized &#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="type">ThreadUtils</span>.runInNewThread(<span class="string">"streaming-start"</span>) &#123;</span><br><span class="line">    sparkContext.setCallSite(startSite.get)</span><br><span class="line">    sparkContext.clearJobGroup()</span><br><span class="line">    sparkContext.setLocalProperty(<span class="type">SparkContext</span>.<span class="type">SPARK_JOB_INTERRUPT_ON_CANCEL</span>, <span class="string">"false"</span>)</span><br><span class="line">    scheduler.start()  <span class="comment">// 【这里调用了 JobScheduler().start()】</span></span><br><span class="line">  &#125;</span><br><span class="line">  state = <span class="type">StreamingContextState</span>.<span class="type">ACTIVE</span></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Spark-Streaming-的-Job-总调度者-JobScheduler"><a href="#Spark-Streaming-的-Job-总调度者-JobScheduler" class="headerlink" title="Spark Streaming 的 Job 总调度者 JobScheduler"></a>Spark Streaming 的 Job 总调度者 JobScheduler</h2><p><strong><code>JobScheduler</code> 是 Spark Streaming 的 Job 总调度者</strong>。</p><p><code>JobScheduler</code> 有两个非常重要的成员：<code>JobGenerator</code> 和 <code>ReceiverTracker</code>。<code>JobScheduler</code> 将每个 batch 的 RDD DAG 具体生成工作委托给 <code>JobGenerator</code>，而将源头输入数据的记录工作委托给 <code>ReceiverTracker</code>。</p><p><img src="0.imgs/050.png" alt="image"></p><pre><code>JobScheduler    的全限定名是：org.apache.spark.streaming.scheduler.JobSchedulerJobGenerator    的全限定名是：org.apache.spark.streaming.scheduler.JobGeneratorReceiverTracker 的全限定名是：org.apache.spark.streaming.scheduler.ReceiverTracker</code></pre><p><strong><code>JobGenerator</code> 维护了一个定时器</strong>，周期就是我们刚刚提到的 <code>batchDuration</code>，<strong>定时为每个 batch 生成 RDD DAG 的实例</strong>。<br>具体的，根据我们在 <a href="1.2 DStream 生成 RDD 实例详解.md">DStream 生成 RDD 实例详解</a> 中的解析，<code>DStreamGraph.generateJobs(time)</code> 将返回一个 <code>Seq[Job]</code>，其中的每个 <code>Job</code> 是一个 <code>ForEachDStream</code> 实例的 <code>generateJob(time)</code> 返回的结果。</p><p><img src="0.imgs/055.png" alt="image"></p><p>此时，<code>JobGenerator</code> 拿到了 <code>Seq[Job]</code> 后（如上图 <code>(2)</code> ），就将其包装成一个 JobSet（如上图 <code>(3)</code> ），然后就调用 <code>JobScheduler.submitJobSet(jobSet)</code> 来交付回 JobScheduler（如上图 (4) ）。</p><p>那么 <code>JobScheduler</code> 收到 <code>jobSet</code> 后是具体如何处理的呢？我们看其实现：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 JobScheduler.submitJobSet(jobSet: JobSet)</span></span><br><span class="line"><span class="keyword">if</span> (jobSet.jobs.isEmpty) &#123;</span><br><span class="line">  logInfo(<span class="string">"No jobs added for time "</span> + jobSet.time)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  listenerBus.post(<span class="type">StreamingListenerBatchSubmitted</span>(jobSet.toBatchInfo))</span><br><span class="line">  jobSets.put(jobSet.time, jobSet)</span><br><span class="line">  <span class="comment">// 【下面这行是最主要的处理逻辑：将每个 job 都在 jobExecutor 线程池中、用 new JobHandler 来处理】</span></span><br><span class="line">  jobSet.jobs.foreach(job =&gt; jobExecutor.execute(<span class="keyword">new</span> <span class="type">JobHandler</span>(job)))</span><br><span class="line">  logInfo(<span class="string">"Added jobs for time "</span> + jobSet.time)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这里最重要的处理逻辑是 <code>job =&gt; jobExecutor.execute(new JobHandler(job))</code>，也就是将每个 job 都在 jobExecutor 线程池中、用 new JobHandler 来处理。</p><h3 id="JobHandler"><a href="#JobHandler" class="headerlink" title="JobHandler"></a>JobHandler</h3><p>先来看 JobHandler 针对 Job 的主要处理逻辑：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 JobHandler</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span></span>()</span><br><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 【发布 JobStarted 消息】</span></span><br><span class="line">  _eventLoop.post(<span class="type">JobStarted</span>(job))</span><br><span class="line">  <span class="type">PairRDDFunctions</span>.disableOutputSpecValidation.withValue(<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="comment">// 【主要逻辑，直接调用了 job.run()】</span></span><br><span class="line">    job.run()</span><br><span class="line">  &#125;</span><br><span class="line">  _eventLoop = eventLoop</span><br><span class="line">  <span class="keyword">if</span> (_eventLoop != <span class="literal">null</span>) &#123;</span><br><span class="line">  <span class="comment">// 【发布 JobCompleted 消息】</span></span><br><span class="line">    _eventLoop.post(<span class="type">JobCompleted</span>(job))</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>也就是说，<code>JobHandler</code> 除了做一些状态记录外，最主要的就是调用 <code>job.run()</code>！这里就与我们在 <a href="1.2 DStream 生成 RDD 实例详解.md">DStream 生成 RDD 实例详解</a> 里分析的对应起来了：<br>在 <code>ForEachDStream.generateJob(time)</code> 时，是定义了 <code>Job</code> 的运行逻辑，即定义了 <code>Job.func</code>。而在 <code>JobHandler</code> 这里，是真正调用了 <code>Job.run()</code>、将触发 <code>Job.func</code> 的真正执行！</p><h3 id="Job-运行的线程池-jobExecutor"><a href="#Job-运行的线程池-jobExecutor" class="headerlink" title="Job 运行的线程池 jobExecutor"></a>Job 运行的线程池 jobExecutor</h3><p>上面 <code>JobHandler</code> 是解决了做什么的问题，本节 <code>jobExecutor</code> 是解决 <code>Job</code> 在哪里做。</p><p>具体的，<code>jobExecutor</code> 是 <code>JobScheduler</code> 的成员：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 JobScheduler</span></span><br><span class="line"><span class="keyword">private</span>[streaming]</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JobScheduler</span>(<span class="params">val ssc: <span class="type">StreamingContext</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> numConcurrentJobs = ssc.conf.getInt(<span class="string">"spark.streaming.concurrentJobs"</span>, <span class="number">1</span>)</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> jobExecutor =</span><br><span class="line">      <span class="type">ThreadUtils</span>.newDaemonFixedThreadPool(numConcurrentJobs, <span class="string">"streaming-job-executor"</span>)</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>也就是，<code>ThreadUtils.newDaemonFixedThreadPool()</code> 调用将产生一个名为 <code>&quot;streaming-job-executor&quot;</code> 的线程池，所以，<code>Job</code> 将在这个线程池的线程里，被实际执行 <code>func</code>。</p><h2 id="spark-streaming-concurrentJobs-参数"><a href="#spark-streaming-concurrentJobs-参数" class="headerlink" title="spark.streaming.concurrentJobs 参数"></a>spark.streaming.concurrentJobs 参数</h2><p>这里 <code>jobExecutor</code> 的线程池大小，是由 <code>spark.streaming.concurrentJobs</code> 参数来控制的，当没有显式设置时，其取值为 <code>1</code>。</p><p>进一步说，这里 <code>jobExecutor</code> 的线程池大小，就是能够并行执行的 <code>Job</code> 数。而回想前文讲解的 <code>DStreamGraph.generateJobs(time)</code> 过程，一次 batch 产生一个 <code>Seq[Job}</code>，里面可能包含多个 <code>Job</code> —— 所以，确切的，<strong>有几个 <em>output</em> 操作，就调用几次 <code>ForEachDStream.generatorJob(time)</code>，就产生出几个 <code>Job</code> </strong>。</p><p>为了验证这个结果，我们做一个简单的小测试：先设置 <code>spark.streaming.concurrentJobs = 10</code>，然后在每个 batch 里做 <code>2</code> 次 <code>foreachRDD()</code> 这样的 <em>output</em> 操作：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 完整代码可见本文最后的附录</span></span><br><span class="line"><span class="keyword">val</span> <span class="type">BLOCK_INTERVAL</span> = <span class="number">1</span> <span class="comment">// in seconds</span></span><br><span class="line"><span class="keyword">val</span> <span class="type">BATCH_INTERVAL</span> = <span class="number">5</span> <span class="comment">// in seconds</span></span><br><span class="line"><span class="keyword">val</span> <span class="type">CURRENT_JOBS</span> = <span class="number">10</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment">// DStream DAG 定义开始</span></span><br><span class="line"><span class="keyword">val</span> inputStream = ssc.receiverStream(...)</span><br><span class="line">inputStream.foreachRDD(_ =&gt; <span class="type">Thread</span>.sleep(<span class="type">Int</span>.<span class="type">MaxValue</span>)) <span class="comment">// output 1</span></span><br><span class="line">inputStream.foreachRDD(_ =&gt; <span class="type">Thread</span>.sleep(<span class="type">Int</span>.<span class="type">MaxValue</span>)) <span class="comment">// output 2</span></span><br><span class="line"><span class="comment">// DStream DAG 定义结束</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>在上面的设定下，我们很容易知道，能够同时在处理的 batch 有 <code>10 / 2 = 5</code> 个，其余的 batch 的 <code>Job</code> 只能处于等待处理状态。</p><p>下面的就是刚才测试代码的运行结果，验证了我们前面的分析和计算：</p><p><img src="2.imgs/020.png" alt="image"></p><h2 id="Spark-Streaming-的-JobSet-Job，与-Spark-Core-的-Job-Stage-TaskSet-Task"><a href="#Spark-Streaming-的-JobSet-Job，与-Spark-Core-的-Job-Stage-TaskSet-Task" class="headerlink" title="Spark Streaming 的 JobSet, Job，与 Spark Core 的 Job, Stage, TaskSet, Task"></a>Spark Streaming 的 JobSet, Job，与 Spark Core 的 Job, Stage, TaskSet, Task</h2><p>最后，我们专门拿出一个小节，辨别一下这 Spark Streaming 的 JobSet, Job，与 Spark Core 的 Job, Stage, TaskSet, Task 这几个概念。</p><pre><code>[Spark Streaming]JobSet  的全限定名是：org.apache.spark.streaming.scheduler.JobSetJob     的全限定名是：org.apache.spark.streaming.scheduler.Job[Spark Core]Job     没有一个对应的实体类，主要是通过 jobId:Int 来表示一个具体的 jobStage   的全限定名是：org.apache.spark.scheduler.StageTaskSet 的全限定名是：org.apache.spark.scheduler.TaskSetTask    的全限定名是：org.apache.spark.scheduler.Task</code></pre><p>Spark Core 的 Job, Stage, Task 就是我们“日常”谈论 Spark 任务时所说的那些含义，而且在 Spark 的 WebUI 上有非常好的体现，比如下图就是 1 个 <code>Job</code> 包含 3 个 <code>Stage</code>；3 个 <code>Stage</code> 各包含 8, 2, 4 个 <code>Task</code>。而 <code>TaskSet</code> 则是 Spark Core 的内部代码里用的类，是 <code>Task</code> 的集合，和 <code>Stage</code> 是同义的。</p><p><img src="2.imgs/021.png" alt="image"></p><p>而 Spark Streaming 里也有一个 <code>Job</code>，但此 <code>Job</code> 非彼 <code>Job</code>。Spark Streaming 里的 <code>Job</code> 更像是个 <code>Java</code> 里的 <code>Runnable</code>，可以 <code>run()</code> 一个自定义的 <code>func</code> 函数。而这个 <code>func</code>, 可以：</p><ul><li>直接调用 <code>RDD</code> 的 <em>action</em>，从而产生 1 个或多个 Spark Core 的 <code>Job</code></li><li>先打印一行表头；然后调用 <code>firstTen = RDD.collect()</code>，再打印 <code>firstTen</code> 的内容；最后再打印一行表尾 —— 这正是 <code>DStream.print()</code> 的 <code>Job</code> 实现</li><li>也可以是任何用户定义的 code，甚至整个 Spark Streaming 执行过程都不产生任何 Spark Core 的 <code>Job</code> —— 如上一小节所展示的测试代码，其 <code>Job</code> 的 <code>func</code> 实现就是：<code>Thread.sleep(Int.MaxValue)</code>，仅仅是为了让这个 <code>Job</code> 一直跑在 <code>jobExecutor</code> 线程池里，从而测试 <code>jobExecutor</code> 的并行度 :)</li></ul><p>最后，Spark Streaming 的 <code>JobSet</code> 就是多个 <code>Job</code> 的集合了。</p><p>如果对上面 5 个概念做一个层次划分的话（上一层与下一层多是一对多的关系，但不完全准确），就应该是下表的样子：</p><table><br>    <tr><br>        <td></td><br>        <td>Spark Core</td><br>        <td>Spark Streaming</td><br>    </tr><br>    <tr><br>        <td>lv 5</td><br>        <td>RDD DAGs</td><br>        <td>DStreamGraph</td><br>    </tr><br>    <tr><br>        <td>lv 4</td><br>        <td>RDD DAG</td><br>        <td>JobSet</td><br>    </tr><br>    <tr><br>        <td>lv 3</td><br>        <td>Job</td><br>        <td>Job</td><br>    </tr><br>    <tr><br>        <td>lv 2</td><br>        <td>Stage</td><br>        <td>←</td><br>    </tr><br>    <tr><br>        <td>lv 1</td><br>        <td>Task</td><br>        <td>←</td><br>    </tr><br></table><h2 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.concurrent.&#123;<span class="type">Executors</span>, <span class="type">TimeUnit</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.storage.<span class="type">StorageLevel</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.receiver.<span class="type">Receiver</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ConcurrentJobsDemo</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 完整代码可见本文最后的附录</span></span><br><span class="line">    <span class="keyword">val</span> <span class="type">BLOCK_INTERVAL</span> = <span class="number">1</span> <span class="comment">// in seconds</span></span><br><span class="line">    <span class="keyword">val</span> <span class="type">BATCH_INTERVAL</span> = <span class="number">5</span> <span class="comment">// in seconds</span></span><br><span class="line">    <span class="keyword">val</span> <span class="type">CURRENT_JOBS</span> = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">    conf.setAppName(<span class="keyword">this</span>.getClass.getSimpleName)</span><br><span class="line">    conf.setMaster(<span class="string">"local[2]"</span>)</span><br><span class="line">    conf.set(<span class="string">"spark.streaming.blockInterval"</span>, <span class="string">s"<span class="subst">$&#123;BLOCK_INTERVAL&#125;</span>s"</span>)</span><br><span class="line">    conf.set(<span class="string">"spark.streaming.concurrentJobs"</span>, <span class="string">s"<span class="subst">$&#123;CURRENT_JOBS&#125;</span>"</span>)</span><br><span class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="type">BATCH_INTERVAL</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// DStream DAG 定义开始</span></span><br><span class="line">    <span class="keyword">val</span> inputStream = ssc.receiverStream(<span class="keyword">new</span> <span class="type">MyReceiver</span>)</span><br><span class="line">    inputStream.foreachRDD(_ =&gt; <span class="type">Thread</span>.sleep(<span class="type">Int</span>.<span class="type">MaxValue</span>)) <span class="comment">// output 1</span></span><br><span class="line">    inputStream.foreachRDD(_ =&gt; <span class="type">Thread</span>.sleep(<span class="type">Int</span>.<span class="type">MaxValue</span>)) <span class="comment">// output 2</span></span><br><span class="line">    <span class="comment">// DStream DAG 定义结束</span></span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">MyReceiver</span> <span class="keyword">extends</span> <span class="title">Receiver</span>[<span class="type">String</span>](<span class="params"><span class="type">StorageLevel</span>.<span class="type">MEMORY_ONLY</span></span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onStart</span></span>() &#123;</span><br><span class="line">      <span class="comment">// invoke store("str") every 100ms</span></span><br><span class="line">      <span class="type">Executors</span>.newScheduledThreadPool(<span class="number">1</span>).scheduleAtFixedRate(<span class="keyword">new</span> <span class="type">Runnable</span> &#123;</span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = store(<span class="string">"str"</span>)</span><br><span class="line">      &#125;, <span class="number">0</span>, <span class="number">100</span>, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onStop</span></span>() &#123;&#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><br><br><br></p><p>（本文完，参与本文的讨论请 <a href="https://github.com/proflin/CoolplaySpark/issues/4" target="_blank" rel="noopener">猛戳这里</a>，返回目录请 <a href="readme.md">猛戳这里</a>）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;JobScheduler-Job-JobSet-详解&quot;&gt;&lt;a href=&quot;#JobScheduler-Job-JobSet-详解&quot; class=&quot;headerlink&quot; title=&quot;JobScheduler, Job, JobSet 详解&quot;&gt;&lt;/a&gt;JobSch
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97/1.2%20DStream%20%E7%94%9F%E6%88%90%20RDD%20%E5%AE%9E%E4%BE%8B%E8%AF%A6%E8%A7%A3/"/>
    <id>http://yoursite.com/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/1.2 DStream 生成 RDD 实例详解/</id>
    <published>2018-02-09T03:49:13.888Z</published>
    <updated>2018-02-09T03:48:41.410Z</updated>
    
    <content type="html"><![CDATA[<h1 id="DStream-生成-RDD-实例详解"><a href="#DStream-生成-RDD-实例详解" class="headerlink" title="DStream 生成 RDD 实例详解"></a>DStream 生成 RDD 实例详解</h1><p><strong><em>[酷玩 Spark] Spark Streaming 源码解析系列</em></strong> ，返回目录请 <a href="readme.md">猛戳这里</a></p><p><a href="http://e.qq.com" target="_blank" rel="noopener">「腾讯·广点通」</a>技术团队荣誉出品</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">本系列内容适用范围：</span><br><span class="line"></span><br><span class="line">* 2017.07.11 update, Spark 2.2 全系列 √ (已发布：2.2.0)</span><br><span class="line">* 2017.10.02 update, Spark 2.1 全系列 √ (已发布：2.1.0, 2.1.1, 2.1.2)</span><br><span class="line">* 2016.11.14 update, Spark 2.0 全系列 √ (已发布：2.0.0, 2.0.1, 2.0.2)</span><br></pre></td></tr></table></figure><p><br><br><br></p><p>阅读本文前，请一定先阅读 <a href="0.1 Spark Streaming 实现思路与模块概述.md">Spark Streaming 实现思路与模块概述</a> 一文，其中概述了 Spark Streaming 的 4 大模块的基本作用，有了全局概念后再看本文对 <code>模块 1 DAG 静态定义</code> 细节的解释。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>我们在前面的文章讲过，Spark Streaming 的 <code>模块 1 DAG 静态定义</code> 要解决的问题就是如何把计算逻辑描述为一个 RDD DAG 的“模板”，在后面 Job 动态生成的时候，针对每个 batch，都将根据这个“模板”生成一个 RDD DAG 的实例。</p><p><img src="0.imgs/032.png" alt="image"></p><p>在 Spark Streaming 里，这个 RDD “模板”对应的具体的类是 <code>DStream</code>，RDD DAG “模板”对应的具体类是 <code>DStreamGraph</code>。</p><pre><code>DStream      的全限定名是：org.apache.spark.streaming.dstream.DStreamDStreamGraph 的全限定名是：org.apache.spark.streaming.DStreamGraph</code></pre><p>本文我们就来详解 <code>DStream</code> 最主要的功能：为每个 batch 生成 <code>RDD</code> 实例。</p><h2 id="Quick-Example"><a href="#Quick-Example" class="headerlink" title="Quick Example"></a>Quick Example</h2><p>我们在前文 <a href="1.1 DStream, DStreamGraph 详解.md">DStream, DStreamGraph 详解</a> 中引用了 <a href="0.imgs/http://spark.apache.org/docs/latest/streaming-programming-guide.html#a-quick-example">Spark Streaming 官方的 quick example</a> 的这段对 DStream DAG 的定义，注意看代码中的注释讲解内容：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ssc.socketTextStream() 将创建一个 SocketInputDStream；这个 InputDStream 的 SocketReceiver 将监听本机 9999 端口</span></span><br><span class="line"><span class="keyword">val</span> lines = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> words = lines.flatMap(_.split(<span class="string">" "</span>))      <span class="comment">// DStream transformation</span></span><br><span class="line"><span class="keyword">val</span> pairs = words.map(word =&gt; (word, <span class="number">1</span>))     <span class="comment">// DStream transformation</span></span><br><span class="line"><span class="keyword">val</span> wordCounts = pairs.reduceByKey(_ + _)    <span class="comment">// DStream transformation</span></span><br><span class="line">wordCounts.print()                           <span class="comment">// DStream output</span></span><br></pre></td></tr></table></figure><p>这里我们找到 <code>ssc.socketTextStream(&quot;localhost&quot;, 9999)</code> 的源码实现：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">socketStream</span></span>[<span class="type">T</span>: <span class="type">ClassTag</span>](hostname: <span class="type">String</span>, port: <span class="type">Int</span>, converter: (<span class="type">InputStream</span>) =&gt; <span class="type">Iterator</span>[<span class="type">T</span>], storageLevel: <span class="type">StorageLevel</span>): <span class="type">ReceiverInputDStream</span>[<span class="type">T</span>] = &#123;</span><br><span class="line">  <span class="keyword">new</span> <span class="type">SocketInputDStream</span>[<span class="type">T</span>](<span class="keyword">this</span>, hostname, port, converter, storageLevel)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>也就是 <code>ssc.socketTextStream()</code> 将 <code>new</code> 出来一个 <code>DStream</code> 具体子类 <code>SocketInputDStream</code> 的实例。</p><p>然后我们继续找到下一行 <code>lines.flatMap(_.split(&quot; &quot;))</code> 的源码实现：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](flatMapFunc: <span class="type">T</span> =&gt; <span class="type">Traversable</span>[<span class="type">U</span>]): <span class="type">DStream</span>[<span class="type">U</span>] = ssc.withScope &#123;</span><br><span class="line">  <span class="keyword">new</span> <span class="type">FlatMappedDStream</span>(<span class="keyword">this</span>, context.sparkContext.clean(flatMapFunc))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>也就是 <code>lines.flatMap(_.split(&quot; &quot;))</code> 将 <code>new</code> 出来一个 <code>DStream</code> 具体子类 <code>FlatMappedDStream</code> 的实例。</p><p>后面几行也是如此，所以我们如果用 DStream DAG 图来表示之前那段 quick example 的话，就是这个样子：</p><p><img src="1.imgs/010.png" alt="image"></p><p>也即，我们给出的那段代码，用具体的实现来替换的话，结果如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> lines = <span class="keyword">new</span> <span class="type">SocketInputDStream</span>(<span class="string">"localhost"</span>, <span class="number">9999</span>)   <span class="comment">// 类型是 SocketInputDStream</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> words = <span class="keyword">new</span> <span class="type">FlatMappedDStream</span>(lines, _.split(<span class="string">" "</span>))  <span class="comment">// 类型是 FlatMappedDStream</span></span><br><span class="line"><span class="keyword">val</span> pairs = <span class="keyword">new</span> <span class="type">MappedDStream</span>(words, word =&gt; (word, <span class="number">1</span>)) <span class="comment">// 类型是 MappedDStream</span></span><br><span class="line"><span class="keyword">val</span> wordCounts = <span class="keyword">new</span> <span class="type">ShuffledDStream</span>(pairs, _ + _)      <span class="comment">// 类型是 ShuffledDStream</span></span><br><span class="line"><span class="keyword">new</span> <span class="type">ForeachDStream</span>(wordCounts, cnt =&gt; cnt.print())      <span class="comment">// 类型是 ForeachDStream</span></span><br></pre></td></tr></table></figure><h2 id="DStream-通过-generatedRDD-管理已生成的-RDD"><a href="#DStream-通过-generatedRDD-管理已生成的-RDD" class="headerlink" title="DStream 通过 generatedRDD 管理已生成的 RDD"></a>DStream 通过 <code>generatedRDD</code> 管理已生成的 <code>RDD</code></h2><p><code>DStream</code> 内部用一个类型是 <code>HashMap</code> 的变量 <code>generatedRDD</code> 来记录已经生成过的 <code>RDD</code>：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[streaming] <span class="keyword">var</span> generatedRDDs = <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">Time</span>, <span class="type">RDD</span>[<span class="type">T</span>]] ()</span><br></pre></td></tr></table></figure><p><code>generatedRDD</code> 的 key 是一个 <code>Time</code>；这个 <code>Time</code> 是与用户指定的 <code>batchDuration</code>  对齐了的时间 —— 如每 15s 生成一个 batch 的话，那么这里的 key 的时间就是 <code>08h:00m:00s</code>，<code>08h:00m:15s</code> 这种，所以其实也就代表是第几个 batch。<code>generatedRDD</code> 的 value 就是 <code>RDD</code> 的实例。</p><p>需要注意，每一个不同的 <code>DStream</code> 实例，都有一个自己的 <code>generatedRDD</code>。如在下图中，<code>DStream a, b, c, d</code> 各有自己的 <code>generatedRDD</code> 变量；图中也示意了 <code>DStream a</code> 的 <code>generatedRDD</code> 变量。</p><p><img src="0.imgs/045.png" alt="image"></p><p><code>DStream</code> 对这个 <code>HashMap</code> 的存取主要是通过 <code>getOrCompute(time: Time)</code> 方法，实现也很简单，就是一个 —— 查表，如果有就直接返回，如果没有就生成了放入表、再返回 —— 的逻辑：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[streaming] <span class="keyword">final</span> <span class="function"><span class="keyword">def</span> <span class="title">getOrCompute</span></span>(time: <span class="type">Time</span>): <span class="type">Option</span>[<span class="type">RDD</span>[<span class="type">T</span>]] = &#123;</span><br><span class="line">    <span class="comment">// 从 generatedRDDs 里 get 一下：如果有 rdd 就返回，没有 rdd 就进行 orElse 下面的 rdd 生成步骤</span></span><br><span class="line">    generatedRDDs.get(time).orElse &#123;</span><br><span class="line">      <span class="comment">// 验证 time 需要是 valid</span></span><br><span class="line">      <span class="keyword">if</span> (isTimeValid(time)) &#123;</span><br><span class="line">        <span class="comment">// 然后调用 compute(time) 方法获得 rdd 实例，并存入 rddOption 变量</span></span><br><span class="line">        <span class="keyword">val</span> rddOption = createRDDWithLocalProperties(time) &#123;</span><br><span class="line">          <span class="type">PairRDDFunctions</span>.disableOutputSpecValidation.withValue(<span class="literal">true</span>) &#123;</span><br><span class="line">            compute(time)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        rddOption.foreach &#123; <span class="keyword">case</span> newRDD =&gt;</span><br><span class="line">          <span class="keyword">if</span> (storageLevel != <span class="type">StorageLevel</span>.<span class="type">NONE</span>) &#123;</span><br><span class="line">            newRDD.persist(storageLevel)</span><br><span class="line">            logDebug(<span class="string">s"Persisting RDD <span class="subst">$&#123;newRDD.id&#125;</span> for time <span class="subst">$time</span> to <span class="subst">$storageLevel</span>"</span>)</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">if</span> (checkpointDuration != <span class="literal">null</span> &amp;&amp; (time - zeroTime).isMultipleOf(checkpointDuration)) &#123;</span><br><span class="line">            newRDD.checkpoint()</span><br><span class="line">            logInfo(<span class="string">s"Marking RDD <span class="subst">$&#123;newRDD.id&#125;</span> for time <span class="subst">$time</span> for checkpointing"</span>)</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// 将刚刚实例化出来的 rddOption 放入 generatedRDDs 对应的 time 位置</span></span><br><span class="line">          generatedRDDs.put(time, newRDD)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 返回刚刚实例化出来的 rddOption</span></span><br><span class="line">        rddOption</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="type">None</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>最主要还是调用了一个 abstract 的 <code>compute(time)</code> 方法。这个方法用于生成 <code>RDD</code> 实例，生成后被放进 <code>generatedRDD</code> 里供后续的查询和使用。这个 <code>compute(time)</code> 方法在 <code>DStream</code> 类里是 abstract 的，但在每个具体的子类里都提供了实现。</p><h2 id="a-InputDStream-的-compute-time-实现"><a href="#a-InputDStream-的-compute-time-实现" class="headerlink" title="(a) InputDStream 的 compute(time) 实现"></a>(a) <code>InputDStream</code> 的 <code>compute(time)</code> 实现</h2><p><code>InputDStream</code> 是个有很多子类的抽象类，我们看一个具体的子类 <code>FileInputDStream</code>。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 FileInputDStream</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(validTime: <span class="type">Time</span>): <span class="type">Option</span>[<span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]] = &#123;</span><br><span class="line">    <span class="comment">// 通过一个 findNewFiles() 方法，找到 validTime 以后产生的新 file 的数据</span></span><br><span class="line">    <span class="keyword">val</span> newFiles = findNewFiles(validTime.milliseconds)</span><br><span class="line">    logInfo(<span class="string">"New files at time "</span> + validTime + <span class="string">":\n"</span> + newFiles.mkString(<span class="string">"\n"</span>))</span><br><span class="line">    batchTimeToSelectedFiles += ((validTime, newFiles))</span><br><span class="line">    recentlySelectedFiles ++= newFiles</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 找到了一些新 file；以新 file 的数组为参数，通过 filesToRDD() 生成单个 RDD 实例 rdds</span></span><br><span class="line">    <span class="keyword">val</span> rdds = <span class="type">Some</span>(filesToRDD(newFiles))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> metadata = <span class="type">Map</span>(</span><br><span class="line">      <span class="string">"files"</span> -&gt; newFiles.toList,</span><br><span class="line">      <span class="type">StreamInputInfo</span>.<span class="type">METADATA_KEY_DESCRIPTION</span> -&gt; newFiles.mkString(<span class="string">"\n"</span>))</span><br><span class="line">    <span class="keyword">val</span> inputInfo = <span class="type">StreamInputInfo</span>(id, <span class="number">0</span>, metadata)</span><br><span class="line">    ssc.scheduler.inputInfoTracker.reportInfo(validTime, inputInfo)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 返回生成的单个 RDD 实例 rdds</span></span><br><span class="line">    rdds</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>而 <code>filesToRDD()</code> 实现如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 FileInputDStream</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">filesToRDD</span></span>(files: <span class="type">Seq</span>[<span class="type">String</span>]): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)] = &#123;</span><br><span class="line">  <span class="comment">// 对每个 file，都 sc.newAPIHadoopFile(file) 来生成一个 RDD</span></span><br><span class="line">  <span class="keyword">val</span> fileRDDs = files.map &#123; file =&gt;</span><br><span class="line">    <span class="keyword">val</span> rdd = serializableConfOpt.map(_.value) <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Some</span>(config) =&gt; context.sparkContext.newAPIHadoopFile(</span><br><span class="line">        file,</span><br><span class="line">        fm.runtimeClass.asInstanceOf[<span class="type">Class</span>[<span class="type">F</span>]],</span><br><span class="line">        km.runtimeClass.asInstanceOf[<span class="type">Class</span>[<span class="type">K</span>]],</span><br><span class="line">        vm.runtimeClass.asInstanceOf[<span class="type">Class</span>[<span class="type">V</span>]],</span><br><span class="line">        config)</span><br><span class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; context.sparkContext.newAPIHadoopFile[<span class="type">K</span>, <span class="type">V</span>, <span class="type">F</span>](file)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (rdd.partitions.size == <span class="number">0</span>) &#123;</span><br><span class="line">      logError(<span class="string">"File "</span> + file + <span class="string">" has no data in it. Spark Streaming can only ingest "</span> +</span><br><span class="line">        <span class="string">"files that have been \"moved\" to the directory assigned to the file stream. "</span> +</span><br><span class="line">        <span class="string">"Refer to the streaming programming guide for more details."</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    rdd</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 将每个 file 对应的 RDD 进行 union，返回一个 union 后的 UnionRDD</span></span><br><span class="line">  <span class="keyword">new</span> <span class="type">UnionRDD</span>(context.sparkContext, fileRDDs)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所以，结合以上 <code>compute(validTime: Time)</code> 和 <code>filesToRDD(files: Seq[String])</code> 方法，我们得出 <code>FileInputDStream</code> 为每个 batch 生成 RDD 的实例过程如下：</p><ul><li>(1) 先通过一个 findNewFiles() 方法，找到 validTime 以后产生的多个新 file</li><li>(2) 对每个新 file，都将其作为参数调用 sc.newAPIHadoopFile(file)，生成一个 RDD 实例</li><li>(3) 将 (2) 中的多个新 file 对应的多个 RDD 实例进行 union，返回一个 union 后的 UnionRDD</li></ul><p>其它 <code>InputDStream</code> 的为每个 batch 生成 <code>RDD</code> 实例的过程也比较类似了。</p><h2 id="b-一般-DStream-的-compute-time-实现"><a href="#b-一般-DStream-的-compute-time-实现" class="headerlink" title="(b) 一般 DStream 的 compute(time) 实现"></a>(b) 一般 <code>DStream</code> 的 <code>compute(time)</code> 实现</h2><p>前一小节的 <code>InputDStream</code> 没有上游依赖的 <code>DStream</code>，可以直接为每个 batch 产生 <code>RDD</code> 实例。一般 <code>DStream</code> 都是由  <em>transofrmation</em> 生成的，都有上游依赖的 <code>DStream</code>，所以为了为 batch 产生 <code>RDD</code> 实例，就需要在 <code>compute(time)</code> 方法里先获取上游依赖的 <code>DStream</code> 产生的 <code>RDD</code> 实例。</p><p>具体的，我们看两个具体 <code>DStream</code> —— <code>MappedDStream</code>, <code>FilteredDStream</code> —— 的实现：</p><h3 id="MappedDStream-的-compute-time-实现"><a href="#MappedDStream-的-compute-time-实现" class="headerlink" title="MappedDStream 的 compute(time) 实现"></a><code>MappedDStream</code> 的 <code>compute(time)</code> 实现</h3><p><code>MappedDStream</code> 很简单，全类实现如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.apache.spark.streaming.dstream</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Duration</span>, <span class="type">Time</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> scala.reflect.<span class="type">ClassTag</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[streaming]</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MappedDStream</span>[<span class="type">T</span>: <span class="type">ClassTag</span>, <span class="type">U</span>: <span class="type">ClassTag</span>] (<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    parent: <span class="type">DStream</span>[<span class="type">T</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">    mapFunc: <span class="type">T</span> =&gt; <span class="type">U</span></span></span></span><br><span class="line"><span class="class"><span class="params">  </span>) <span class="keyword">extends</span> <span class="title">DStream</span>[<span class="type">U</span>](<span class="params">parent.ssc</span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">dependencies</span></span>: <span class="type">List</span>[<span class="type">DStream</span>[_]] = <span class="type">List</span>(parent)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">slideDuration</span></span>: <span class="type">Duration</span> = parent.slideDuration</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(validTime: <span class="type">Time</span>): <span class="type">Option</span>[<span class="type">RDD</span>[<span class="type">U</span>]] = &#123;</span><br><span class="line">    parent.getOrCompute(validTime).map(_.map[<span class="type">U</span>](mapFunc))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到，首先在构造函数里传入了两个重要内容：</p><ul><li>parent，是本 <code>MappedDStream</code> 上游依赖的 <code>DStream</code></li><li>mapFunc，是本次 map() 转换的具体函数<ul><li>在前文 <a href="1.1 DStream, DStreamGraph 详解.md">DStream, DStreamGraph 详解</a> 中的 quick example 里的 <code>val pairs = words.map(word =&gt; (word, 1))</code> 的 <code>mapFunc</code> 就是 <code>word =&gt; (word, 1)</code></li></ul></li></ul><p>所以在 <code>compute(time)</code> 的具体实现里，就很简单了：</p><ul><li>(1) 获取 parent <code>DStream</code> 在本 batch 里对应的 <code>RDD</code> 实例</li><li>(2) 在这个 parent <code>RDD</code> 实例上，以 <code>mapFunc</code> 为参数调用 <code>.map(mapFunc)</code> 方法，将得到的新 <code>RDD</code> 实例返回<ul><li>完全相当于用 RDD API 写了这样的代码：<code>return parentRDD.map(mapFunc)</code></li></ul></li></ul><h3 id="FilteredDStream-的-compute-time-实现"><a href="#FilteredDStream-的-compute-time-实现" class="headerlink" title="FilteredDStream 的 compute(time) 实现"></a><code>FilteredDStream</code> 的 <code>compute(time)</code> 实现</h3><p>再看看 <code>FilteredDStream</code> 的全部实现：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.apache.spark.streaming.dstream</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Duration</span>, <span class="type">Time</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> scala.reflect.<span class="type">ClassTag</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[streaming]</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FilteredDStream</span>[<span class="type">T</span>: <span class="type">ClassTag</span>](<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    parent: <span class="type">DStream</span>[<span class="type">T</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">    filterFunc: <span class="type">T</span> =&gt; <span class="type">Boolean</span></span></span></span><br><span class="line"><span class="class"><span class="params">  </span>) <span class="keyword">extends</span> <span class="title">DStream</span>[<span class="type">T</span>](<span class="params">parent.ssc</span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">dependencies</span></span>: <span class="type">List</span>[<span class="type">DStream</span>[_]] = <span class="type">List</span>(parent)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">slideDuration</span></span>: <span class="type">Duration</span> = parent.slideDuration</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(validTime: <span class="type">Time</span>): <span class="type">Option</span>[<span class="type">RDD</span>[<span class="type">T</span>]] = &#123;</span><br><span class="line">    parent.getOrCompute(validTime).map(_.filter(filterFunc))</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同 <code>MappedDStream</code> 一样，<code>FilteredDStream</code> 也在构造函数里传入了两个重要内容：</p><ul><li>parent，是本 <code>FilteredDStream</code> 上游依赖的 <code>DStream</code></li><li>filterFunc，是本次 filter() 转换的具体函数</li></ul><p>所以在 <code>compute(time)</code> 的具体实现里，就很简单了：</p><ul><li>(1) 获取 parent <code>DStream</code> 在本 batch 里对应的 <code>RDD</code> 实例</li><li>(2) 在这个 parent <code>RDD</code> 实例上，以 <code>filterFunc</code> 为参数调用 <code>.filter(filterFunc)</code> 方法，将得到的新 <code>RDD</code> 实例返回<ul><li>完全相当于用 RDD API 写了这样的代码：<code>return parentRDD.filter(filterFunc)</code></li></ul></li></ul><h3 id="总结一般-DStream-的-compute-time-实现"><a href="#总结一般-DStream-的-compute-time-实现" class="headerlink" title="总结一般 DStream 的 compute(time) 实现"></a>总结一般 <code>DStream</code> 的 <code>compute(time)</code> 实现</h3><p>总结上面 <code>MappedDStream</code> 和 <code>FilteredDStream</code> 的实现，可以看到：</p><ul><li><code>DStream</code> 的 <code>.map()</code> 操作生成了 <code>MappedDStream</code>，而 <code>MappedDStream</code> 在每个 batch 里生成 <code>RDD</code> 实例时，将对 <code>parentRDD</code> 调用 <code>RDD</code> 的 <code>.map()</code> 操作 —— <strong><code>DStream.map()</code> 操作完美复制为每个 batch 的 <code>RDD.map()</code> 操作</strong></li><li><code>DStream</code> 的 <code>.filter()</code> 操作生成了 <code>FilteredDStream</code>，而 <code>FilteredDStream</code> 在每个 batch 里生成 <code>RDD</code> 实例时，将对 <code>parentRDD</code> 调用 <code>RDD</code> 的 <code>.filter()</code> 操作 —— <strong><code>DStream.filter()</code> 操作完美复制为每个 batch 的 <code>RDD.filter()</code> 操作</strong></li></ul><p>在最开始， <code>DStream</code> 的 <em>transformation</em> 的 API 设计与 <code>RDD</code> 的 <em>transformation</em> 设计保持了一致，就使得，每一个 <code>dStreamA</code>.<em>transformation</em>() 得到的新 <code>dStreamB</code> 能将 <code>dStreamA.</code><em>transformation()</em> 操作完美复制为每个 batch 的 <code>rddA.</code><em>transformation()</em> 操作。</p><p><strong>这也就是 <code>DStream</code> 能够作为 <code>RDD</code> 模板，在每个 batch 里实例化 <code>RDD</code> 的根本原因。</strong></p><h2 id="c-ForEachDStream-的-compute-time-实现"><a href="#c-ForEachDStream-的-compute-time-实现" class="headerlink" title="(c) ForEachDStream 的 compute(time) 实现"></a>(c) <code>ForEachDStream</code> 的 <code>compute(time)</code> 实现</h2><p>上面分析了 <code>DStream</code> 的 <em>transformation</em> 如何在 <code>compute(time)</code> 里复制为 <code>RDD</code> 的 <em>transformation</em>，下面我们分析 <code>DStream</code> 的 <em>output</em> 如何在 <code>compute(time)</code> 里复制为 <code>RDD</code> 的 <em>action</em>。</p><p>我们前面讲过，对一个 <code>DStream</code> 进行 <em>output</em> 操作，将生成一个新的 <code>ForEachDStream</code>，这个 <code>ForEachDStream</code> 用一个 <code>foreachFunc</code> 成员来记录 <em>output</em> 的具体内容。</p><p><code>ForEachDStream</code> 全部实现如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.apache.spark.streaming.dstream</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Duration</span>, <span class="type">Time</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.scheduler.<span class="type">Job</span></span><br><span class="line"><span class="keyword">import</span> scala.reflect.<span class="type">ClassTag</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>[streaming]</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ForEachDStream</span>[<span class="type">T</span>: <span class="type">ClassTag</span>] (<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">    parent: <span class="type">DStream</span>[<span class="type">T</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">    foreachFunc: (<span class="type">RDD</span>[<span class="type">T</span>], <span class="type">Time</span></span>) <span class="title">=&gt;</span> <span class="title">Unit</span></span></span><br><span class="line"><span class="class">  ) <span class="keyword">extends</span> <span class="title">DStream</span>[<span class="type">Unit</span>](<span class="params">parent.ssc</span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">dependencies</span></span>: <span class="type">List</span>[<span class="type">DStream</span>[_]] = <span class="type">List</span>(parent)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">slideDuration</span></span>: <span class="type">Duration</span> = parent.slideDuration</span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(validTime: <span class="type">Time</span>): <span class="type">Option</span>[<span class="type">RDD</span>[<span class="type">Unit</span>]] = <span class="type">None</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">generateJob</span></span>(time: <span class="type">Time</span>): <span class="type">Option</span>[<span class="type">Job</span>] = &#123;</span><br><span class="line">    parent.getOrCompute(time) <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">Some</span>(rdd) =&gt;</span><br><span class="line">        <span class="keyword">val</span> jobFunc = () =&gt; createRDDWithLocalProperties(time) &#123;</span><br><span class="line">          ssc.sparkContext.setCallSite(creationSite)</span><br><span class="line">          foreachFunc(rdd, time)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">Job</span>(time, jobFunc))</span><br><span class="line">      <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="type">None</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同前面一样，<code>ForEachDStream</code> 也在构造函数里传入了两个重要内容：</p><ul><li>parent，是本 <code>ForEachDStream</code> 上游依赖的 <code>DStream</code></li><li>foreachFunc，是本次 <em>output</em> 的具体函数</li></ul><p>所以在 <code>compute(time)</code> 的具体实现里，就很简单了：</p><ul><li>(1) 获取 parent <code>DStream</code> 在本 batch 里对应的 <code>RDD</code> 实例</li><li>(2) 以这个 parent <code>RDD</code> 和本次 batch 的 time 为参数，调用 <code>foreachFunc(parentRDD, time)</code> 方法</li></ul><p>例如，我们看看 <code>DStream.print()</code> 里 <code>foreachFunc(rdd, time)</code> 的具体实现：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foreachFunc</span></span>: (<span class="type">RDD</span>[<span class="type">T</span>], <span class="type">Time</span>) =&gt; <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> firstNum = rdd.take(num + <span class="number">1</span>)</span><br><span class="line">  println(<span class="string">"-------------------------------------------"</span>)</span><br><span class="line">  println(<span class="string">"Time: "</span> + time)</span><br><span class="line">  println(<span class="string">"-------------------------------------------"</span>)</span><br><span class="line">  firstNum.take(num).foreach(println)</span><br><span class="line">  <span class="keyword">if</span> (firstNum.length &gt; num) println(<span class="string">"..."</span>)</span><br><span class="line">  println()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>就可以知道，如果对着 <code>rdd</code> 调用上面这个 <code>foreachFunc</code> 的话，就会在每个 batch 里，都会在 <code>rdd</code> 上执行 <code>.take()</code> 获取一些元素到 driver 端，然后再 <code>.foreach(println)</code>；也就形成了在 driver 端打印这个 <code>DStream</code> 的一些内容的效果了！</p><h2 id="DStreamGraph-生成-RDD-DAG-实例"><a href="#DStreamGraph-生成-RDD-DAG-实例" class="headerlink" title="DStreamGraph 生成 RDD DAG 实例"></a>DStreamGraph 生成 RDD DAG 实例</h2><p>在前文 <a href="0.1 Spark Streaming 实现思路与模块概述.md">Spark Streaming 实现思路与模块概述</a> 中，我们曾经讲过，在每个 batch 时，都由 <code>JobGenerator</code> 来要求 <code>RDD</code> DAG “模板” 来创建 <code>RDD</code> DAG 实例，即下图中的第 (2) 步。</p><p><img src="0.imgs/055.png" alt="image"></p><p>具体的，是 <code>JobGenerator</code> 来调用 <code>DStreamGraph</code> 的 <code>generateJobs(time)</code> 方法。</p><p>那么翻出来 <code>generateJobs()</code> 的实现：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 DStreamGraph</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generateJobs</span></span>(time: <span class="type">Time</span>): <span class="type">Seq</span>[<span class="type">Job</span>] = &#123;</span><br><span class="line">  logDebug(<span class="string">"Generating jobs for time "</span> + time)</span><br><span class="line">  <span class="keyword">val</span> jobs = <span class="keyword">this</span>.synchronized &#123;</span><br><span class="line">    outputStreams.flatMap(outputStream =&gt; outputStream.generateJob(time))</span><br><span class="line">  &#125;</span><br><span class="line">  logDebug(<span class="string">"Generated "</span> + jobs.length + <span class="string">" jobs for time "</span> + time)</span><br><span class="line">  jobs</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>也就是说，是 <code>DStreamGraph</code> 继续调用了每个 <code>outputStream</code> 的 <code>generateJob(time)</code> 方法 —— 而我们知道，只有 ForEachDStream 是 outputStream，所以将调用 <code>ForEachDStream</code> 的 <code>generateJob(time)</code> 方法。</p><p><img src="1.imgs/035.png" alt="image"></p><p>举个例子，如上图，由于我们在代码里的两次 print() 操作产生了两个 <code>ForEachDStream</code> 节点 <code>x</code> 和 <code>y</code>，那么 <code>DStreamGraph.generateJobs(time)</code> 就将先后调用 <code>x.generateJob(time)</code> 和 <code>y.generateJob(time)</code> 方法，并将各获得一个 Job。</p><p>但是…… <code>x.generateJob(time)</code> 和 <code>y.generateJob(time)</code> 的返回值 Job 到底是啥？那我们先插播一下 <code>Job</code>。</p><h3 id="Spark-Streaming-的-Job"><a href="#Spark-Streaming-的-Job" class="headerlink" title="Spark Streaming 的 Job"></a>Spark Streaming 的 Job</h3><p>Spark Streaming 里重新定义了一个 <code>Job</code> 类，功能与 <code>Java</code> 的 <code>Runnable</code> 差不多：一个 <code>Job</code> 能够自定义一个 <code>func() 函数</code>，而 <code>Job</code> 的 <code>.run()</code> 方法实现就是执行这个 <code>func()</code>。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 节选自 org.apache.spark.streaming.scheduler.Job</span></span><br><span class="line"><span class="keyword">private</span>[streaming]</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Job</span>(<span class="params">val time: <span class="type">Time</span>, func: (</span>) <span class="title">=&gt;</span> <span class="title">_</span>) </span>&#123;</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line">    _result = <span class="type">Try</span>(func())</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所以其实 <code>Job</code> 的本质是将实际的 <code>func()</code> 定义和 <code>func()</code> 被调用分离了 —— 就像 <code>Runnable</code> 是将 <code>run()</code> 的具体定义和 <code>run()</code> 的被调用分离了一样。</p><p>下面我们继续来看 <code>x.generateJob(time)</code> 和 <code>y.generateJob(time)</code> 实现。</p><h3 id="x-generateJob-time-过程"><a href="#x-generateJob-time-过程" class="headerlink" title="x.generateJob(time) 过程"></a><code>x.generateJob(time)</code> 过程</h3><p><code>x</code> 是一个 <code>ForEachDStream</code>，其 <code>generateJob(time)</code> 的实现如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 来自 ForEachDStream</span></span><br><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">generateJob</span></span>(time: <span class="type">Time</span>): <span class="type">Option</span>[<span class="type">Job</span>] = &#123;</span><br><span class="line">  <span class="comment">// 【首先调用 parentDStream 的 getOrCompute() 来获取 parentRDD】</span></span><br><span class="line">  parent.getOrCompute(time) <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Some</span>(rdd) =&gt;</span><br><span class="line">      <span class="comment">// 【然后定义 jobFunc 为在 parentRDD 上执行 foreachFun() 】</span></span><br><span class="line">      <span class="keyword">val</span> jobFunc = () =&gt; createRDDWithLocalProperties(time) &#123;</span><br><span class="line">        ssc.sparkContext.setCallSite(creationSite)</span><br><span class="line">        foreachFunc(rdd, time)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 【最后将 jobFunc 包装为 Job 返回】</span></span><br><span class="line">      <span class="type">Some</span>(<span class="keyword">new</span> <span class="type">Job</span>(time, jobFunc))</span><br><span class="line">    <span class="keyword">case</span> <span class="type">None</span> =&gt; <span class="type">None</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>就是这里牵扯到了 <code>x</code> 的 <code>parentDStream.getOrCompute(time)</code>，即 <code>d.getOrCompute(time)</code>；而 <code>d.getOrCompute(time)</code> 会牵扯 <code>c.getOrCompute(time)</code>，乃至 <code>a.getOrCompute(time)</code>, <code>b.getOrCompute(time)</code></p><p>用一个时序图来表达这里的调用关系会清晰很多：</p><p><img src="1.imgs/050.png" alt="image"></p><p>所以最后的时候，由于对 <code>x.generateJob(time)</code> 形成的递归调用， 将形成一个 Job，其内容 <code>func</code> 如下图：</p><p><img src="1.imgs/051.png" alt="image"></p><h3 id="y-generateJob-time-过程"><a href="#y-generateJob-time-过程" class="headerlink" title="y.generateJob(time) 过程"></a><code>y.generateJob(time)</code> 过程</h3><p>同样的，<code>y</code> 节点生成 Job 的过程，与 <code>x</code> 节点的过程非常类似，只是在 <code>b.getOrCompute(time)</code> 时，会命中 <code>get(time)</code> 而不需要触发 <code>compute(time)</code> 了，这是因为该 <code>RDD</code> 实例已经在 <code>x</code> 节点的生成过程中被实例化过一次，所以在这里只需要取出来用就可以了。</p><p>同样，最后的时候，由于对 <code>y.generateJob(time)</code> 形成的递归调用， 将形成一个 Job，其内容 <code>func</code> 如下图：</p><p><img src="1.imgs/052.png" alt="image"></p><h3 id="返回-Seq-Job"><a href="#返回-Seq-Job" class="headerlink" title="返回 Seq[Job]"></a>返回 Seq[Job]</h3><p>所以当 <code>DStreamGraph.generateJobs(time)</code> 结束时，会返回多个 <code>Job</code>，是因为作为 <code>output stream</code> 的每个 <code>ForEachDStream</code> 都通过 <code>generateJob(time)</code> 方法贡献了一个 <code>Job</code>。</p><p><img src="1.imgs/035.png" alt="image"></p><p>比如在上图里，<code>DStreamGraph.generateJobs(time)</code> 会返回一个 <code>Job</code> 的序列，其大小为 <code>2</code>，其内容分别为：</p><p><img src="1.imgs/053.png" alt="image"></p><p>至此，在给定的 batch 里，<code>DStreamGraph.generateJobs(time)</code> 的工作已经全部完成，<code>Seq[Job]</code> 作为结果返回给 <code>JobGenerator</code> 后，<code>JobGenerator</code> 也会尽快提交到 <code>JobSheduler</code> 那里尽快调用 <code>Job.run()</code> 使得这 <code>2</code> 个 <code>RDD</code> DAG 尽快运行起来。</p><p>而且，每个新 batch 生成时，都会调用 <code>DStreamGraph.generateJobs(time)</code>，也进而触发我们之前讨论这个 <code>Job</code> 生成过程，周而复始。</p><p>到此，整个 <code>DStream</code> 作为 <code>RDD</code> 的 “模板” 为每个 batch 实例化 <code>RDD</code>，<code>DStreamGraph</code> 作为 <code>RDD</code> DAG 的 “模板” 为每个 batch 实例化 <code>RDD</code> DAG，就分析完成了。</p><p><br><br><br></p><p>（本文完，参与本文的讨论请 <a href="https://github.com/proflin/CoolplaySpark/issues/3" target="_blank" rel="noopener">猛戳这里</a>，返回目录请 <a href="readme.md">猛戳这里</a>）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;DStream-生成-RDD-实例详解&quot;&gt;&lt;a href=&quot;#DStream-生成-RDD-实例详解&quot; class=&quot;headerlink&quot; title=&quot;DStream 生成 RDD 实例详解&quot;&gt;&lt;/a&gt;DStream 生成 RDD 实例详解&lt;/h1&gt;&lt;p&gt;&lt;s
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97/1.1%20DStream,%20DStreamGraph%20%E8%AF%A6%E8%A7%A3/"/>
    <id>http://yoursite.com/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/1.1 DStream, DStreamGraph 详解/</id>
    <published>2018-02-09T03:49:13.878Z</published>
    <updated>2018-02-09T03:48:41.409Z</updated>
    
    <content type="html"><![CDATA[<h1 id="DStream-DStreamGraph-详解"><a href="#DStream-DStreamGraph-详解" class="headerlink" title="DStream, DStreamGraph 详解"></a>DStream, DStreamGraph 详解</h1><p><strong><em>[酷玩 Spark] Spark Streaming 源码解析系列</em></strong> ，返回目录请 <a href="readme.md">猛戳这里</a></p><p><a href="http://e.qq.com" target="_blank" rel="noopener">「腾讯·广点通」</a>技术团队荣誉出品</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">本系列内容适用范围：</span><br><span class="line"></span><br><span class="line">* 2017.07.11 update, Spark 2.2 全系列 √ (已发布：2.2.0)</span><br><span class="line">* 2017.10.02 update, Spark 2.1 全系列 √ (已发布：2.1.0, 2.1.1, 2.1.2)</span><br><span class="line">* 2016.11.14 update, Spark 2.0 全系列 √ (已发布：2.0.0, 2.0.1, 2.0.2)</span><br></pre></td></tr></table></figure><p><br><br><br></p><p>阅读本文前，请一定先阅读 <a href="0.1 Spark Streaming 实现思路与模块概述.md">Spark Streaming 实现思路与模块概述</a> 一文，其中概述了 Spark Streaming 的 4 大模块的基本作用，有了全局概念后再看本文对 <code>模块 1 DAG 静态定义</code> 细节的解释。</p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>我们在前面的文章讲过，Spark Streaming 的 <code>模块 1 DAG 静态定义</code> 要解决的问题就是如何把计算逻辑描述为一个 RDD DAG 的“模板”，在后面 Job 动态生成的时候，针对每个 batch，都将根据这个“模板”生成一个 RDD DAG 的实例。</p><p><img src="0.imgs/032.png" alt="image"></p><p>在 Spark Streaming 里，这个 RDD “模板”对应的具体的类是 <code>DStream</code>，RDD DAG “模板”对应的具体类是 <code>DStreamGraph</code>。</p><pre><code>DStream      的全限定名是：org.apache.spark.streaming.dstream.DStreamDStreamGraph 的全限定名是：org.apache.spark.streaming.DStreamGraph</code></pre><p><img src="1.imgs/005.png" alt="image"></p><p>本文涉及的类在 Spark Streaming 中的位置如上图所示；下面详解 <code>DStream</code>, <code>DStreamGraph</code>。</p><h2 id="DStream-transformation-output-operation-解析"><a href="#DStream-transformation-output-operation-解析" class="headerlink" title="DStream, transformation, output operation 解析"></a>DStream, <em>transformation</em>, <em>output operation</em> 解析</h2><p>回想一下，RDD 的定义是一个只读、分区的数据集（<code>an RDD is a read-only, partitioned collection of records</code>），而 DStream 又是 RDD 的模板，所以我们把 Dstream 也视同数据集。</p><p>我们先看看定义在这个 DStream 数据集上的<em>转换</em>（<strong><em>transformation</em></strong>）和 <em>输出</em>（<strong><em>output</em></strong>）。</p><p>现在假设我们有一个 <code>DStream</code> 数据集 a：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> a = <span class="keyword">new</span> <span class="type">DStream</span>()</span><br></pre></td></tr></table></figure><p>那么通过 <code>filter()</code> 操作就可以从 <code>a</code> 生成一个新的 <code>DStream</code> 数据集 <code>b</code>：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> b = a.filter(func)</span><br></pre></td></tr></table></figure><p>这里能够由已有的 <code>DStream</code> 产生新 <code>DStream</code> 的操作统称 <strong><em>transformation</em></strong>。一些典型的 <em>tansformation</em> 包括 <code>map()</code>, <code>filter()</code>, <code>reduce()</code>, <code>join()</code> 等 。</p><blockquote><p>Transformation    Meaning<br>map(func)    Return a new DStream by passing each element of the source DStream through a function func.<br>flatMap(func)    Similar to map, but each input item can be mapped to 0 or more output items.<br>filter(func)    Return a new DStream by selecting only the records of the source DStream on which func returns true.<br>repartition(numPartitions)    Changes the level of parallelism in this DStream by creating more or fewer partitions.</p></blockquote><p>另一些不产生新 <code>DStream</code> 数据集，而是只在已有 <code>DStream</code> 数据集上进行的操作和输出，统称为 <strong><em>output</em></strong>。比如 <code>a.print()</code> 就不会产生新的数据集，而是只是将 <code>a</code> 的内容打印出来，所以 <code>print()</code> 就是一种 <em>output</em> 操作。一些典型的 <em>output</em> 包括 <code>print()</code>, <code>saveAsTextFiles()</code>, <code>saveAsHadoopFiles()</code>, <code>foreachRDD()</code> 等。</p><blockquote><p>print()    Prints the first ten elements of every batch of data in a DStream on the driver node running the streaming application. This is useful for development and debugging.<br>Python API This is called pprint() in the Python API.<br>saveAsTextFiles(prefix, [suffix])    Save this DStream’s contents as text files. The file name at each batch interval is generated based on prefix and suffix: “prefix-TIME_IN_MS[.suffix]”.<br>saveAsObjectFiles(prefix, [suffix])    Save this DStream’s contents as SequenceFiles of serialized Java objects. The file name at each batch interval is generated based on prefix and suffix: “prefix-TIME_IN_MS[.suffix]”.<br>Python API This is not available in the Python API.<br>saveAsHadoopFiles(prefix, [suffix])    Save this DStream’s contents as Hadoop files. The file name at each batch interval is generated based on prefix and suffix: “prefix-TIME_IN_MS[.suffix]”.<br>Python API This is not available in the Python API.<br>foreachRDD(func)    The most generic output operator that applies a function, func, to each RDD generated from the stream. This function should push the data in each RDD to an external system, such as saving the RDD to files, or writing it over the network to a database. Note that the function func is executed in the driver process running the streaming application, and will usually have RDD actions in it that will force the computation of the streaming RDDs.</p></blockquote><h2 id="一段-quick-example-的-transformation-output-解析"><a href="#一段-quick-example-的-transformation-output-解析" class="headerlink" title="一段 quick example 的 transformation, output 解析"></a>一段 quick example 的 <em>transformation</em>, <em>output</em> 解析</h2><p>我们看一下 <a href="0.imgs/http://spark.apache.org/docs/latest/streaming-programming-guide.html#a-quick-example">Spark Streaming 官方的 quick example</a> 的这段对 DStream DAG 的定义，注意看代码中的注释讲解内容：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ssc.socketTextStream() 将创建一个 SocketInputDStream；这个 InputDStream 的 SocketReceiver 将监听本机 9999 端口</span></span><br><span class="line"><span class="keyword">val</span> lines = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> words = lines.flatMap(_.split(<span class="string">" "</span>))      <span class="comment">// DStream transformation</span></span><br><span class="line"><span class="keyword">val</span> pairs = words.map(word =&gt; (word, <span class="number">1</span>))     <span class="comment">// DStream transformation</span></span><br><span class="line"><span class="keyword">val</span> wordCounts = pairs.reduceByKey(_ + _)    <span class="comment">// DStream transformation</span></span><br><span class="line">wordCounts.print()                           <span class="comment">// DStream output</span></span><br></pre></td></tr></table></figure><p>这里我们找到 <code>ssc.socketTextStream(&quot;localhost&quot;, 9999)</code> 的源码实现：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">socketStream</span></span>[<span class="type">T</span>: <span class="type">ClassTag</span>](</span><br><span class="line">  hostname: <span class="type">String</span>,</span><br><span class="line">  port: <span class="type">Int</span>, </span><br><span class="line">  converter: (<span class="type">InputStream</span>) =&gt; <span class="type">Iterator</span>[<span class="type">T</span>],</span><br><span class="line">  storageLevel: <span class="type">StorageLevel</span>)</span><br><span class="line">  : <span class="type">ReceiverInputDStream</span>[<span class="type">T</span>] = &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">SocketInputDStream</span>[<span class="type">T</span>](<span class="keyword">this</span>, hostname, port, converter, storageLevel)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>也就是 <code>ssc.socketTextStream()</code> 将 <code>new</code> 出来一个 <code>DStream</code> 具体子类 <code>SocketInputDStream</code> 的实例。</p><p>然后我们继续找到下一行 <code>lines.flatMap(_.split(&quot; &quot;))</code> 的源码实现：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](flatMapFunc: <span class="type">T</span> =&gt; <span class="type">Traversable</span>[<span class="type">U</span>]): <span class="type">DStream</span>[<span class="type">U</span>] = ssc.withScope &#123;</span><br><span class="line">    <span class="keyword">new</span> <span class="type">FlatMappedDStream</span>(<span class="keyword">this</span>, context.sparkContext.clean(flatMapFunc))</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>也就是 <code>lines.flatMap(_.split(&quot; &quot;))</code> 将 <code>new</code> 出来一个 <code>DStream</code> 具体子类 <code>FlatMappedDStream</code> 的实例。</p><p>后面几行也是如此，所以我们如果用 DStream DAG 图来表示之前那段 quick example 的话，就是这个样子：</p><p><img src="1.imgs/010.png" alt="image"></p><p>也即，我们给出的那段代码，用具体的实现来替换的话，结果如下：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> lines = <span class="keyword">new</span> <span class="type">SocketInputDStream</span>(<span class="string">"localhost"</span>, <span class="number">9999</span>)   <span class="comment">// 类型是 SocketInputDStream</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> words = <span class="keyword">new</span> <span class="type">FlatMappedDStream</span>(lines, _.split(<span class="string">" "</span>))  <span class="comment">// 类型是 FlatMappedDStream</span></span><br><span class="line"><span class="keyword">val</span> pairs = <span class="keyword">new</span> <span class="type">MappedDStream</span>(words, word =&gt; (word, <span class="number">1</span>)) <span class="comment">// 类型是 MappedDStream</span></span><br><span class="line"><span class="keyword">val</span> wordCounts = <span class="keyword">new</span> <span class="type">ShuffledDStream</span>(pairs, _ + _)      <span class="comment">// 类型是 ShuffledDStream</span></span><br><span class="line"><span class="keyword">new</span> <span class="type">ForeachDStream</span>(wordCounts, cnt =&gt; cnt.print())      <span class="comment">// 类型是 ForeachDStream</span></span><br></pre></td></tr></table></figure><p>总结一下：</p><ul><li><em>transformation</em>：可以看到基本上 1 种 <em>transformation</em> 将对应产生一个新的 <code>DStream</code> 子类实例，如：<ul><li><code>.flatMap()</code> 将产生 <code>FaltMappedDStream</code> 实例</li><li><code>.map()</code>     将产生 <code>MappedDStream</code> 实例</li></ul></li><li><em>output</em>：将只产生一种 <code>ForEachDStream</code> 子类实例，用一个函数 <code>func</code> 来记录需要做的操作<ul><li>如对于 <code>print()</code> 就是：<code>func</code> = <code>cnt =&gt; cnt.print()</code></li></ul></li></ul><p>我们将有另一篇文章具体对 <code>DStream</code> 所有 <em>transformation</em> 的列举和分析，本文不展开。</p><h2 id="DStream-类继承体系"><a href="#DStream-类继承体系" class="headerlink" title="DStream 类继承体系"></a>DStream 类继承体系</h2><p>上面我们看到的 <code>SocketInputDStream</code>, <code>FlatMappedDStream</code>, <code>ForeachDStream</code> 等都是 <code>DStream</code> 的具体子类。</p><p><code>DStream</code> 的所有子类如下：</p><p><img src="1.imgs/040.png" alt="image"></p><p>一会我们要对其这些 <code>DStream</code> 子类进行一个分类。</p><h2 id="Dependency-DStreamGraph-解析"><a href="#Dependency-DStreamGraph-解析" class="headerlink" title="Dependency, DStreamGraph 解析"></a>Dependency, DStreamGraph 解析</h2><p>先再次回过头来看一下 <em>transformation</em> 操作。当我们写代码 <code>c = a.join(b), d = c.filter()</code> 时， 它们的 DAG 逻辑关系是 <code>a/b → c，c → d</code>，但在 Spark Streaming 在进行物理记录时却是反向的 <code>a/b ← c, c ← d</code>，如下图：</p><p><img src="1.imgs/020.png" alt="image"></p><p>那物理上为什么不顺着 DAG 来正向记录，却用反向记录？</p><p>这里背后的原因是，在 Spark Core 的 RDD API 里，RDD 的计算是被触发了以后才进行 lazy 求值的，即当真正求 <code>d</code> 的值的时候，先计算上游 dependency <code>c</code>；而计算 <code>c</code> 则先进一步计算 <code>c</code> 的上游 dependency <code>a</code> 和 <code>b</code>。Spark Streaming 里则与 RDD DAG 的反向表示保持了一致，对 DStream 也采用的反向表示。</p><p>所以，这里 <code>d</code> 对 <code>c</code> 的引用，表达的是一个上游<em>依赖</em>（<strong><em>dependency</em></strong>）的关系；也就是说，不求值则已，一旦 <code>d.print()</code> 这个 <em>output</em> 操作触发了对 <code>d</code> 的求值，那么就需要从 <code>d</code> 开始往上游进行追溯计算。</p><p>具体的过程是，<code>d.print()</code> 将 <code>new</code> 一个 <code>d</code> 的一个下游 <code>ForEachDStream x</code> —— <code>x</code> 中记明了需要做的操作 <code>func = print()</code> —— 然后在每个 batch 动态生成 RDD 实例时，以 <code>x</code> 为根节点、进行一次 BFS（宽度优先遍历），就可以快速得到需要进行实际计算的最小集合。如下图所示，这个最小集合就是 {<code>a</code>, <code>b</code>, <code>c</code>, <code>d</code>}。</p><p><img src="1.imgs/025.png" alt="image"></p><p>再看一个例子。如下图所示，如果对 <code>d</code>, <code>f</code> 分别调用 <code>print()</code> 的 <em>output</em> 操作，那么将在 <code>d</code>, <code>f</code> 的下游分别产生新的 <code>DStream x, y</code>，分别记录了具体操作 <code>func = print()</code>。在每个 batch 动态生成 RDD 实例时，就会分别对 <code>x</code> 和 <code>y</code> 进行 BFS 遍历，分别得到上游集合 {<code>a</code>,<code>b</code>,<code>c</code>,<code>d</code>} 和 {<code>b</code>,<code>e</code>,<code>f</code>}。作为对比，这里我们不对 <code>h</code> 进行 <code>print()</code> 的 <em>output</em> 操作，所以 <code>g</code>, <code>h</code> 将得不到遍历。</p><p><img src="1.imgs/030.png" alt="image"></p><p>通过以上分析，我们总结一下：</p><ul><li><p>(1) DStream 逻辑上通过 <em>transformation</em> 来形成 DAG，但在物理上却是通过与 <em>transformation</em> 反向的<em>依赖</em>（<strong><em>dependency</em></strong>）来构成表示的</p></li><li><p>(2) 当某个节点调用了 <em>output</em> 操作时，就产生一个新的 <code>ForEachDStream</code> ，这个新的 <code>ForEachDStream</code> 记录了具体的 <em>output</em> 操作是什么</p></li><li><p>(3) 在每个 batch 动态生成 RDD 实例时，就对 (2) 中新生成的 <code>DStream</code> 进行 BFS 遍历</p></li></ul><p>我们将在 (2) 中，由 <em>output</em> 操作新生成的 <code>DStream</code> 称为 <em>output stream</em>。</p><p>最后，我们给出：</p><ul><li><p>(4) <strong>Spark Streaming 记录整个 DStream DAG 的方式，就是通过一个 <code>DStreamGraph</code> 实例记录了到所有的 <em>output stream</em> 节点的引用</strong></p><ul><li>通过对所有 <em>output stream</em> 节点进行遍历，就可以得到所有上游依赖的 <code>DStream</code></li><li>不能被遍历到的 <code>DStream</code> 节点 —— 如 <code>g</code> 和 <code>h</code> —— 则虽然出现在了逻辑的 DAG 中，但是并不属于物理的 <code>DStreamGraph</code>，也将在 Spark Streaming 的实际运行过程中不产生任何作用</li></ul></li><li><p>(5) <code>DStreamGraph</code> 实例同时也记录了到所有 <em>input stream</em> 节点的引用</p><ul><li>DStreamGraph 时常需要遍历没有上游依赖的 <code>DStream</code> 节点 —— 称为 <em>input stream</em> —— 记录一下就可以避免每次为查找 <em>input stream</em> 而对 <em>output steam</em> 进行 BFS 的消耗</li></ul></li></ul><p>我们本节所描述的内容，用下图就能够总结了：</p><p><img src="1.imgs/035.png" alt="image"></p><p><br><br><br></p><p>（本文完，参与本文的讨论请 <a href="https://github.com/proflin/CoolplaySpark/issues/2" target="_blank" rel="noopener">猛戳这里</a>，返回目录请 <a href="readme.md">猛戳这里</a>）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;DStream-DStreamGraph-详解&quot;&gt;&lt;a href=&quot;#DStream-DStreamGraph-详解&quot; class=&quot;headerlink&quot; title=&quot;DStream, DStreamGraph 详解&quot;&gt;&lt;/a&gt;DStream, DStream
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/02/09/bigdata/spark/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97/0.1%20Spark%20Streaming%20%E5%AE%9E%E7%8E%B0%E6%80%9D%E8%B7%AF%E4%B8%8E%E6%A8%A1%E5%9D%97%E6%A6%82%E8%BF%B0/"/>
    <id>http://yoursite.com/2018/02/09/bigdata/spark/Spark Streaming 源码解析系列/0.1 Spark Streaming 实现思路与模块概述/</id>
    <published>2018-02-09T03:49:13.868Z</published>
    <updated>2018-02-09T03:48:41.379Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Spark-Streaming-实现思路与模块概述"><a href="#Spark-Streaming-实现思路与模块概述" class="headerlink" title="Spark Streaming 实现思路与模块概述"></a>Spark Streaming 实现思路与模块概述</h1><p><strong><em>[酷玩 Spark] Spark Streaming 源码解析系列</em></strong> ，返回目录请 <a href="readme.md">猛戳这里</a></p><p><a href="http://e.qq.com" target="_blank" rel="noopener">「腾讯·广点通」</a>技术团队荣誉出品</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">本系列内容适用范围：</span><br><span class="line"></span><br><span class="line">* 2017.07.11 update, Spark 2.2 全系列 √ (已发布：2.2.0)</span><br><span class="line">* 2017.10.02 update, Spark 2.1 全系列 √ (已发布：2.1.0, 2.1.1, 2.1.2)</span><br><span class="line">* 2016.11.14 update, Spark 2.0 全系列 √ (已发布：2.0.0, 2.0.1, 2.0.2)</span><br></pre></td></tr></table></figure><p><br><br><br></p><h2 id="一、基于-Spark-做-Spark-Streaming-的思路"><a href="#一、基于-Spark-做-Spark-Streaming-的思路" class="headerlink" title="一、基于 Spark 做 Spark Streaming 的思路"></a>一、基于 Spark 做 Spark Streaming 的思路</h2><p>Spark Streaming 与 Spark Core 的关系可以用下面的经典部件图来表述：</p><p><img src="0.imgs/010.png" alt="image"></p><p>在本节，我们先探讨一下基于 Spark Core 的 RDD API，如何对 streaming data 进行处理。<strong>理解下面描述的这个思路非常重要，因为基于这个思路详细展开后，就能够充分理解整个 Spark Streaming 的模块划分和代码逻辑</strong>。</p><p>第一步，假设我们有一小块数据，那么通过 RDD API，我们能够构造出一个进行数据处理的 RDD DAG（如下图所示）。</p><p><img src="0.imgs/020.png" alt="image"></p><p>第二步，我们对连续的 streaming data 进行切片处理 —— 比如将最近 200ms 时间的 event 积攒一下 —— 每个切片就是一个 batch，然后使用第一步中的 RDD DAG 对这个 batch 的数据进行处理。</p><blockquote><p>注意: 这里我们使用的是 batch 的概念 —— 其实 200ms 在其它同类系统中通常叫做 mini-batch，不过既然 Spark Streaming 官方的叫法就是 batch，我们这里就用 batch 表达 mini-batch 的意思了 :)</p></blockquote><p>所以，针对连续不断的 streaming data 进行多次切片，就会形成多个 batch，也就对应出来多个 RDD DAG（每个 RDD DAG 针对一个 batch 的数据）。如此一来，<strong>这多个 RDD DAG 之间相互同构，却又是不同的实例</strong>。我们用下图来表示这个关系：</p><p><img src="0.imgs/030.png" alt="image"></p><p>所以，我们将需要：</p><ul><li><p>(1) 一个<strong>静态</strong>的 RDD DAG 的<strong>模板</strong>，来表示处理逻辑；</p></li><li><p>(2) 一个<strong>动态</strong>的<strong>工作控制器</strong>，将连续的 streaming data 切分数据片段，并按照模板<strong>复制</strong>出新的 RDD DAG 的<strong>实例</strong>，对数据片段进行处理；</p></li></ul><p><img src="0.imgs/032.png" alt="image"></p><p>第三步，我们回过头来看 streaming data 本身的产生。Hadoop MapReduce, Spark RDD API 进行批处理时，一般默认数据已经在 HDFS, HBase 或其它存储上。而 streaming data —— 比如 twitter 流 —— 又有可能是在系统外实时产生的，就需要能够将这些数据导入到 Spark Streaming 系统里，就像 Apache Storm 的 Spout，Apache S4 的 Adapter 能够把数据导入系统里的作用是一致的。所以，我们将需要：</p><ul><li>(3) 原始数据的产生和导入；</li></ul><p>第四步，我们考虑，有了以上 (1)(2)(3) 3 部分，就可以顺利用 RDD API 处理 streaming data 了吗？其实相对于 batch job 通常几个小时能够跑完来讲，streaming job 的运行时间是 +∞（正无穷大）的，所以我们还将需要：</p><ul><li>(4) 对长时运行任务的保障，包括输入数据的失效后的重构，处理任务的失败后的重调。</li></ul><p>至此，streaming data 的特点决定了，如果我们想基于 Spark Core 进行 streaming data 的处理，还需要在 Spark Core 的框架上解决刚才列出的 (1)(2)(3)(4) 这四点问题：</p><p><img src="0.imgs/035.png" alt="image"></p><h2 id="二、Spark-Streaming-的整体模块划分"><a href="#二、Spark-Streaming-的整体模块划分" class="headerlink" title="二、Spark Streaming 的整体模块划分"></a>二、Spark Streaming 的整体模块划分</h2><p>根据 Spark Streaming 解决这 4 个问题的不同 focus，可以将 Spark Streaming 划分为四个大的模块：</p><ul><li>模块 1：DAG 静态定义</li><li>模块 2：Job 动态生成</li><li>模块 3：数据产生与导入</li><li>模块 4：长时容错</li></ul><p>其中每个模块涉及到的主要的类，示意如下：</p><p><img src="0.imgs/040.png" alt="image"></p><p>这里先不用纠结每个类的具体用途，我们将在本文中简述，并在本系列的后续文章里对每个模块逐一详述。</p><h3 id="2-1-模块-1：DAG-静态定义"><a href="#2-1-模块-1：DAG-静态定义" class="headerlink" title="2.1 模块 1：DAG 静态定义"></a>2.1 模块 1：DAG 静态定义</h3><p>通过前面的描述我们知道，应该首先对计算逻辑描述为一个 RDD DAG 的“模板”，在后面 Job 动态生成的时候，针对每个 batch，Spark Streaming 都将根据这个“模板”生成一个 RDD DAG 的实例。</p><h4 id="DStream-和-DStreamGraph"><a href="#DStream-和-DStreamGraph" class="headerlink" title="DStream 和 DStreamGraph"></a>DStream 和 DStreamGraph</h4><p>其实在 Spark Streaming 里，这个 RDD “模板”对应的具体的类是 <code>DStream</code>，RDD DAG “模板”对应的具体类是 <code>DStreamGraph</code>。而 <code>RDD</code> 本身也有很多子类，几乎每个子类都有一个对应的 <code>DStream</code>，如 <code>UnionRDD</code> 的对应是 <code>UnionDStream</code>。<code>RDD</code> 通过 <code>transformation</code> 连接成 RDD DAG（但 RDD DAG 在 Spark Core 里没有对应的具体类），<code>DStream</code> 也通过 <code>transformation</code> 连接成 <code>DStreamGraph</code>。</p><pre><code>DStream      的全限定名是：org.apache.spark.streaming.dstream.DStreamDStreamGraph 的全限定名是：org.apache.spark.streaming.DStreamGraph</code></pre><h4 id="DStream-和-RDD-的关系"><a href="#DStream-和-RDD-的关系" class="headerlink" title="DStream 和 RDD 的关系"></a>DStream 和 RDD 的关系</h4><p>既然 <code>DStream</code> 是 <code>RDD</code> 的模板，而且 <code>DStream</code> 和 <code>RDD</code> 具有相同的 <em>transformation</em> 操作，比如 map(), filter(), reduce() ……等等（正是这些相同的 <em>transformation</em> 使得 <code>DStreamGraph</code> 能够忠实记录 RDD DAG 的计算逻辑），那 <code>RDD</code> 和 <code>DStream</code> 有什么不一样吗？</p><p>还真不一样。</p><p>比如，<code>DStream</code> 维护了对每个产出的 <code>RDD</code> 实例的引用。比如下图里，<code>DStream A</code> 在 3 个 batch 里分别实例化了 3 个 <code>RDD</code>，分别是 <code>a[1]</code>, <code>a[2]</code>, <code>a[3]</code>，那么 <code>DStream A</code> 就保留了一个 <code>batch → 所产出的 RDD</code> 的哈希表，即包含 <code>batch 1 → a[1]</code>, <code>batch 2 → a[2]</code>, <code>batch 3 → a[3]</code> 这 3 项。</p><p><img src="0.imgs/045.png" alt="image"></p><p>另外，能够进行流量控制的 <code>DStream</code> 子类，如 <code>ReceiverInputDStream</code>，还会保存关于历次 batch 的源头数据条数、历次 batch 计算花费的时间等数值，用来实时计算准确的流量控制信息，这些都是记在 <code>DStream</code> 里的，而 <code>RDD a[1]</code> 等则不会保存这些信息。</p><p>我们在考虑的时候，可以认为，<code>RDD</code> 加上 batch 维度就是 <code>DStream</code>，<code>DStream</code> 去掉 batch 维度就是 <code>RDD</code> —— 就像 <code>RDD = DStream at batch T</code>。</p><p>不过这里需要特别说明的是，在 <code>DStreamGraph</code> 的图里，DStream（即数据）是顶点，<code>DStream</code> 之间的 transformation（即计算）是边，这与 Apache Storm 等是相反的。</p><p>在 Apache Storm 的 topology 里，计算是顶点，stream（连续的 tuple，即数据）是边。这一点也是比较熟悉 Storm 的同学刚开始一下子不太理解 DStream 的原因–我们再重复一遍，DStream 即是数据本身，在有向图里是顶点、而不是边。</p><p><img src="0.imgs/046.png" alt="image"></p><h3 id="2-2-模块-2：Job-动态生成"><a href="#2-2-模块-2：Job-动态生成" class="headerlink" title="2.2 模块 2：Job 动态生成"></a>2.2 模块 2：Job 动态生成</h3><p>现在有了 <code>DStreamGraph</code> 和 <code>DStream</code>，也就是静态定义了的计算逻辑，下面我们来看 Spark Streaming 是如何将其动态调度的。</p><p>在 Spark Streaming 程序的入口，我们都会定义一个 batchDuration，就是需要每隔多长时间就比照静态的 <code>DStreamGraph</code> 来动态生成一个 RDD DAG 实例。在 Spark Streaming 里，总体负责动态作业调度的具体类是 <code>JobScheduler</code>，在 Spark Streaming 程序开始运行的时候，会生成一个 <code>JobScheduler</code> 的实例，并被 start() 运行起来。</p><p><code>JobScheduler</code> 有两个非常重要的成员：<code>JobGenerator</code> 和 <code>ReceiverTracker</code>。<code>JobScheduler</code> 将每个 batch 的 RDD DAG 具体生成工作委托给 <code>JobGenerator</code>，而将源头输入数据的记录工作委托给 <code>ReceiverTracker</code>。</p><p><img src="0.imgs/050.png" alt="image"></p><pre><code>JobScheduler    的全限定名是：org.apache.spark.streaming.scheduler.JobSchedulerJobGenerator    的全限定名是：org.apache.spark.streaming.scheduler.JobGeneratorReceiverTracker 的全限定名是：org.apache.spark.streaming.scheduler.ReceiverTracker</code></pre><p><strong><code>JobGenerator</code> 维护了一个定时器</strong>，周期就是我们刚刚提到的 batchDuration，<strong>定时为每个 batch 生成 RDD DAG 的实例</strong>。具体的，每次 RDD DAG 实际生成包含 5 个步骤：</p><ul><li>(1) <strong>要求 <code>ReceiverTracker</code> 将目前已收到的数据进行一次 allocate</strong>，即将上次 batch 切分后的数据切分到到本次新的 batch 里；</li><li>(2) <strong>要求 <code>DStreamGraph</code> 复制出一套新的 RDD DAG 的实例</strong>，具体过程是：<code>DStreamGraph</code> 将要求图里的尾 <code>DStream</code> 节点生成具体的 RDD 实例，并递归的调用尾 <code>DStream</code> 的上游 <code>DStream</code> 节点……以此遍历整个 <code>DStreamGraph</code>，遍历结束也就正好生成了 RDD DAG 的实例；</li><li>(3) <strong>获取第 1 步 <code>ReceiverTracker</code> 分配到本 batch 的源头数据的 meta 信息</strong>；</li><li>(4) 将第 2 步生成的本 batch 的 RDD DAG，和第 3 步获取到的 meta 信息，<strong>一同提交给 <code>JobScheduler</code> 异步执行</strong>；</li><li>(5) 只要提交结束（不管是否已开始异步执行），就<strong>马上对整个系统的当前运行状态做一个 checkpoint</strong>。</li></ul><p>上述 5 个步骤的调用关系图如下：</p><p><img src="0.imgs/055.png" alt="image"></p><h3 id="2-3-模块-3：数据产生与导入"><a href="#2-3-模块-3：数据产生与导入" class="headerlink" title="2.3 模块 3：数据产生与导入"></a>2.3 模块 3：数据产生与导入</h3><p>下面我们看 Spark Streaming 解决第三个问题的模块分析，即数据的产生与导入。</p><p><code>DStream</code> 有一个重要而特殊的子类 <code>ReceiverInputDStream</code>：它除了需要像其它 <code>DStream</code> 那样在某个 batch 里实例化 <code>RDD</code> 以外，还需要额外的 <code>Receiver</code> 为这个 <code>RDD</code> 生产数据！</p><p>具体的，Spark Streaming 在程序刚开始运行时：</p><ul><li><p>(1) 由 <code>Receiver</code> 的总指挥 <code>ReceiverTracker</code> 分发多个 job（每个 job 有 1 个 task），到多个 executor 上分别启动 <code>ReceiverSupervisor</code> 实例；</p></li><li><p>(2) 每个 <code>ReceiverSupervisor</code> 启动后将马上生成一个用户提供的 <code>Receiver</code> 实现的实例 —— 该 <code>Receiver</code> 实现可以持续产生或者持续接收系统外数据，比如 <code>TwitterReceiver</code> 可以实时爬取 twitter 数据 —— 并在 <code>Receiver</code> 实例生成后调用 <code>Receiver.onStart()</code>；</p></li></ul><p><img src="0.imgs/060.png" alt="image"></p><pre><code>ReceiverSupervisor 的全限定名是：org.apache.spark.streaming.receiver.ReceiverSupervisorReceiver           的全限定名是：org.apache.spark.streaming.receiver.Receiver</code></pre><p>(1)(2) 的过程由上图所示，这时 <code>Receiver</code> 启动工作已运行完毕。</p><p>接下来 <code>ReceiverSupervisor</code> 将在 executor 端作为的主要角色，并且：</p><ul><li><p>(3) <code>Receiver</code> 在 <code>onStart()</code> 启动后，就将<strong>持续不断</strong>地接收外界数据，并持续交给 <code>ReceiverSupervisor</code> 进行数据转储；</p></li><li><p>(4) <code>ReceiverSupervisor</code> <strong>持续不断</strong>地接收到 <code>Receiver</code> 转来的数据：</p><ul><li>如果数据很细小，就需要 <code>BlockGenerator</code> 攒多条数据成一块(4a)、然后再成块存储(4b 或 4c)</li><li><p>反之就不用攒，直接成块存储(4b 或 4c)</p></li><li><p>这里 Spark Streaming 目前支持两种成块存储方式，一种是由 <code>BlockManagerBasedBlockHandler</code> 直接存到 executor 的内存或硬盘，另一种由 <code>WriteAheadLogBasedBlockHandler</code> 是同时写 WAL(4c) 和 executor 的内存或硬盘</p></li></ul></li><li><p>(5) 每次成块在 executor 存储完毕后，<code>ReceiverSupervisor</code> 就会及时上报块数据的 meta 信息给 driver 端的 <code>ReceiverTracker</code>；这里的 meta 信息包括数据的标识 id，数据的位置，数据的条数，数据的大小等信息；</p></li><li><p>(6) <code>ReceiverTracker</code> 再将收到的块数据 meta 信息直接转给自己的成员 <code>ReceivedBlockTracker</code>，由 <code>ReceivedBlockTracker</code> 专门管理收到的块数据 meta 信息。</p></li></ul><p><img src="0.imgs/065.png" alt="image"></p><pre><code>BlockGenerator                 的全限定名是：org.apache.spark.streaming.receiver.BlockGeneratorBlockManagerBasedBlockHandler  的全限定名是：org.apache.spark.streaming.receiver.BlockManagerBasedBlockHandlerWriteAheadLogBasedBlockHandler 的全限定名是：org.apache.spark.streaming.receiver.WriteAheadLogBasedBlockHandlerReceivedBlockTracker           的全限定名是：org.apache.spark.streaming.scheduler.ReceivedBlockTrackerReceiverInputDStream           的全限定名是：org.apache.spark.streaming.dstream.ReceiverInputDStream</code></pre><p>这里 (3)(4)(5)(6) 的过程是一直<strong>持续不断</strong>地发生的，我们也将其在上图里标识出来。</p><p>后续在 driver 端，就由 <code>ReceiverInputDStream</code> 在每个 batch 去检查 <code>ReceiverTracker</code> 收到的块数据 meta 信息，界定哪些新数据需要在本 batch 内处理，然后生成相应的 <code>RDD</code> 实例去处理这些块数据，这个过程在<code>模块 1：DAG 静态定义</code> <code>模块2：Job 动态生成</code> 里描述过了。</p><h3 id="2-4-模块-4：长时容错"><a href="#2-4-模块-4：长时容错" class="headerlink" title="2.4 模块 4：长时容错"></a>2.4 模块 4：长时容错</h3><p>以上我们简述完成 Spark Streamimg 基于 Spark Core 所新增功能的 3 个模块，接下来我们看一看第 4 个模块将如何保障 Spark Streaming 的长时运行 —— 也就是，如何与前 3 个模块结合，保障前 3 个模块的长时运行。</p><p>通过前 3 个模块的关键类的分析，我们可以知道，保障模块 1 和 2 需要在 driver 端完成，保障模块 3 需要在 executor 端和 driver 端完成。</p><h4 id="executor-端长时容错"><a href="#executor-端长时容错" class="headerlink" title="executor 端长时容错"></a>executor 端长时容错</h4><p>先看 executor 端。</p><p>在 executor 端，<code>ReceiverSupervisor</code> 和 <code>Receiver</code> 失效后直接重启就 OK 了，关联是保障收到的块数据的安全。保障了源头块数据，就能够保障 RDD DAG （Spark Core 的 lineage）重做。</p><p>Spark Streaming 对源头块数据的保障，分为 4 个层次，全面、相互补充，又可根据不同场景灵活设置：</p><ul><li><strong>(1) 热备</strong>：热备是指在存储块数据时，将其存储到本 executor、并同时 replicate 到另外一个 executor 上去。这样在一个 replica 失效后，可以立刻无感知切换到另一份 replica 进行计算。实现方式是，在实现自己的 Receiver 时，即指定一下 <code>StorageLevel</code> 为 <code>MEMORY_ONLY_2</code> 或 <code>MEMORY_AND_DISK_2</code> 就可以了。</li></ul><blockquote><p>// 1.5.2 update 这已经是默认了。</p></blockquote><ul><li><strong>(2) 冷备</strong>：冷备是每次存储块数据前，先把块数据作为 log 写出到 <code>WriteAheadLog</code> 里，再存储到本 executor。executor 失效时，就由另外的 executor 去读 WAL，再重做 log 来恢复块数据。WAL 通常写到可靠存储如 HDFS 上，所以恢复时可能需要一段 recover time。</li></ul><p><img src="0.imgs/070.png" alt="image"></p><ul><li><p><strong>(3) 重放</strong>：如果上游支持重放，比如 Apache Kafka，那么就可以选择不用热备或者冷备来另外存储数据了，而是在失效时换一个 executor 进行数据重放即可。</p></li><li><p><strong>(4) 忽略</strong>：最后，如果应用的实时性需求大于准确性，那么一块数据丢失后我们也可以选择忽略、不恢复失效的源头数据。</p></li></ul><p>我们用一个表格来总结一下：</p><table><br><tr><br>    <td align="center"></td><br>    <td align="center"><strong>图示</strong></td><br>    <td align="center"><strong>优点</strong></td><br>    <td align="center"><strong>缺点</strong></td><br></tr><br><tr><br>    <td align="center"><strong>(1) 热备</strong></td><br>    <td align="center"><img src="0.imgs/075a.png"></td><br>    <td align="center">无 recover time</td><br>    <td align="center">需要占用双倍资源</td><br></tr><br><tr><br>    <td align="center"><strong>(2) 冷备</strong></td><br>    <td align="center"><img src="0.imgs/075b.png"></td><br>    <td align="center">十分可靠</td><br>    <td align="center">存在 recover time</td><br></tr><br><tr><br>    <td align="center"><strong>(3) 重放</strong></td><br>    <td align="center"><img src="0.imgs/075c.png"></td><br>    <td align="center">不占用额外资源</td><br>    <td align="center">存在 recover time</td><br></tr><br><tr><br>    <td align="center"><strong>(4) 忽略</strong></td><br>    <td align="center"><img src="0.imgs/075d.png"></td><br>    <td align="center">无 recover time</td><br>    <td align="center">准确性有损失</td><br></tr><br></table><h4 id="driver-端长时容错"><a href="#driver-端长时容错" class="headerlink" title="driver 端长时容错"></a>driver 端长时容错</h4><p>前面我们讲过，块数据的 meta 信息上报到 <code>ReceiverTracker</code>，然后交给 <code>ReceivedBlockTracker</code> 做具体的管理。<code>ReceivedBlockTracker</code> 也采用 WAL 冷备方式进行备份，在 driver 失效后，由新的 <code>ReceivedBlockTracker</code> 读取 WAL 并恢复 block 的 meta 信息。</p><p>另外，需要定时对 <code>DStreamGraph</code> 和 <code>JobScheduler</code> 做 <code>Checkpoint</code>，来记录整个 <code>DStreamGraph</code> 的变化、和每个 batch 的 job 的完成情况。</p><p>注意到这里采用的是完整 checkpoint 的方式，和之前的 WAL 的方式都不一样。<code>Checkpoint</code> 通常也是落地到可靠存储如 HDFS。<code>Checkpoint</code> 发起的间隔默认的是和 <code>batchDuration 一致</code>；即每次 batch 发起、提交了需要运行的 job 后就做 <code>Checkpoint</code>，另外在 job 完成了更新任务状态的时候再次做一下 <code>Checkpoint</code>。</p><p>这样一来，在 driver 失效并恢复后，可以读取最近一次的 <code>Checkpoint</code> 来恢复作业的 <code>DStreamGraph</code> 和 job 的运行及完成状态。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><table><br>    <tr><br>        <td align="center"><strong>模块</strong></td><br>        <td align="center" colspan="2"><strong>长时容错保障方式</strong></td><br>    </tr><br>    <tr><br>        <td align="center">模块 1-DAG 静态定义</td><br>        <td align="center">driver 端</td><br>        <td>定时对 DStreamGraph 做 Checkpoint，来记录整个 DStreamGraph 的变化</td><br>    </tr><br>    <tr><br>        <td align="center">模块 2-job 动态生成</td><br>        <td align="center">driver 端</td><br>        <td>定时对 JobScheduler 做 Checkpoint，来记录每个 batch 的 job 的完成情况</td><br>    </tr><br>    <tr><br>        <td align="center">模块 3-数据产生与导入</td><br>        <td align="center">driver 端</td><br>        <td>源头块数据的 meta 信息上报 ReceiverTracker 时，写入 WAL</td><br>    </tr><br>    <tr><br>        <td align="center">模块 3-数据产生与导入</td><br>        <td align="center">executor 端</td><br>        <td>对源头块数据的保障：(1) 热备；(2) 冷备；(3) 重放；(4) 忽略</td><br>    </tr><br></table><p>总结一下“模块4：长时容错”的内容为上述表格，可以看到，Spark Streaming 的长时容错特性，能够提供不重、不丢，exactly-once 的处理语义。</p><h2 id="三、入口：StreamingContext"><a href="#三、入口：StreamingContext" class="headerlink" title="三、入口：StreamingContext"></a>三、入口：StreamingContext</h2><p>上面我们花了很多篇幅来介绍 Spark Streaming 的四大模块，我们在最后介绍一下 <code>StreamingContext</code>。</p><p>下面我们用这段仅 11 行的完整 <a href="0.imgs/http://spark.apache.org/docs/latest/streaming-programming-guide.html#a-quick-example">quick example</a>，来说明用户 code 是怎么通过 <code>StreamingContext</code> 与前面几个模块进行交互的：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming._</span><br><span class="line"></span><br><span class="line"><span class="comment">// 首先配置一下本 quick example 将跑在本机，app name 是 NetworkWordCount</span></span><br><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[2]"</span>).setAppName(<span class="string">"NetworkWordCount"</span>)</span><br><span class="line"><span class="comment">// batchDuration 设置为 1 秒，然后创建一个 streaming 入口</span></span><br><span class="line"><span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">// ssc.socketTextStream() 将创建一个 SocketInputDStream；这个 InputDStream 的 SocketReceiver 将监听本机 9999 端口</span></span><br><span class="line"><span class="keyword">val</span> lines = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> words = lines.flatMap(_.split(<span class="string">" "</span>))      <span class="comment">// DStream transformation</span></span><br><span class="line"><span class="keyword">val</span> pairs = words.map(word =&gt; (word, <span class="number">1</span>))     <span class="comment">// DStream transformation</span></span><br><span class="line"><span class="keyword">val</span> wordCounts = pairs.reduceByKey(_ + _)    <span class="comment">// DStream transformation</span></span><br><span class="line">wordCounts.print()                           <span class="comment">// DStream output</span></span><br><span class="line"><span class="comment">// 上面 4 行利用 DStream transformation 构造出了 lines -&gt; words -&gt; pairs -&gt; wordCounts -&gt; .print() 这样一个 DStreamGraph</span></span><br><span class="line"><span class="comment">// 但注意，到目前是定义好了产生数据的 SocketReceiver，以及一个 DStreamGraph，这些都是静态的</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 下面这行 start() 将在幕后启动 JobScheduler, 进而启动 JobGenerator 和 ReceiverTracker</span></span><br><span class="line"><span class="comment">// ssc.start()</span></span><br><span class="line"><span class="comment">//    -&gt; JobScheduler.start()</span></span><br><span class="line"><span class="comment">//        -&gt; JobGenerator.start();    开始不断生成一个一个 batch</span></span><br><span class="line"><span class="comment">//        -&gt; ReceiverTracker.start(); 开始往 executor 上分布 ReceiverSupervisor 了，也会进一步创建和启动 Receiver</span></span><br><span class="line">ssc.start()</span><br><span class="line"></span><br><span class="line"><span class="comment">// 然后用户 code 主线程就 block 在下面这行代码了</span></span><br><span class="line"><span class="comment">// block 的后果就是，后台的 JobScheduler 线程周而复始的产生一个一个 batch 而不停息</span></span><br><span class="line"><span class="comment">// 也就是在这里，我们前面静态定义的 DStreamGraph 的 print()，才一次一次被在 RDD 实例上调用，一次一次打印出当前 batch 的结果</span></span><br><span class="line">ssc.awaitTermination()</span><br></pre></td></tr></table></figure><p>所以我们看到，<code>StreamingContext</code> 是 Spark Streaming 提供给用户 code 的、与前述 4 个模块交互的一个简单和统一的入口。</p><h2 id="四、总结与回顾"><a href="#四、总结与回顾" class="headerlink" title="四、总结与回顾"></a>四、总结与回顾</h2><p>在最后我们再把 [Sark Streaming 官方 Programming Guide] (<a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html#a-quick-example" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/streaming-programming-guide.html#a-quick-example</a>) 的部分内容放在这里，作为本文的一个回顾和总结。请大家看一看，如果看懂了本文的内容，是不是读下面这些比较 high-level 的介绍会清晰化很多 :-)</p><blockquote><p><strong>Spark Streaming</strong> is an extension of the <strong>core Spark API</strong> that enables <strong>scalable</strong>, <strong>high-throughput</strong>, <strong>fault-tolerant stream processing of live data streams</strong>. Data can be ingested from many sources like Kafka, Flume, Twitter, ZeroMQ, Kinesis, or TCP sockets, and can be processed using complex algorithms expressed with high-level functions like map, reduce, join and window. Finally, processed data can be pushed out to filesystems, databases, and live dashboards. In fact, you can apply Spark’s machine learning and graph processing algorithms on data streams.</p><p><img src="0.imgs/streaming-arch.png" alt=""></p><p>Internally, it works as follows. <strong>Spark Streaming receives live input data streams and divides the data into batches, which are then processed by the Spark engine to generate the final stream of results in batches</strong>.</p><p><img src="0.imgs/streaming-flow.png" alt=""></p><p>Spark Streaming provides a high-level abstraction called <strong>discretized stream</strong> or <strong>DStream</strong>, which represents a continuous stream of data. DStreams can be created either from input data streams from sources such as Kafka, Flume, and Kinesis, or by applying high-level operations on other DStreams. <strong>Internally, a DStream is represented as a sequence of RDDs</strong>.</p><p>…</p></blockquote><p>##知识共享</p><p><img src="https://licensebuttons.net/l/by-nc/4.0/88x31.png" alt=""></p><p>除非另有注明，本文及本《Spark Streaming 源码解析系列》系列文章使用 <a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">CC BY-NC（署名-非商业性使用）</a> 知识共享许可协议。</p><p><br><br><br></p><p>（本文完，参与本文的讨论请 <a href="https://github.com/proflin/CoolplaySpark/issues/1" target="_blank" rel="noopener">猛戳这里</a>，返回目录请 <a href="readme.md">猛戳这里</a>）</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Spark-Streaming-实现思路与模块概述&quot;&gt;&lt;a href=&quot;#Spark-Streaming-实现思路与模块概述&quot; class=&quot;headerlink&quot; title=&quot;Spark Streaming 实现思路与模块概述&quot;&gt;&lt;/a&gt;Spark Strea
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2018/01/29/hello-world/"/>
    <id>http://yoursite.com/2018/01/29/hello-world/</id>
    <published>2018-01-29T01:52:14.136Z</published>
    <updated>2018-01-29T01:52:14.136Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
</feed>
